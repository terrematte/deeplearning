{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIf7eFgwyZ06"
      },
      "source": [
        "# 1 Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4OeKOISEobo"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "import time\n",
        "import datetime\n",
        "import pytz\n",
        "import IPython"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRdkrAFXxYcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54d7b384-9352-4173-ec91-f00932c84a27"
      },
      "source": [
        "print('TF version:', tf.__version__)\n",
        "print('GPU devices:', tf.config.list_physical_devices('GPU'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.17.0\n",
            "GPU devices: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -V"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EekSqBOGKDbY",
        "outputId": "d1906e14-b878-4849-e09b-198a40008340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSK_tRj1yipL"
      },
      "source": [
        "# 2 Data load and preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download train_catvnoncat.h5\n",
        "!gdown 'https://github.com/terrematte/deeplearning/raw/refs/heads/main/datasets/cats/train_catvnoncat.h5'\n",
        "\n",
        "# download test_catvnoncat.h5\n",
        "!gdown 'https://github.com/terrematte/deeplearning/raw/refs/heads/main/datasets/cats/test_catvnoncat.h5'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2NjGVQeJdYC",
        "outputId": "b6424411-21d7-4e57-99e7-378e069ec3a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://github.com/terrematte/deeplearning/raw/refs/heads/main/datasets/cats/train_catvnoncat.h5\n",
            "To: /content/train_catvnoncat.h5\n",
            "100% 2.57M/2.57M [00:00<00:00, 40.3MB/s]\n",
            "Downloading...\n",
            "From: https://github.com/terrematte/deeplearning/raw/refs/heads/main/datasets/cats/test_catvnoncat.h5\n",
            "To: /content/test_catvnoncat.h5\n",
            "100% 617k/617k [00:00<00:00, 22.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evhmAkbKxYy_"
      },
      "source": [
        "def load_dataset():\n",
        "    # load the train data\n",
        "    train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
        "\n",
        "    # your train set features\n",
        "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
        "\n",
        "    # your train set labels\n",
        "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
        "\n",
        "    # load the test data\n",
        "    test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
        "\n",
        "    # your test set features\n",
        "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
        "\n",
        "    # your test set labels\n",
        "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
        "\n",
        "    # the list of classes\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "\n",
        "    # reshape the test data\n",
        "    train_set_y_orig = train_set_y_orig.reshape((train_set_y_orig.shape[0],1))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((test_set_y_orig.shape[0],1))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjQYsrdPHSyh"
      },
      "source": [
        "# Loading the data (cat/non-cat)\n",
        "train_set_x_orig, train_y, test_set_x_orig, test_y, classes = load_dataset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ihL83MbHlhc"
      },
      "source": [
        "# Reshape the training and test examples\n",
        "train_set_x_flatten = train_set_x_orig.reshape(train_set_x_orig.shape[0],-1)\n",
        "test_set_x_flatten = test_set_x_orig.reshape(test_set_x_orig.shape[0],-1)\n",
        "\n",
        "# Standardize the dataset\n",
        "train_x = train_set_x_flatten/255\n",
        "test_x = test_set_x_flatten/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQn-Brt-IhK_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892f9397-df67-472e-baf1-cc7eec7f56cb"
      },
      "source": [
        "print (\"train_x shape: \" + str(train_x.shape))\n",
        "print (\"train_y shape: \" + str(train_y.shape))\n",
        "print (\"test_x  shape: \" + str(test_x.shape))\n",
        "print (\"test_y  shape: \" + str(test_y.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_x shape: (209, 12288)\n",
            "train_y shape: (209, 1)\n",
            "test_x  shape: (50, 12288)\n",
            "test_y  shape: (50, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #not a cat image\n",
        "index = 1\n",
        "plt.imshow(train_x[index].reshape(64,64,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "KVT88TrAHruE",
        "outputId": "656be99d-e74a-412f-c623-00c9cf6608d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e94b1126170>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATILeNhddrcC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "outputId": "a3f0314d-0704-49f6-e4a3-2e8e85b1891a"
      },
      "source": [
        "# visualize a sample modified data\n",
        "index = 2\n",
        "plt.imshow(train_x[index].reshape(64,64,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e94a0241b40>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xa9dcSRx1__x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "97c0dedf-2606-409f-9a4b-2840aca67e73"
      },
      "source": [
        "# visualize a sample raw data\n",
        "index = 13\n",
        "plt.imshow(train_set_x_orig[index])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc383f87ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvACru73ysxG"
      },
      "source": [
        "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_train_begin(self, batch, logs=None):\n",
        "    self.begins = time.time()\n",
        "    print('Training: begins at {}'.format(datetime.datetime.now(pytz.timezone('America/Fortaleza')).strftime(\"%a, %d %b %Y %H:%M:%S\")))\n",
        "\n",
        "  def on_train_end(self, logs=None):\n",
        "    print('Training: ends at {}'.format(datetime.datetime.now(pytz.timezone('America/Fortaleza')).strftime(\"%a, %d %b %Y %H:%M:%S\")))\n",
        "    print('Duration: {:.2f} seconds'.format(time.time() - self.begins))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyHu7kEeyrh-"
      },
      "source": [
        "# 3 Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPkKk-ZayvfU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b38dfa25-77e4-4e14-c3d2-0ce6c885da14"
      },
      "source": [
        "# Instantiate a simple classification model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(8, activation=tf.nn.relu, dtype='float64'),\n",
        "  tf.keras.layers.Dense(8, activation=tf.nn.relu, dtype='float64'),\n",
        "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, dtype='float64')\n",
        "])\n",
        "\n",
        "# Instantiate a logistic loss function that expects integer targets.\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Instantiate an accuracy metric.\n",
        "accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "# Instantiate an optimizer.\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
        "\n",
        "# configure the optimizer, loss, and metrics to monitor.\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
        "\n",
        "# training\n",
        "history = model.fit(x=train_x,\n",
        "                    y=train_y,\n",
        "                    batch_size=32,\n",
        "                    epochs=500,\n",
        "                    validation_data=(test_x,test_y),\n",
        "                    callbacks=[MyCustomCallback()],\n",
        "                    verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training: begins at Mon, 18 Sep 2023 10:06:21\n",
            "Epoch 1/500\n",
            "7/7 [==============================] - 7s 114ms/step - loss: 0.7070 - binary_accuracy: 0.4306 - val_loss: 0.7029 - val_binary_accuracy: 0.3600\n",
            "Epoch 2/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6906 - binary_accuracy: 0.5598 - val_loss: 0.7088 - val_binary_accuracy: 0.3200\n",
            "Epoch 3/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6874 - binary_accuracy: 0.5837 - val_loss: 0.7140 - val_binary_accuracy: 0.3400\n",
            "Epoch 4/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6841 - binary_accuracy: 0.5981 - val_loss: 0.7191 - val_binary_accuracy: 0.3600\n",
            "Epoch 5/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6819 - binary_accuracy: 0.6172 - val_loss: 0.7249 - val_binary_accuracy: 0.3400\n",
            "Epoch 6/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6796 - binary_accuracy: 0.6364 - val_loss: 0.7300 - val_binary_accuracy: 0.3400\n",
            "Epoch 7/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6774 - binary_accuracy: 0.6459 - val_loss: 0.7344 - val_binary_accuracy: 0.3400\n",
            "Epoch 8/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6755 - binary_accuracy: 0.6507 - val_loss: 0.7386 - val_binary_accuracy: 0.3400\n",
            "Epoch 9/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6736 - binary_accuracy: 0.6459 - val_loss: 0.7429 - val_binary_accuracy: 0.3400\n",
            "Epoch 10/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6718 - binary_accuracy: 0.6555 - val_loss: 0.7467 - val_binary_accuracy: 0.3400\n",
            "Epoch 11/500\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6703 - binary_accuracy: 0.6507 - val_loss: 0.7501 - val_binary_accuracy: 0.3400\n",
            "Epoch 12/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6689 - binary_accuracy: 0.6507 - val_loss: 0.7542 - val_binary_accuracy: 0.3400\n",
            "Epoch 13/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.6674 - binary_accuracy: 0.6507 - val_loss: 0.7580 - val_binary_accuracy: 0.3400\n",
            "Epoch 14/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6662 - binary_accuracy: 0.6507 - val_loss: 0.7611 - val_binary_accuracy: 0.3400\n",
            "Epoch 15/500\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6651 - binary_accuracy: 0.6507 - val_loss: 0.7655 - val_binary_accuracy: 0.3400\n",
            "Epoch 16/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.6637 - binary_accuracy: 0.6507 - val_loss: 0.7697 - val_binary_accuracy: 0.3400\n",
            "Epoch 17/500\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6623 - binary_accuracy: 0.6507 - val_loss: 0.7737 - val_binary_accuracy: 0.3400\n",
            "Epoch 18/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6611 - binary_accuracy: 0.6507 - val_loss: 0.7789 - val_binary_accuracy: 0.3400\n",
            "Epoch 19/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.6599 - binary_accuracy: 0.6555 - val_loss: 0.7828 - val_binary_accuracy: 0.3400\n",
            "Epoch 20/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6592 - binary_accuracy: 0.6555 - val_loss: 0.7865 - val_binary_accuracy: 0.3400\n",
            "Epoch 21/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6581 - binary_accuracy: 0.6555 - val_loss: 0.7897 - val_binary_accuracy: 0.3400\n",
            "Epoch 22/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6574 - binary_accuracy: 0.6555 - val_loss: 0.7929 - val_binary_accuracy: 0.3400\n",
            "Epoch 23/500\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.6567 - binary_accuracy: 0.6555 - val_loss: 0.7977 - val_binary_accuracy: 0.3400\n",
            "Epoch 24/500\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.6561 - binary_accuracy: 0.6555 - val_loss: 0.8006 - val_binary_accuracy: 0.3400\n",
            "Epoch 25/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6555 - binary_accuracy: 0.6555 - val_loss: 0.8053 - val_binary_accuracy: 0.3400\n",
            "Epoch 26/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6548 - binary_accuracy: 0.6555 - val_loss: 0.8096 - val_binary_accuracy: 0.3400\n",
            "Epoch 27/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6540 - binary_accuracy: 0.6555 - val_loss: 0.8111 - val_binary_accuracy: 0.3400\n",
            "Epoch 28/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6536 - binary_accuracy: 0.6555 - val_loss: 0.8129 - val_binary_accuracy: 0.3400\n",
            "Epoch 29/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.6531 - binary_accuracy: 0.6555 - val_loss: 0.8149 - val_binary_accuracy: 0.3400\n",
            "Epoch 30/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6529 - binary_accuracy: 0.6555 - val_loss: 0.8171 - val_binary_accuracy: 0.3400\n",
            "Epoch 31/500\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6523 - binary_accuracy: 0.6555 - val_loss: 0.8173 - val_binary_accuracy: 0.3400\n",
            "Epoch 32/500\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6520 - binary_accuracy: 0.6555 - val_loss: 0.8203 - val_binary_accuracy: 0.3400\n",
            "Epoch 33/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.6516 - binary_accuracy: 0.6555 - val_loss: 0.8234 - val_binary_accuracy: 0.3400\n",
            "Epoch 34/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6511 - binary_accuracy: 0.6555 - val_loss: 0.8273 - val_binary_accuracy: 0.3400\n",
            "Epoch 35/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6507 - binary_accuracy: 0.6555 - val_loss: 0.8294 - val_binary_accuracy: 0.3400\n",
            "Epoch 36/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6503 - binary_accuracy: 0.6555 - val_loss: 0.8313 - val_binary_accuracy: 0.3400\n",
            "Epoch 37/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.6501 - binary_accuracy: 0.6555 - val_loss: 0.8330 - val_binary_accuracy: 0.3400\n",
            "Epoch 38/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6499 - binary_accuracy: 0.6555 - val_loss: 0.8335 - val_binary_accuracy: 0.3400\n",
            "Epoch 39/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6496 - binary_accuracy: 0.6555 - val_loss: 0.8381 - val_binary_accuracy: 0.3400\n",
            "Epoch 40/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6492 - binary_accuracy: 0.6555 - val_loss: 0.8394 - val_binary_accuracy: 0.3400\n",
            "Epoch 41/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6488 - binary_accuracy: 0.6555 - val_loss: 0.8416 - val_binary_accuracy: 0.3400\n",
            "Epoch 42/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6488 - binary_accuracy: 0.6555 - val_loss: 0.8432 - val_binary_accuracy: 0.3400\n",
            "Epoch 43/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6480 - binary_accuracy: 0.6555 - val_loss: 0.8460 - val_binary_accuracy: 0.3400\n",
            "Epoch 44/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6478 - binary_accuracy: 0.6555 - val_loss: 0.8460 - val_binary_accuracy: 0.3400\n",
            "Epoch 45/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6477 - binary_accuracy: 0.6555 - val_loss: 0.8438 - val_binary_accuracy: 0.3400\n",
            "Epoch 46/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6479 - binary_accuracy: 0.6555 - val_loss: 0.8463 - val_binary_accuracy: 0.3400\n",
            "Epoch 47/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6470 - binary_accuracy: 0.6555 - val_loss: 0.8463 - val_binary_accuracy: 0.3400\n",
            "Epoch 48/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6470 - binary_accuracy: 0.6555 - val_loss: 0.8476 - val_binary_accuracy: 0.3400\n",
            "Epoch 49/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6466 - binary_accuracy: 0.6555 - val_loss: 0.8494 - val_binary_accuracy: 0.3400\n",
            "Epoch 50/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6464 - binary_accuracy: 0.6555 - val_loss: 0.8530 - val_binary_accuracy: 0.3400\n",
            "Epoch 51/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6464 - binary_accuracy: 0.6555 - val_loss: 0.8536 - val_binary_accuracy: 0.3400\n",
            "Epoch 52/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6459 - binary_accuracy: 0.6555 - val_loss: 0.8522 - val_binary_accuracy: 0.3400\n",
            "Epoch 53/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6457 - binary_accuracy: 0.6555 - val_loss: 0.8517 - val_binary_accuracy: 0.3400\n",
            "Epoch 54/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6455 - binary_accuracy: 0.6555 - val_loss: 0.8508 - val_binary_accuracy: 0.3400\n",
            "Epoch 55/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6455 - binary_accuracy: 0.6555 - val_loss: 0.8547 - val_binary_accuracy: 0.3400\n",
            "Epoch 56/500\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6450 - binary_accuracy: 0.6555 - val_loss: 0.8506 - val_binary_accuracy: 0.3400\n",
            "Epoch 57/500\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.6449 - binary_accuracy: 0.6555 - val_loss: 0.8537 - val_binary_accuracy: 0.3400\n",
            "Epoch 58/500\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6446 - binary_accuracy: 0.6555 - val_loss: 0.8556 - val_binary_accuracy: 0.3400\n",
            "Epoch 59/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.6445 - binary_accuracy: 0.6555 - val_loss: 0.8562 - val_binary_accuracy: 0.3400\n",
            "Epoch 60/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6440 - binary_accuracy: 0.6555 - val_loss: 0.8581 - val_binary_accuracy: 0.3400\n",
            "Epoch 61/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.6437 - binary_accuracy: 0.6555 - val_loss: 0.8575 - val_binary_accuracy: 0.3400\n",
            "Epoch 62/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6436 - binary_accuracy: 0.6555 - val_loss: 0.8608 - val_binary_accuracy: 0.3400\n",
            "Epoch 63/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6432 - binary_accuracy: 0.6555 - val_loss: 0.8586 - val_binary_accuracy: 0.3400\n",
            "Epoch 64/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.6429 - binary_accuracy: 0.6555 - val_loss: 0.8551 - val_binary_accuracy: 0.3400\n",
            "Epoch 65/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.6428 - binary_accuracy: 0.6555 - val_loss: 0.8563 - val_binary_accuracy: 0.3400\n",
            "Epoch 66/500\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.6427 - binary_accuracy: 0.6555 - val_loss: 0.8542 - val_binary_accuracy: 0.3400\n",
            "Epoch 67/500\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6422 - binary_accuracy: 0.6555 - val_loss: 0.8540 - val_binary_accuracy: 0.3400\n",
            "Epoch 68/500\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.6421 - binary_accuracy: 0.6555 - val_loss: 0.8558 - val_binary_accuracy: 0.3400\n",
            "Epoch 69/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.6421 - binary_accuracy: 0.6555 - val_loss: 0.8517 - val_binary_accuracy: 0.3400\n",
            "Epoch 70/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6419 - binary_accuracy: 0.6555 - val_loss: 0.8549 - val_binary_accuracy: 0.3400\n",
            "Epoch 71/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6418 - binary_accuracy: 0.6555 - val_loss: 0.8530 - val_binary_accuracy: 0.3400\n",
            "Epoch 72/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6414 - binary_accuracy: 0.6555 - val_loss: 0.8578 - val_binary_accuracy: 0.3400\n",
            "Epoch 73/500\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6412 - binary_accuracy: 0.6555 - val_loss: 0.8543 - val_binary_accuracy: 0.3400\n",
            "Epoch 74/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6410 - binary_accuracy: 0.6555 - val_loss: 0.8556 - val_binary_accuracy: 0.3400\n",
            "Epoch 75/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6407 - binary_accuracy: 0.6555 - val_loss: 0.8563 - val_binary_accuracy: 0.3400\n",
            "Epoch 76/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6404 - binary_accuracy: 0.6555 - val_loss: 0.8554 - val_binary_accuracy: 0.3400\n",
            "Epoch 77/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6402 - binary_accuracy: 0.6555 - val_loss: 0.8562 - val_binary_accuracy: 0.3400\n",
            "Epoch 78/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6400 - binary_accuracy: 0.6555 - val_loss: 0.8555 - val_binary_accuracy: 0.3400\n",
            "Epoch 79/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6399 - binary_accuracy: 0.6555 - val_loss: 0.8579 - val_binary_accuracy: 0.3400\n",
            "Epoch 80/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6406 - binary_accuracy: 0.6555 - val_loss: 0.8547 - val_binary_accuracy: 0.3400\n",
            "Epoch 81/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6394 - binary_accuracy: 0.6555 - val_loss: 0.8568 - val_binary_accuracy: 0.3400\n",
            "Epoch 82/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6396 - binary_accuracy: 0.6555 - val_loss: 0.8576 - val_binary_accuracy: 0.3400\n",
            "Epoch 83/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6389 - binary_accuracy: 0.6555 - val_loss: 0.8578 - val_binary_accuracy: 0.3400\n",
            "Epoch 84/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.6387 - binary_accuracy: 0.6555 - val_loss: 0.8580 - val_binary_accuracy: 0.3400\n",
            "Epoch 85/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.6386 - binary_accuracy: 0.6555 - val_loss: 0.8579 - val_binary_accuracy: 0.3400\n",
            "Epoch 86/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6385 - binary_accuracy: 0.6555 - val_loss: 0.8563 - val_binary_accuracy: 0.3400\n",
            "Epoch 87/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6382 - binary_accuracy: 0.6555 - val_loss: 0.8583 - val_binary_accuracy: 0.3400\n",
            "Epoch 88/500\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.6378 - binary_accuracy: 0.6555 - val_loss: 0.8576 - val_binary_accuracy: 0.3400\n",
            "Epoch 89/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6376 - binary_accuracy: 0.6555 - val_loss: 0.8553 - val_binary_accuracy: 0.3400\n",
            "Epoch 90/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6374 - binary_accuracy: 0.6555 - val_loss: 0.8556 - val_binary_accuracy: 0.3400\n",
            "Epoch 91/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6372 - binary_accuracy: 0.6555 - val_loss: 0.8580 - val_binary_accuracy: 0.3400\n",
            "Epoch 92/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6371 - binary_accuracy: 0.6555 - val_loss: 0.8613 - val_binary_accuracy: 0.3400\n",
            "Epoch 93/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6375 - binary_accuracy: 0.6555 - val_loss: 0.8613 - val_binary_accuracy: 0.3400\n",
            "Epoch 94/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6365 - binary_accuracy: 0.6555 - val_loss: 0.8603 - val_binary_accuracy: 0.3400\n",
            "Epoch 95/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6365 - binary_accuracy: 0.6555 - val_loss: 0.8576 - val_binary_accuracy: 0.3400\n",
            "Epoch 96/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6360 - binary_accuracy: 0.6555 - val_loss: 0.8598 - val_binary_accuracy: 0.3400\n",
            "Epoch 97/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6360 - binary_accuracy: 0.6555 - val_loss: 0.8584 - val_binary_accuracy: 0.3400\n",
            "Epoch 98/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6355 - binary_accuracy: 0.6555 - val_loss: 0.8607 - val_binary_accuracy: 0.3400\n",
            "Epoch 99/500\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6352 - binary_accuracy: 0.6555 - val_loss: 0.8581 - val_binary_accuracy: 0.3400\n",
            "Epoch 100/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6357 - binary_accuracy: 0.6555 - val_loss: 0.8606 - val_binary_accuracy: 0.3400\n",
            "Epoch 101/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6349 - binary_accuracy: 0.6555 - val_loss: 0.8595 - val_binary_accuracy: 0.3400\n",
            "Epoch 102/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6346 - binary_accuracy: 0.6555 - val_loss: 0.8609 - val_binary_accuracy: 0.3400\n",
            "Epoch 103/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6344 - binary_accuracy: 0.6555 - val_loss: 0.8570 - val_binary_accuracy: 0.3400\n",
            "Epoch 104/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6344 - binary_accuracy: 0.6555 - val_loss: 0.8570 - val_binary_accuracy: 0.3400\n",
            "Epoch 105/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6341 - binary_accuracy: 0.6555 - val_loss: 0.8564 - val_binary_accuracy: 0.3400\n",
            "Epoch 106/500\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.6340 - binary_accuracy: 0.6555 - val_loss: 0.8574 - val_binary_accuracy: 0.3400\n",
            "Epoch 107/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6340 - binary_accuracy: 0.6555 - val_loss: 0.8538 - val_binary_accuracy: 0.3400\n",
            "Epoch 108/500\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6333 - binary_accuracy: 0.6555 - val_loss: 0.8569 - val_binary_accuracy: 0.3400\n",
            "Epoch 109/500\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.6330 - binary_accuracy: 0.6555 - val_loss: 0.8589 - val_binary_accuracy: 0.3400\n",
            "Epoch 110/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.6329 - binary_accuracy: 0.6555 - val_loss: 0.8564 - val_binary_accuracy: 0.3400\n",
            "Epoch 111/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6326 - binary_accuracy: 0.6555 - val_loss: 0.8554 - val_binary_accuracy: 0.3400\n",
            "Epoch 112/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6324 - binary_accuracy: 0.6555 - val_loss: 0.8568 - val_binary_accuracy: 0.3400\n",
            "Epoch 113/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.6320 - binary_accuracy: 0.6555 - val_loss: 0.8580 - val_binary_accuracy: 0.3400\n",
            "Epoch 114/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6324 - binary_accuracy: 0.6555 - val_loss: 0.8590 - val_binary_accuracy: 0.3400\n",
            "Epoch 115/500\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.6317 - binary_accuracy: 0.6555 - val_loss: 0.8572 - val_binary_accuracy: 0.3400\n",
            "Epoch 116/500\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.6312 - binary_accuracy: 0.6555 - val_loss: 0.8551 - val_binary_accuracy: 0.3400\n",
            "Epoch 117/500\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6312 - binary_accuracy: 0.6555 - val_loss: 0.8556 - val_binary_accuracy: 0.3400\n",
            "Epoch 118/500\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6307 - binary_accuracy: 0.6555 - val_loss: 0.8558 - val_binary_accuracy: 0.3400\n",
            "Epoch 119/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6306 - binary_accuracy: 0.6555 - val_loss: 0.8534 - val_binary_accuracy: 0.3400\n",
            "Epoch 120/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6302 - binary_accuracy: 0.6555 - val_loss: 0.8544 - val_binary_accuracy: 0.3400\n",
            "Epoch 121/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6305 - binary_accuracy: 0.6555 - val_loss: 0.8523 - val_binary_accuracy: 0.3400\n",
            "Epoch 122/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.6298 - binary_accuracy: 0.6555 - val_loss: 0.8529 - val_binary_accuracy: 0.3400\n",
            "Epoch 123/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6294 - binary_accuracy: 0.6555 - val_loss: 0.8543 - val_binary_accuracy: 0.3400\n",
            "Epoch 124/500\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6298 - binary_accuracy: 0.6555 - val_loss: 0.8560 - val_binary_accuracy: 0.3400\n",
            "Epoch 125/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6290 - binary_accuracy: 0.6555 - val_loss: 0.8545 - val_binary_accuracy: 0.3400\n",
            "Epoch 126/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6286 - binary_accuracy: 0.6555 - val_loss: 0.8547 - val_binary_accuracy: 0.3400\n",
            "Epoch 127/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6287 - binary_accuracy: 0.6555 - val_loss: 0.8540 - val_binary_accuracy: 0.3400\n",
            "Epoch 128/500\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6281 - binary_accuracy: 0.6555 - val_loss: 0.8541 - val_binary_accuracy: 0.3400\n",
            "Epoch 129/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6283 - binary_accuracy: 0.6555 - val_loss: 0.8512 - val_binary_accuracy: 0.3400\n",
            "Epoch 130/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6279 - binary_accuracy: 0.6555 - val_loss: 0.8532 - val_binary_accuracy: 0.3400\n",
            "Epoch 131/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6275 - binary_accuracy: 0.6555 - val_loss: 0.8511 - val_binary_accuracy: 0.3400\n",
            "Epoch 132/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6277 - binary_accuracy: 0.6555 - val_loss: 0.8515 - val_binary_accuracy: 0.3400\n",
            "Epoch 133/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6274 - binary_accuracy: 0.6555 - val_loss: 0.8506 - val_binary_accuracy: 0.3400\n",
            "Epoch 134/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6271 - binary_accuracy: 0.6555 - val_loss: 0.8510 - val_binary_accuracy: 0.3400\n",
            "Epoch 135/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6268 - binary_accuracy: 0.6555 - val_loss: 0.8534 - val_binary_accuracy: 0.3400\n",
            "Epoch 136/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6265 - binary_accuracy: 0.6555 - val_loss: 0.8554 - val_binary_accuracy: 0.3400\n",
            "Epoch 137/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6261 - binary_accuracy: 0.6555 - val_loss: 0.8564 - val_binary_accuracy: 0.3400\n",
            "Epoch 138/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6258 - binary_accuracy: 0.6555 - val_loss: 0.8549 - val_binary_accuracy: 0.3400\n",
            "Epoch 139/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6257 - binary_accuracy: 0.6555 - val_loss: 0.8567 - val_binary_accuracy: 0.3400\n",
            "Epoch 140/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6255 - binary_accuracy: 0.6555 - val_loss: 0.8576 - val_binary_accuracy: 0.3400\n",
            "Epoch 141/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6257 - binary_accuracy: 0.6555 - val_loss: 0.8585 - val_binary_accuracy: 0.3400\n",
            "Epoch 142/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6251 - binary_accuracy: 0.6555 - val_loss: 0.8585 - val_binary_accuracy: 0.3400\n",
            "Epoch 143/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6247 - binary_accuracy: 0.6555 - val_loss: 0.8578 - val_binary_accuracy: 0.3400\n",
            "Epoch 144/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6246 - binary_accuracy: 0.6555 - val_loss: 0.8573 - val_binary_accuracy: 0.3400\n",
            "Epoch 145/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6249 - binary_accuracy: 0.6555 - val_loss: 0.8572 - val_binary_accuracy: 0.3400\n",
            "Epoch 146/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6242 - binary_accuracy: 0.6555 - val_loss: 0.8580 - val_binary_accuracy: 0.3400\n",
            "Epoch 147/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6238 - binary_accuracy: 0.6555 - val_loss: 0.8597 - val_binary_accuracy: 0.3400\n",
            "Epoch 148/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6233 - binary_accuracy: 0.6555 - val_loss: 0.8591 - val_binary_accuracy: 0.3400\n",
            "Epoch 149/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6232 - binary_accuracy: 0.6555 - val_loss: 0.8593 - val_binary_accuracy: 0.3400\n",
            "Epoch 150/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6227 - binary_accuracy: 0.6555 - val_loss: 0.8588 - val_binary_accuracy: 0.3400\n",
            "Epoch 151/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6226 - binary_accuracy: 0.6555 - val_loss: 0.8613 - val_binary_accuracy: 0.3400\n",
            "Epoch 152/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6224 - binary_accuracy: 0.6555 - val_loss: 0.8600 - val_binary_accuracy: 0.3400\n",
            "Epoch 153/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6226 - binary_accuracy: 0.6555 - val_loss: 0.8563 - val_binary_accuracy: 0.3400\n",
            "Epoch 154/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6218 - binary_accuracy: 0.6555 - val_loss: 0.8538 - val_binary_accuracy: 0.3400\n",
            "Epoch 155/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6215 - binary_accuracy: 0.6555 - val_loss: 0.8527 - val_binary_accuracy: 0.3400\n",
            "Epoch 156/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6217 - binary_accuracy: 0.6555 - val_loss: 0.8507 - val_binary_accuracy: 0.3400\n",
            "Epoch 157/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6209 - binary_accuracy: 0.6555 - val_loss: 0.8504 - val_binary_accuracy: 0.3400\n",
            "Epoch 158/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6208 - binary_accuracy: 0.6555 - val_loss: 0.8502 - val_binary_accuracy: 0.3400\n",
            "Epoch 159/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6206 - binary_accuracy: 0.6555 - val_loss: 0.8526 - val_binary_accuracy: 0.3400\n",
            "Epoch 160/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6203 - binary_accuracy: 0.6555 - val_loss: 0.8502 - val_binary_accuracy: 0.3400\n",
            "Epoch 161/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6200 - binary_accuracy: 0.6555 - val_loss: 0.8537 - val_binary_accuracy: 0.3400\n",
            "Epoch 162/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6195 - binary_accuracy: 0.6555 - val_loss: 0.8511 - val_binary_accuracy: 0.3400\n",
            "Epoch 163/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6191 - binary_accuracy: 0.6555 - val_loss: 0.8513 - val_binary_accuracy: 0.3400\n",
            "Epoch 164/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6193 - binary_accuracy: 0.6555 - val_loss: 0.8532 - val_binary_accuracy: 0.3400\n",
            "Epoch 165/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6188 - binary_accuracy: 0.6555 - val_loss: 0.8519 - val_binary_accuracy: 0.3400\n",
            "Epoch 166/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6186 - binary_accuracy: 0.6555 - val_loss: 0.8519 - val_binary_accuracy: 0.3400\n",
            "Epoch 167/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6181 - binary_accuracy: 0.6555 - val_loss: 0.8541 - val_binary_accuracy: 0.3400\n",
            "Epoch 168/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6183 - binary_accuracy: 0.6555 - val_loss: 0.8542 - val_binary_accuracy: 0.3400\n",
            "Epoch 169/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6179 - binary_accuracy: 0.6555 - val_loss: 0.8587 - val_binary_accuracy: 0.3400\n",
            "Epoch 170/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6173 - binary_accuracy: 0.6555 - val_loss: 0.8564 - val_binary_accuracy: 0.3400\n",
            "Epoch 171/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6169 - binary_accuracy: 0.6555 - val_loss: 0.8545 - val_binary_accuracy: 0.3400\n",
            "Epoch 172/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6165 - binary_accuracy: 0.6555 - val_loss: 0.8528 - val_binary_accuracy: 0.3400\n",
            "Epoch 173/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6165 - binary_accuracy: 0.6555 - val_loss: 0.8517 - val_binary_accuracy: 0.3400\n",
            "Epoch 174/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6159 - binary_accuracy: 0.6555 - val_loss: 0.8534 - val_binary_accuracy: 0.3400\n",
            "Epoch 175/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6161 - binary_accuracy: 0.6555 - val_loss: 0.8511 - val_binary_accuracy: 0.3400\n",
            "Epoch 176/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6154 - binary_accuracy: 0.6555 - val_loss: 0.8512 - val_binary_accuracy: 0.3400\n",
            "Epoch 177/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6153 - binary_accuracy: 0.6555 - val_loss: 0.8519 - val_binary_accuracy: 0.3400\n",
            "Epoch 178/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6148 - binary_accuracy: 0.6555 - val_loss: 0.8543 - val_binary_accuracy: 0.3400\n",
            "Epoch 179/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6146 - binary_accuracy: 0.6555 - val_loss: 0.8533 - val_binary_accuracy: 0.3400\n",
            "Epoch 180/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6146 - binary_accuracy: 0.6555 - val_loss: 0.8497 - val_binary_accuracy: 0.3400\n",
            "Epoch 181/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6141 - binary_accuracy: 0.6555 - val_loss: 0.8486 - val_binary_accuracy: 0.3400\n",
            "Epoch 182/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6138 - binary_accuracy: 0.6555 - val_loss: 0.8480 - val_binary_accuracy: 0.3400\n",
            "Epoch 183/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6132 - binary_accuracy: 0.6555 - val_loss: 0.8472 - val_binary_accuracy: 0.3400\n",
            "Epoch 184/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6132 - binary_accuracy: 0.6555 - val_loss: 0.8475 - val_binary_accuracy: 0.3400\n",
            "Epoch 185/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6131 - binary_accuracy: 0.6555 - val_loss: 0.8471 - val_binary_accuracy: 0.3400\n",
            "Epoch 186/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6127 - binary_accuracy: 0.6555 - val_loss: 0.8453 - val_binary_accuracy: 0.3400\n",
            "Epoch 187/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6119 - binary_accuracy: 0.6555 - val_loss: 0.8428 - val_binary_accuracy: 0.3400\n",
            "Epoch 188/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6116 - binary_accuracy: 0.6555 - val_loss: 0.8428 - val_binary_accuracy: 0.3400\n",
            "Epoch 189/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6115 - binary_accuracy: 0.6555 - val_loss: 0.8446 - val_binary_accuracy: 0.3400\n",
            "Epoch 190/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6114 - binary_accuracy: 0.6555 - val_loss: 0.8425 - val_binary_accuracy: 0.3400\n",
            "Epoch 191/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6107 - binary_accuracy: 0.6555 - val_loss: 0.8457 - val_binary_accuracy: 0.3400\n",
            "Epoch 192/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6106 - binary_accuracy: 0.6555 - val_loss: 0.8485 - val_binary_accuracy: 0.3400\n",
            "Epoch 193/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6102 - binary_accuracy: 0.6555 - val_loss: 0.8452 - val_binary_accuracy: 0.3400\n",
            "Epoch 194/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6096 - binary_accuracy: 0.6555 - val_loss: 0.8470 - val_binary_accuracy: 0.3400\n",
            "Epoch 195/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6093 - binary_accuracy: 0.6555 - val_loss: 0.8447 - val_binary_accuracy: 0.3400\n",
            "Epoch 196/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6090 - binary_accuracy: 0.6555 - val_loss: 0.8438 - val_binary_accuracy: 0.3400\n",
            "Epoch 197/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6083 - binary_accuracy: 0.6555 - val_loss: 0.8456 - val_binary_accuracy: 0.3400\n",
            "Epoch 198/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6078 - binary_accuracy: 0.6555 - val_loss: 0.8430 - val_binary_accuracy: 0.3400\n",
            "Epoch 199/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6082 - binary_accuracy: 0.6555 - val_loss: 0.8437 - val_binary_accuracy: 0.3400\n",
            "Epoch 200/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6079 - binary_accuracy: 0.6555 - val_loss: 0.8413 - val_binary_accuracy: 0.3400\n",
            "Epoch 201/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6078 - binary_accuracy: 0.6555 - val_loss: 0.8434 - val_binary_accuracy: 0.3400\n",
            "Epoch 202/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6066 - binary_accuracy: 0.6555 - val_loss: 0.8420 - val_binary_accuracy: 0.3400\n",
            "Epoch 203/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6060 - binary_accuracy: 0.6555 - val_loss: 0.8398 - val_binary_accuracy: 0.3400\n",
            "Epoch 204/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6064 - binary_accuracy: 0.6555 - val_loss: 0.8416 - val_binary_accuracy: 0.3400\n",
            "Epoch 205/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6061 - binary_accuracy: 0.6555 - val_loss: 0.8382 - val_binary_accuracy: 0.3400\n",
            "Epoch 206/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6058 - binary_accuracy: 0.6555 - val_loss: 0.8374 - val_binary_accuracy: 0.3400\n",
            "Epoch 207/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6055 - binary_accuracy: 0.6555 - val_loss: 0.8360 - val_binary_accuracy: 0.3400\n",
            "Epoch 208/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6048 - binary_accuracy: 0.6555 - val_loss: 0.8372 - val_binary_accuracy: 0.3400\n",
            "Epoch 209/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6051 - binary_accuracy: 0.6555 - val_loss: 0.8391 - val_binary_accuracy: 0.3400\n",
            "Epoch 210/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6043 - binary_accuracy: 0.6555 - val_loss: 0.8386 - val_binary_accuracy: 0.3400\n",
            "Epoch 211/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6034 - binary_accuracy: 0.6555 - val_loss: 0.8360 - val_binary_accuracy: 0.3400\n",
            "Epoch 212/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6029 - binary_accuracy: 0.6555 - val_loss: 0.8393 - val_binary_accuracy: 0.3400\n",
            "Epoch 213/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6028 - binary_accuracy: 0.6555 - val_loss: 0.8376 - val_binary_accuracy: 0.3400\n",
            "Epoch 214/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6022 - binary_accuracy: 0.6555 - val_loss: 0.8412 - val_binary_accuracy: 0.3400\n",
            "Epoch 215/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6026 - binary_accuracy: 0.6555 - val_loss: 0.8321 - val_binary_accuracy: 0.3400\n",
            "Epoch 216/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6020 - binary_accuracy: 0.6555 - val_loss: 0.8354 - val_binary_accuracy: 0.3400\n",
            "Epoch 217/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6013 - binary_accuracy: 0.6555 - val_loss: 0.8361 - val_binary_accuracy: 0.3400\n",
            "Epoch 218/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6008 - binary_accuracy: 0.6555 - val_loss: 0.8382 - val_binary_accuracy: 0.3400\n",
            "Epoch 219/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6007 - binary_accuracy: 0.6555 - val_loss: 0.8365 - val_binary_accuracy: 0.3400\n",
            "Epoch 220/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5999 - binary_accuracy: 0.6555 - val_loss: 0.8384 - val_binary_accuracy: 0.3400\n",
            "Epoch 221/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6001 - binary_accuracy: 0.6555 - val_loss: 0.8409 - val_binary_accuracy: 0.3400\n",
            "Epoch 222/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5996 - binary_accuracy: 0.6555 - val_loss: 0.8429 - val_binary_accuracy: 0.3400\n",
            "Epoch 223/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5994 - binary_accuracy: 0.6555 - val_loss: 0.8368 - val_binary_accuracy: 0.3400\n",
            "Epoch 224/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5985 - binary_accuracy: 0.6555 - val_loss: 0.8375 - val_binary_accuracy: 0.3400\n",
            "Epoch 225/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5985 - binary_accuracy: 0.6555 - val_loss: 0.8371 - val_binary_accuracy: 0.3400\n",
            "Epoch 226/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5978 - binary_accuracy: 0.6555 - val_loss: 0.8340 - val_binary_accuracy: 0.3400\n",
            "Epoch 227/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5977 - binary_accuracy: 0.6555 - val_loss: 0.8351 - val_binary_accuracy: 0.3400\n",
            "Epoch 228/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5978 - binary_accuracy: 0.6555 - val_loss: 0.8335 - val_binary_accuracy: 0.3400\n",
            "Epoch 229/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5968 - binary_accuracy: 0.6603 - val_loss: 0.8362 - val_binary_accuracy: 0.3400\n",
            "Epoch 230/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5962 - binary_accuracy: 0.6555 - val_loss: 0.8361 - val_binary_accuracy: 0.3400\n",
            "Epoch 231/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5963 - binary_accuracy: 0.6555 - val_loss: 0.8364 - val_binary_accuracy: 0.3400\n",
            "Epoch 232/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5958 - binary_accuracy: 0.6603 - val_loss: 0.8395 - val_binary_accuracy: 0.3400\n",
            "Epoch 233/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5951 - binary_accuracy: 0.6555 - val_loss: 0.8407 - val_binary_accuracy: 0.3400\n",
            "Epoch 234/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5951 - binary_accuracy: 0.6555 - val_loss: 0.8304 - val_binary_accuracy: 0.3400\n",
            "Epoch 235/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5948 - binary_accuracy: 0.6603 - val_loss: 0.8304 - val_binary_accuracy: 0.3400\n",
            "Epoch 236/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5943 - binary_accuracy: 0.6603 - val_loss: 0.8282 - val_binary_accuracy: 0.3400\n",
            "Epoch 237/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5935 - binary_accuracy: 0.6603 - val_loss: 0.8291 - val_binary_accuracy: 0.3400\n",
            "Epoch 238/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5928 - binary_accuracy: 0.6603 - val_loss: 0.8268 - val_binary_accuracy: 0.3400\n",
            "Epoch 239/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.5924 - binary_accuracy: 0.6603 - val_loss: 0.8296 - val_binary_accuracy: 0.3400\n",
            "Epoch 240/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5924 - binary_accuracy: 0.6603 - val_loss: 0.8303 - val_binary_accuracy: 0.3400\n",
            "Epoch 241/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5921 - binary_accuracy: 0.6603 - val_loss: 0.8364 - val_binary_accuracy: 0.3400\n",
            "Epoch 242/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5920 - binary_accuracy: 0.6603 - val_loss: 0.8299 - val_binary_accuracy: 0.3400\n",
            "Epoch 243/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5910 - binary_accuracy: 0.6603 - val_loss: 0.8296 - val_binary_accuracy: 0.3400\n",
            "Epoch 244/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5905 - binary_accuracy: 0.6603 - val_loss: 0.8295 - val_binary_accuracy: 0.3400\n",
            "Epoch 245/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5903 - binary_accuracy: 0.6603 - val_loss: 0.8287 - val_binary_accuracy: 0.3400\n",
            "Epoch 246/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5896 - binary_accuracy: 0.6603 - val_loss: 0.8249 - val_binary_accuracy: 0.3400\n",
            "Epoch 247/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.5889 - binary_accuracy: 0.6603 - val_loss: 0.8251 - val_binary_accuracy: 0.3400\n",
            "Epoch 248/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5892 - binary_accuracy: 0.6603 - val_loss: 0.8292 - val_binary_accuracy: 0.3400\n",
            "Epoch 249/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5882 - binary_accuracy: 0.6603 - val_loss: 0.8267 - val_binary_accuracy: 0.3400\n",
            "Epoch 250/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5881 - binary_accuracy: 0.6603 - val_loss: 0.8199 - val_binary_accuracy: 0.3400\n",
            "Epoch 251/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5882 - binary_accuracy: 0.6603 - val_loss: 0.8236 - val_binary_accuracy: 0.3400\n",
            "Epoch 252/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5867 - binary_accuracy: 0.6603 - val_loss: 0.8252 - val_binary_accuracy: 0.3400\n",
            "Epoch 253/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5871 - binary_accuracy: 0.6603 - val_loss: 0.8192 - val_binary_accuracy: 0.3400\n",
            "Epoch 254/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5859 - binary_accuracy: 0.6603 - val_loss: 0.8170 - val_binary_accuracy: 0.3400\n",
            "Epoch 255/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5861 - binary_accuracy: 0.6603 - val_loss: 0.8180 - val_binary_accuracy: 0.3400\n",
            "Epoch 256/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5854 - binary_accuracy: 0.6603 - val_loss: 0.8257 - val_binary_accuracy: 0.3400\n",
            "Epoch 257/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5845 - binary_accuracy: 0.6603 - val_loss: 0.8258 - val_binary_accuracy: 0.3400\n",
            "Epoch 258/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5843 - binary_accuracy: 0.6603 - val_loss: 0.8284 - val_binary_accuracy: 0.3400\n",
            "Epoch 259/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5838 - binary_accuracy: 0.6603 - val_loss: 0.8253 - val_binary_accuracy: 0.3400\n",
            "Epoch 260/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5833 - binary_accuracy: 0.6603 - val_loss: 0.8231 - val_binary_accuracy: 0.3400\n",
            "Epoch 261/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5825 - binary_accuracy: 0.6603 - val_loss: 0.8184 - val_binary_accuracy: 0.3400\n",
            "Epoch 262/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5826 - binary_accuracy: 0.6603 - val_loss: 0.8201 - val_binary_accuracy: 0.3400\n",
            "Epoch 263/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5821 - binary_accuracy: 0.6603 - val_loss: 0.8191 - val_binary_accuracy: 0.3400\n",
            "Epoch 264/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5810 - binary_accuracy: 0.6603 - val_loss: 0.8169 - val_binary_accuracy: 0.3400\n",
            "Epoch 265/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5807 - binary_accuracy: 0.6603 - val_loss: 0.8189 - val_binary_accuracy: 0.3400\n",
            "Epoch 266/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5806 - binary_accuracy: 0.6603 - val_loss: 0.8213 - val_binary_accuracy: 0.3400\n",
            "Epoch 267/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5798 - binary_accuracy: 0.6603 - val_loss: 0.8114 - val_binary_accuracy: 0.3400\n",
            "Epoch 268/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5791 - binary_accuracy: 0.6603 - val_loss: 0.8134 - val_binary_accuracy: 0.3400\n",
            "Epoch 269/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5796 - binary_accuracy: 0.6603 - val_loss: 0.8122 - val_binary_accuracy: 0.3400\n",
            "Epoch 270/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5784 - binary_accuracy: 0.6603 - val_loss: 0.8140 - val_binary_accuracy: 0.3400\n",
            "Epoch 271/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5775 - binary_accuracy: 0.6603 - val_loss: 0.8088 - val_binary_accuracy: 0.3400\n",
            "Epoch 272/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5774 - binary_accuracy: 0.6603 - val_loss: 0.8131 - val_binary_accuracy: 0.3400\n",
            "Epoch 273/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5771 - binary_accuracy: 0.6603 - val_loss: 0.8060 - val_binary_accuracy: 0.3400\n",
            "Epoch 274/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5768 - binary_accuracy: 0.6603 - val_loss: 0.8103 - val_binary_accuracy: 0.3400\n",
            "Epoch 275/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5764 - binary_accuracy: 0.6603 - val_loss: 0.8111 - val_binary_accuracy: 0.3400\n",
            "Epoch 276/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5751 - binary_accuracy: 0.6603 - val_loss: 0.8130 - val_binary_accuracy: 0.3400\n",
            "Epoch 277/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5749 - binary_accuracy: 0.6603 - val_loss: 0.8129 - val_binary_accuracy: 0.3400\n",
            "Epoch 278/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5750 - binary_accuracy: 0.6603 - val_loss: 0.8089 - val_binary_accuracy: 0.3400\n",
            "Epoch 279/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5741 - binary_accuracy: 0.6603 - val_loss: 0.8045 - val_binary_accuracy: 0.3400\n",
            "Epoch 280/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5737 - binary_accuracy: 0.6603 - val_loss: 0.8049 - val_binary_accuracy: 0.3400\n",
            "Epoch 281/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5726 - binary_accuracy: 0.6603 - val_loss: 0.8067 - val_binary_accuracy: 0.3400\n",
            "Epoch 282/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5720 - binary_accuracy: 0.6603 - val_loss: 0.8040 - val_binary_accuracy: 0.3400\n",
            "Epoch 283/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5719 - binary_accuracy: 0.6603 - val_loss: 0.8010 - val_binary_accuracy: 0.3400\n",
            "Epoch 284/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5709 - binary_accuracy: 0.6603 - val_loss: 0.8066 - val_binary_accuracy: 0.3400\n",
            "Epoch 285/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5708 - binary_accuracy: 0.6603 - val_loss: 0.8072 - val_binary_accuracy: 0.3400\n",
            "Epoch 286/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5698 - binary_accuracy: 0.6603 - val_loss: 0.8075 - val_binary_accuracy: 0.3400\n",
            "Epoch 287/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5705 - binary_accuracy: 0.6603 - val_loss: 0.8081 - val_binary_accuracy: 0.3400\n",
            "Epoch 288/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5695 - binary_accuracy: 0.6603 - val_loss: 0.8034 - val_binary_accuracy: 0.3400\n",
            "Epoch 289/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5687 - binary_accuracy: 0.6603 - val_loss: 0.8021 - val_binary_accuracy: 0.3600\n",
            "Epoch 290/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5694 - binary_accuracy: 0.6603 - val_loss: 0.7929 - val_binary_accuracy: 0.3600\n",
            "Epoch 291/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5678 - binary_accuracy: 0.6603 - val_loss: 0.7933 - val_binary_accuracy: 0.3600\n",
            "Epoch 292/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5665 - binary_accuracy: 0.6699 - val_loss: 0.7937 - val_binary_accuracy: 0.3600\n",
            "Epoch 293/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5670 - binary_accuracy: 0.6746 - val_loss: 0.7907 - val_binary_accuracy: 0.3600\n",
            "Epoch 294/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5658 - binary_accuracy: 0.6746 - val_loss: 0.7920 - val_binary_accuracy: 0.3600\n",
            "Epoch 295/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5646 - binary_accuracy: 0.6794 - val_loss: 0.7891 - val_binary_accuracy: 0.3600\n",
            "Epoch 296/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5642 - binary_accuracy: 0.6746 - val_loss: 0.7835 - val_binary_accuracy: 0.3600\n",
            "Epoch 297/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5633 - binary_accuracy: 0.6842 - val_loss: 0.7888 - val_binary_accuracy: 0.3600\n",
            "Epoch 298/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5624 - binary_accuracy: 0.6890 - val_loss: 0.7913 - val_binary_accuracy: 0.3600\n",
            "Epoch 299/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5618 - binary_accuracy: 0.6794 - val_loss: 0.7835 - val_binary_accuracy: 0.3600\n",
            "Epoch 300/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5606 - binary_accuracy: 0.6890 - val_loss: 0.7848 - val_binary_accuracy: 0.3800\n",
            "Epoch 301/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5603 - binary_accuracy: 0.6938 - val_loss: 0.7845 - val_binary_accuracy: 0.3800\n",
            "Epoch 302/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5588 - binary_accuracy: 0.7033 - val_loss: 0.7748 - val_binary_accuracy: 0.3800\n",
            "Epoch 303/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5582 - binary_accuracy: 0.7129 - val_loss: 0.7768 - val_binary_accuracy: 0.4000\n",
            "Epoch 304/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5576 - binary_accuracy: 0.7081 - val_loss: 0.7639 - val_binary_accuracy: 0.4200\n",
            "Epoch 305/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5561 - binary_accuracy: 0.7273 - val_loss: 0.7675 - val_binary_accuracy: 0.4200\n",
            "Epoch 306/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5541 - binary_accuracy: 0.7273 - val_loss: 0.7636 - val_binary_accuracy: 0.4200\n",
            "Epoch 307/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5529 - binary_accuracy: 0.7177 - val_loss: 0.7552 - val_binary_accuracy: 0.4400\n",
            "Epoch 308/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5514 - binary_accuracy: 0.7273 - val_loss: 0.7489 - val_binary_accuracy: 0.4200\n",
            "Epoch 309/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5486 - binary_accuracy: 0.7368 - val_loss: 0.7291 - val_binary_accuracy: 0.4000\n",
            "Epoch 310/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5479 - binary_accuracy: 0.7416 - val_loss: 0.7313 - val_binary_accuracy: 0.4200\n",
            "Epoch 311/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5461 - binary_accuracy: 0.7368 - val_loss: 0.7266 - val_binary_accuracy: 0.4200\n",
            "Epoch 312/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5438 - binary_accuracy: 0.7608 - val_loss: 0.7315 - val_binary_accuracy: 0.4200\n",
            "Epoch 313/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5421 - binary_accuracy: 0.7464 - val_loss: 0.7277 - val_binary_accuracy: 0.4200\n",
            "Epoch 314/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5407 - binary_accuracy: 0.7656 - val_loss: 0.7452 - val_binary_accuracy: 0.4200\n",
            "Epoch 315/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5385 - binary_accuracy: 0.7703 - val_loss: 0.7544 - val_binary_accuracy: 0.4200\n",
            "Epoch 316/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5371 - binary_accuracy: 0.7608 - val_loss: 0.7495 - val_binary_accuracy: 0.4200\n",
            "Epoch 317/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5348 - binary_accuracy: 0.7703 - val_loss: 0.7378 - val_binary_accuracy: 0.4200\n",
            "Epoch 318/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5333 - binary_accuracy: 0.7608 - val_loss: 0.7119 - val_binary_accuracy: 0.5000\n",
            "Epoch 319/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5329 - binary_accuracy: 0.7943 - val_loss: 0.7298 - val_binary_accuracy: 0.4400\n",
            "Epoch 320/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5305 - binary_accuracy: 0.7847 - val_loss: 0.7321 - val_binary_accuracy: 0.4600\n",
            "Epoch 321/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5272 - binary_accuracy: 0.7943 - val_loss: 0.7218 - val_binary_accuracy: 0.5000\n",
            "Epoch 322/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5261 - binary_accuracy: 0.7990 - val_loss: 0.7221 - val_binary_accuracy: 0.5000\n",
            "Epoch 323/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5247 - binary_accuracy: 0.8086 - val_loss: 0.7179 - val_binary_accuracy: 0.4800\n",
            "Epoch 324/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5223 - binary_accuracy: 0.8325 - val_loss: 0.7517 - val_binary_accuracy: 0.4600\n",
            "Epoch 325/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5215 - binary_accuracy: 0.8038 - val_loss: 0.7667 - val_binary_accuracy: 0.4600\n",
            "Epoch 326/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5198 - binary_accuracy: 0.7990 - val_loss: 0.7583 - val_binary_accuracy: 0.4600\n",
            "Epoch 327/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5167 - binary_accuracy: 0.8182 - val_loss: 0.7503 - val_binary_accuracy: 0.4600\n",
            "Epoch 328/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5159 - binary_accuracy: 0.7943 - val_loss: 0.7317 - val_binary_accuracy: 0.4600\n",
            "Epoch 329/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5124 - binary_accuracy: 0.7943 - val_loss: 0.6820 - val_binary_accuracy: 0.5400\n",
            "Epoch 330/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5092 - binary_accuracy: 0.8325 - val_loss: 0.7700 - val_binary_accuracy: 0.4600\n",
            "Epoch 331/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5103 - binary_accuracy: 0.8086 - val_loss: 0.6772 - val_binary_accuracy: 0.5400\n",
            "Epoch 332/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5075 - binary_accuracy: 0.8230 - val_loss: 0.6930 - val_binary_accuracy: 0.5200\n",
            "Epoch 333/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5003 - binary_accuracy: 0.8325 - val_loss: 0.7045 - val_binary_accuracy: 0.5000\n",
            "Epoch 334/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4965 - binary_accuracy: 0.8325 - val_loss: 0.6889 - val_binary_accuracy: 0.5200\n",
            "Epoch 335/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4948 - binary_accuracy: 0.8421 - val_loss: 0.7392 - val_binary_accuracy: 0.5000\n",
            "Epoch 336/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4938 - binary_accuracy: 0.8134 - val_loss: 0.6930 - val_binary_accuracy: 0.5200\n",
            "Epoch 337/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4884 - binary_accuracy: 0.8182 - val_loss: 0.6922 - val_binary_accuracy: 0.5200\n",
            "Epoch 338/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4907 - binary_accuracy: 0.8325 - val_loss: 0.7180 - val_binary_accuracy: 0.5000\n",
            "Epoch 339/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4848 - binary_accuracy: 0.8134 - val_loss: 0.6144 - val_binary_accuracy: 0.7200\n",
            "Epoch 340/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4852 - binary_accuracy: 0.8421 - val_loss: 0.7006 - val_binary_accuracy: 0.5400\n",
            "Epoch 341/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4796 - binary_accuracy: 0.8469 - val_loss: 0.6559 - val_binary_accuracy: 0.5800\n",
            "Epoch 342/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4801 - binary_accuracy: 0.8421 - val_loss: 0.7028 - val_binary_accuracy: 0.5400\n",
            "Epoch 343/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4792 - binary_accuracy: 0.8469 - val_loss: 0.7139 - val_binary_accuracy: 0.5400\n",
            "Epoch 344/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4769 - binary_accuracy: 0.8278 - val_loss: 0.7001 - val_binary_accuracy: 0.5400\n",
            "Epoch 345/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4733 - binary_accuracy: 0.8469 - val_loss: 0.7115 - val_binary_accuracy: 0.5400\n",
            "Epoch 346/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4719 - binary_accuracy: 0.8517 - val_loss: 0.7302 - val_binary_accuracy: 0.5200\n",
            "Epoch 347/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4682 - binary_accuracy: 0.8373 - val_loss: 0.6901 - val_binary_accuracy: 0.5400\n",
            "Epoch 348/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4654 - binary_accuracy: 0.8612 - val_loss: 0.7025 - val_binary_accuracy: 0.5200\n",
            "Epoch 349/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4651 - binary_accuracy: 0.8469 - val_loss: 0.6570 - val_binary_accuracy: 0.5600\n",
            "Epoch 350/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4647 - binary_accuracy: 0.8517 - val_loss: 0.7103 - val_binary_accuracy: 0.5400\n",
            "Epoch 351/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4613 - binary_accuracy: 0.8421 - val_loss: 0.6543 - val_binary_accuracy: 0.6200\n",
            "Epoch 352/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4596 - binary_accuracy: 0.8565 - val_loss: 0.7507 - val_binary_accuracy: 0.5400\n",
            "Epoch 353/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4571 - binary_accuracy: 0.8325 - val_loss: 0.7215 - val_binary_accuracy: 0.5400\n",
            "Epoch 354/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4550 - binary_accuracy: 0.8708 - val_loss: 0.6936 - val_binary_accuracy: 0.5400\n",
            "Epoch 355/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4542 - binary_accuracy: 0.8756 - val_loss: 0.6882 - val_binary_accuracy: 0.5400\n",
            "Epoch 356/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4525 - binary_accuracy: 0.8565 - val_loss: 0.7144 - val_binary_accuracy: 0.5600\n",
            "Epoch 357/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4532 - binary_accuracy: 0.8469 - val_loss: 0.7218 - val_binary_accuracy: 0.5400\n",
            "Epoch 358/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4473 - binary_accuracy: 0.8278 - val_loss: 0.6304 - val_binary_accuracy: 0.6800\n",
            "Epoch 359/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.4472 - binary_accuracy: 0.8612 - val_loss: 0.6166 - val_binary_accuracy: 0.6800\n",
            "Epoch 360/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4524 - binary_accuracy: 0.8517 - val_loss: 0.6253 - val_binary_accuracy: 0.6800\n",
            "Epoch 361/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4464 - binary_accuracy: 0.8612 - val_loss: 0.5991 - val_binary_accuracy: 0.7400\n",
            "Epoch 362/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4440 - binary_accuracy: 0.8900 - val_loss: 0.7245 - val_binary_accuracy: 0.5200\n",
            "Epoch 363/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4430 - binary_accuracy: 0.8708 - val_loss: 0.6583 - val_binary_accuracy: 0.6000\n",
            "Epoch 364/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4392 - binary_accuracy: 0.8804 - val_loss: 0.7442 - val_binary_accuracy: 0.5400\n",
            "Epoch 365/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4455 - binary_accuracy: 0.8421 - val_loss: 0.6715 - val_binary_accuracy: 0.5600\n",
            "Epoch 366/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4353 - binary_accuracy: 0.8756 - val_loss: 0.6891 - val_binary_accuracy: 0.5400\n",
            "Epoch 367/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4354 - binary_accuracy: 0.8469 - val_loss: 0.6278 - val_binary_accuracy: 0.6600\n",
            "Epoch 368/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4332 - binary_accuracy: 0.8995 - val_loss: 0.7236 - val_binary_accuracy: 0.5200\n",
            "Epoch 369/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4349 - binary_accuracy: 0.8565 - val_loss: 0.6794 - val_binary_accuracy: 0.5400\n",
            "Epoch 370/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4295 - binary_accuracy: 0.8900 - val_loss: 0.6869 - val_binary_accuracy: 0.5400\n",
            "Epoch 371/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4304 - binary_accuracy: 0.8612 - val_loss: 0.6796 - val_binary_accuracy: 0.5400\n",
            "Epoch 372/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4306 - binary_accuracy: 0.8612 - val_loss: 0.6754 - val_binary_accuracy: 0.5600\n",
            "Epoch 373/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4288 - binary_accuracy: 0.8756 - val_loss: 0.6668 - val_binary_accuracy: 0.6000\n",
            "Epoch 374/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4289 - binary_accuracy: 0.8804 - val_loss: 0.7010 - val_binary_accuracy: 0.5600\n",
            "Epoch 375/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4265 - binary_accuracy: 0.8565 - val_loss: 0.6386 - val_binary_accuracy: 0.6200\n",
            "Epoch 376/500\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4234 - binary_accuracy: 0.8756 - val_loss: 0.5872 - val_binary_accuracy: 0.7400\n",
            "Epoch 377/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4297 - binary_accuracy: 0.8900 - val_loss: 0.6301 - val_binary_accuracy: 0.6200\n",
            "Epoch 378/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4190 - binary_accuracy: 0.9043 - val_loss: 0.6370 - val_binary_accuracy: 0.6200\n",
            "Epoch 379/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4206 - binary_accuracy: 0.8900 - val_loss: 0.6230 - val_binary_accuracy: 0.6400\n",
            "Epoch 380/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4201 - binary_accuracy: 0.8708 - val_loss: 0.6262 - val_binary_accuracy: 0.6400\n",
            "Epoch 381/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4185 - binary_accuracy: 0.8852 - val_loss: 0.6942 - val_binary_accuracy: 0.5400\n",
            "Epoch 382/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4210 - binary_accuracy: 0.8804 - val_loss: 0.7042 - val_binary_accuracy: 0.5400\n",
            "Epoch 383/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4119 - binary_accuracy: 0.8660 - val_loss: 0.6009 - val_binary_accuracy: 0.7200\n",
            "Epoch 384/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4201 - binary_accuracy: 0.9091 - val_loss: 0.6409 - val_binary_accuracy: 0.6400\n",
            "Epoch 385/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4105 - binary_accuracy: 0.9043 - val_loss: 0.6570 - val_binary_accuracy: 0.6200\n",
            "Epoch 386/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4106 - binary_accuracy: 0.8900 - val_loss: 0.6648 - val_binary_accuracy: 0.6000\n",
            "Epoch 387/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4107 - binary_accuracy: 0.8947 - val_loss: 0.6093 - val_binary_accuracy: 0.7000\n",
            "Epoch 388/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4122 - binary_accuracy: 0.8852 - val_loss: 0.5788 - val_binary_accuracy: 0.7200\n",
            "Epoch 389/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4083 - binary_accuracy: 0.8947 - val_loss: 0.6683 - val_binary_accuracy: 0.6000\n",
            "Epoch 390/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4007 - binary_accuracy: 0.8852 - val_loss: 0.5694 - val_binary_accuracy: 0.7400\n",
            "Epoch 391/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4095 - binary_accuracy: 0.8612 - val_loss: 0.6511 - val_binary_accuracy: 0.6200\n",
            "Epoch 392/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3997 - binary_accuracy: 0.9043 - val_loss: 0.6257 - val_binary_accuracy: 0.6400\n",
            "Epoch 393/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4026 - binary_accuracy: 0.9091 - val_loss: 0.7310 - val_binary_accuracy: 0.5200\n",
            "Epoch 394/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4018 - binary_accuracy: 0.8756 - val_loss: 0.6451 - val_binary_accuracy: 0.6400\n",
            "Epoch 395/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3967 - binary_accuracy: 0.9043 - val_loss: 0.6022 - val_binary_accuracy: 0.7000\n",
            "Epoch 396/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3970 - binary_accuracy: 0.8995 - val_loss: 0.6723 - val_binary_accuracy: 0.6200\n",
            "Epoch 397/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3935 - binary_accuracy: 0.8900 - val_loss: 0.6356 - val_binary_accuracy: 0.6400\n",
            "Epoch 398/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3919 - binary_accuracy: 0.9139 - val_loss: 0.7000 - val_binary_accuracy: 0.5800\n",
            "Epoch 399/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3958 - binary_accuracy: 0.8804 - val_loss: 0.6050 - val_binary_accuracy: 0.6800\n",
            "Epoch 400/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3929 - binary_accuracy: 0.8900 - val_loss: 0.6570 - val_binary_accuracy: 0.6200\n",
            "Epoch 401/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3914 - binary_accuracy: 0.9139 - val_loss: 0.6962 - val_binary_accuracy: 0.5800\n",
            "Epoch 402/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3926 - binary_accuracy: 0.8900 - val_loss: 0.6454 - val_binary_accuracy: 0.6200\n",
            "Epoch 403/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3851 - binary_accuracy: 0.9043 - val_loss: 0.6608 - val_binary_accuracy: 0.6400\n",
            "Epoch 404/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3886 - binary_accuracy: 0.8947 - val_loss: 0.6669 - val_binary_accuracy: 0.6400\n",
            "Epoch 405/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3839 - binary_accuracy: 0.9139 - val_loss: 0.6163 - val_binary_accuracy: 0.6400\n",
            "Epoch 406/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3836 - binary_accuracy: 0.8995 - val_loss: 0.6250 - val_binary_accuracy: 0.6400\n",
            "Epoch 407/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3797 - binary_accuracy: 0.9043 - val_loss: 0.5953 - val_binary_accuracy: 0.7000\n",
            "Epoch 408/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3850 - binary_accuracy: 0.8900 - val_loss: 0.6387 - val_binary_accuracy: 0.6200\n",
            "Epoch 409/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3826 - binary_accuracy: 0.9091 - val_loss: 0.6828 - val_binary_accuracy: 0.6000\n",
            "Epoch 410/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3799 - binary_accuracy: 0.9091 - val_loss: 0.6753 - val_binary_accuracy: 0.6400\n",
            "Epoch 411/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3757 - binary_accuracy: 0.8995 - val_loss: 0.6327 - val_binary_accuracy: 0.6200\n",
            "Epoch 412/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3760 - binary_accuracy: 0.9282 - val_loss: 0.6915 - val_binary_accuracy: 0.6000\n",
            "Epoch 413/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3779 - binary_accuracy: 0.8995 - val_loss: 0.6106 - val_binary_accuracy: 0.6800\n",
            "Epoch 414/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3724 - binary_accuracy: 0.8995 - val_loss: 0.5584 - val_binary_accuracy: 0.7200\n",
            "Epoch 415/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3759 - binary_accuracy: 0.8995 - val_loss: 0.5949 - val_binary_accuracy: 0.7200\n",
            "Epoch 416/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3672 - binary_accuracy: 0.9091 - val_loss: 0.6478 - val_binary_accuracy: 0.6400\n",
            "Epoch 417/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3714 - binary_accuracy: 0.9043 - val_loss: 0.5643 - val_binary_accuracy: 0.7400\n",
            "Epoch 418/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3687 - binary_accuracy: 0.9043 - val_loss: 0.5988 - val_binary_accuracy: 0.7000\n",
            "Epoch 419/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3708 - binary_accuracy: 0.9043 - val_loss: 0.6506 - val_binary_accuracy: 0.6400\n",
            "Epoch 420/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3636 - binary_accuracy: 0.9091 - val_loss: 0.5807 - val_binary_accuracy: 0.7400\n",
            "Epoch 421/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3683 - binary_accuracy: 0.8995 - val_loss: 0.6261 - val_binary_accuracy: 0.6400\n",
            "Epoch 422/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3643 - binary_accuracy: 0.9139 - val_loss: 0.6320 - val_binary_accuracy: 0.6200\n",
            "Epoch 423/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3605 - binary_accuracy: 0.9187 - val_loss: 0.7204 - val_binary_accuracy: 0.6000\n",
            "Epoch 424/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3624 - binary_accuracy: 0.9139 - val_loss: 0.6835 - val_binary_accuracy: 0.6200\n",
            "Epoch 425/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3593 - binary_accuracy: 0.9139 - val_loss: 0.6350 - val_binary_accuracy: 0.6400\n",
            "Epoch 426/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3657 - binary_accuracy: 0.9043 - val_loss: 0.6511 - val_binary_accuracy: 0.6600\n",
            "Epoch 427/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3597 - binary_accuracy: 0.9043 - val_loss: 0.6355 - val_binary_accuracy: 0.6400\n",
            "Epoch 428/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3567 - binary_accuracy: 0.8852 - val_loss: 0.5874 - val_binary_accuracy: 0.7400\n",
            "Epoch 429/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3567 - binary_accuracy: 0.9187 - val_loss: 0.7406 - val_binary_accuracy: 0.5600\n",
            "Epoch 430/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3554 - binary_accuracy: 0.8947 - val_loss: 0.5856 - val_binary_accuracy: 0.7400\n",
            "Epoch 431/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3577 - binary_accuracy: 0.9043 - val_loss: 0.6278 - val_binary_accuracy: 0.6600\n",
            "Epoch 432/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3516 - binary_accuracy: 0.9187 - val_loss: 0.6392 - val_binary_accuracy: 0.6800\n",
            "Epoch 433/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3521 - binary_accuracy: 0.9187 - val_loss: 0.6485 - val_binary_accuracy: 0.6600\n",
            "Epoch 434/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3497 - binary_accuracy: 0.9091 - val_loss: 0.6042 - val_binary_accuracy: 0.6800\n",
            "Epoch 435/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3473 - binary_accuracy: 0.9187 - val_loss: 0.6759 - val_binary_accuracy: 0.6200\n",
            "Epoch 436/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3525 - binary_accuracy: 0.9043 - val_loss: 0.6496 - val_binary_accuracy: 0.6600\n",
            "Epoch 437/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3497 - binary_accuracy: 0.8947 - val_loss: 0.6034 - val_binary_accuracy: 0.6800\n",
            "Epoch 438/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3456 - binary_accuracy: 0.9139 - val_loss: 0.6317 - val_binary_accuracy: 0.6800\n",
            "Epoch 439/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3528 - binary_accuracy: 0.8995 - val_loss: 0.6267 - val_binary_accuracy: 0.6600\n",
            "Epoch 440/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3432 - binary_accuracy: 0.9234 - val_loss: 0.5926 - val_binary_accuracy: 0.7400\n",
            "Epoch 441/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3422 - binary_accuracy: 0.9091 - val_loss: 0.6742 - val_binary_accuracy: 0.6200\n",
            "Epoch 442/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3409 - binary_accuracy: 0.9043 - val_loss: 0.6345 - val_binary_accuracy: 0.6800\n",
            "Epoch 443/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3376 - binary_accuracy: 0.9139 - val_loss: 0.6076 - val_binary_accuracy: 0.6800\n",
            "Epoch 444/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3444 - binary_accuracy: 0.9091 - val_loss: 0.6541 - val_binary_accuracy: 0.6400\n",
            "Epoch 445/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3413 - binary_accuracy: 0.8900 - val_loss: 0.6625 - val_binary_accuracy: 0.6600\n",
            "Epoch 446/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3358 - binary_accuracy: 0.9043 - val_loss: 0.5998 - val_binary_accuracy: 0.7200\n",
            "Epoch 447/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3359 - binary_accuracy: 0.9139 - val_loss: 0.6372 - val_binary_accuracy: 0.6800\n",
            "Epoch 448/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3351 - binary_accuracy: 0.9043 - val_loss: 0.5684 - val_binary_accuracy: 0.7400\n",
            "Epoch 449/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3294 - binary_accuracy: 0.9330 - val_loss: 0.7151 - val_binary_accuracy: 0.6000\n",
            "Epoch 450/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3306 - binary_accuracy: 0.9282 - val_loss: 0.6020 - val_binary_accuracy: 0.7000\n",
            "Epoch 451/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3291 - binary_accuracy: 0.9187 - val_loss: 0.5931 - val_binary_accuracy: 0.7200\n",
            "Epoch 452/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3365 - binary_accuracy: 0.9139 - val_loss: 0.6373 - val_binary_accuracy: 0.6800\n",
            "Epoch 453/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3274 - binary_accuracy: 0.9139 - val_loss: 0.5549 - val_binary_accuracy: 0.7600\n",
            "Epoch 454/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3260 - binary_accuracy: 0.9234 - val_loss: 0.6247 - val_binary_accuracy: 0.6600\n",
            "Epoch 455/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3280 - binary_accuracy: 0.9139 - val_loss: 0.5315 - val_binary_accuracy: 0.7400\n",
            "Epoch 456/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3329 - binary_accuracy: 0.8947 - val_loss: 0.5729 - val_binary_accuracy: 0.7400\n",
            "Epoch 457/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3247 - binary_accuracy: 0.9282 - val_loss: 0.6189 - val_binary_accuracy: 0.6600\n",
            "Epoch 458/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3222 - binary_accuracy: 0.9234 - val_loss: 0.6198 - val_binary_accuracy: 0.6600\n",
            "Epoch 459/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3241 - binary_accuracy: 0.9234 - val_loss: 0.6087 - val_binary_accuracy: 0.6800\n",
            "Epoch 460/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3221 - binary_accuracy: 0.9282 - val_loss: 0.6508 - val_binary_accuracy: 0.6800\n",
            "Epoch 461/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3180 - binary_accuracy: 0.9234 - val_loss: 0.5866 - val_binary_accuracy: 0.7400\n",
            "Epoch 462/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3173 - binary_accuracy: 0.9187 - val_loss: 0.6168 - val_binary_accuracy: 0.6600\n",
            "Epoch 463/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3185 - binary_accuracy: 0.9234 - val_loss: 0.5967 - val_binary_accuracy: 0.7200\n",
            "Epoch 464/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3145 - binary_accuracy: 0.9282 - val_loss: 0.6161 - val_binary_accuracy: 0.6800\n",
            "Epoch 465/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3159 - binary_accuracy: 0.9282 - val_loss: 0.6458 - val_binary_accuracy: 0.6800\n",
            "Epoch 466/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3199 - binary_accuracy: 0.9234 - val_loss: 0.6192 - val_binary_accuracy: 0.6600\n",
            "Epoch 467/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3172 - binary_accuracy: 0.9139 - val_loss: 0.5538 - val_binary_accuracy: 0.7400\n",
            "Epoch 468/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3135 - binary_accuracy: 0.9330 - val_loss: 0.6164 - val_binary_accuracy: 0.6600\n",
            "Epoch 469/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3107 - binary_accuracy: 0.9234 - val_loss: 0.6325 - val_binary_accuracy: 0.6800\n",
            "Epoch 470/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3126 - binary_accuracy: 0.9187 - val_loss: 0.5649 - val_binary_accuracy: 0.7400\n",
            "Epoch 471/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3118 - binary_accuracy: 0.9091 - val_loss: 0.6544 - val_binary_accuracy: 0.6800\n",
            "Epoch 472/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3145 - binary_accuracy: 0.9091 - val_loss: 0.5423 - val_binary_accuracy: 0.7400\n",
            "Epoch 473/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3089 - binary_accuracy: 0.9187 - val_loss: 0.6285 - val_binary_accuracy: 0.6800\n",
            "Epoch 474/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3100 - binary_accuracy: 0.9234 - val_loss: 0.6854 - val_binary_accuracy: 0.6200\n",
            "Epoch 475/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3116 - binary_accuracy: 0.9234 - val_loss: 0.6034 - val_binary_accuracy: 0.7200\n",
            "Epoch 476/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3062 - binary_accuracy: 0.9234 - val_loss: 0.6589 - val_binary_accuracy: 0.6600\n",
            "Epoch 477/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3004 - binary_accuracy: 0.9187 - val_loss: 0.5455 - val_binary_accuracy: 0.7600\n",
            "Epoch 478/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3079 - binary_accuracy: 0.9187 - val_loss: 0.5832 - val_binary_accuracy: 0.7400\n",
            "Epoch 479/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.3002 - binary_accuracy: 0.9139 - val_loss: 0.5627 - val_binary_accuracy: 0.7400\n",
            "Epoch 480/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3035 - binary_accuracy: 0.9139 - val_loss: 0.6442 - val_binary_accuracy: 0.6800\n",
            "Epoch 481/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2975 - binary_accuracy: 0.9330 - val_loss: 0.7209 - val_binary_accuracy: 0.6000\n",
            "Epoch 482/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2974 - binary_accuracy: 0.9091 - val_loss: 0.5870 - val_binary_accuracy: 0.7200\n",
            "Epoch 483/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2983 - binary_accuracy: 0.9234 - val_loss: 0.6436 - val_binary_accuracy: 0.6800\n",
            "Epoch 484/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2946 - binary_accuracy: 0.9330 - val_loss: 0.5795 - val_binary_accuracy: 0.7400\n",
            "Epoch 485/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2937 - binary_accuracy: 0.9330 - val_loss: 0.6856 - val_binary_accuracy: 0.6400\n",
            "Epoch 486/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2976 - binary_accuracy: 0.9234 - val_loss: 0.6667 - val_binary_accuracy: 0.6600\n",
            "Epoch 487/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2935 - binary_accuracy: 0.9378 - val_loss: 0.6247 - val_binary_accuracy: 0.6800\n",
            "Epoch 488/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2894 - binary_accuracy: 0.9282 - val_loss: 0.5518 - val_binary_accuracy: 0.7600\n",
            "Epoch 489/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2955 - binary_accuracy: 0.9378 - val_loss: 0.6685 - val_binary_accuracy: 0.6600\n",
            "Epoch 490/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2903 - binary_accuracy: 0.9282 - val_loss: 0.6111 - val_binary_accuracy: 0.7200\n",
            "Epoch 491/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2935 - binary_accuracy: 0.9330 - val_loss: 0.6076 - val_binary_accuracy: 0.7200\n",
            "Epoch 492/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2883 - binary_accuracy: 0.9282 - val_loss: 0.6348 - val_binary_accuracy: 0.6800\n",
            "Epoch 493/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2961 - binary_accuracy: 0.9187 - val_loss: 0.5250 - val_binary_accuracy: 0.7400\n",
            "Epoch 494/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2937 - binary_accuracy: 0.9282 - val_loss: 0.6073 - val_binary_accuracy: 0.7200\n",
            "Epoch 495/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2877 - binary_accuracy: 0.9330 - val_loss: 0.6094 - val_binary_accuracy: 0.7200\n",
            "Epoch 496/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2848 - binary_accuracy: 0.9234 - val_loss: 0.6736 - val_binary_accuracy: 0.6400\n",
            "Epoch 497/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2839 - binary_accuracy: 0.9282 - val_loss: 0.6380 - val_binary_accuracy: 0.6600\n",
            "Epoch 498/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2838 - binary_accuracy: 0.9282 - val_loss: 0.7068 - val_binary_accuracy: 0.6400\n",
            "Epoch 499/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2855 - binary_accuracy: 0.9187 - val_loss: 0.6527 - val_binary_accuracy: 0.6800\n",
            "Epoch 500/500\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.2855 - binary_accuracy: 0.9139 - val_loss: 0.6222 - val_binary_accuracy: 0.7000\n",
            "Training: ends at Mon, 18 Sep 2023 10:07:23\n",
            "Duration: 62.40 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLdVTFjGyyDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7543e48-1426-49e0-ad60-68425a837907"
      },
      "source": [
        "loss, acc = model.evaluate(x=train_x,y=train_y, batch_size=32)\n",
        "print('Train loss: %.4f - acc: %.4f' % (loss, acc))\n",
        "\n",
        "loss_, acc_ = model.evaluate(x=test_x,y=test_y, batch_size=32)\n",
        "print('Test loss: %.4f - acc: %.4f' % (loss_, acc_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 4ms/step - loss: 0.2781 - binary_accuracy: 0.9282\n",
            "Train loss: 0.2781 - acc: 0.9282\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 0.6222 - binary_accuracy: 0.7000\n",
            "Test loss: 0.6222 - acc: 0.7000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RooPTo2ezBBh"
      },
      "source": [
        "# 4 Hyperparameter Tuning\n",
        "\n",
        "Check the tutorials:\n",
        "\n",
        "* https://docs.wandb.ai/tutorials/tensorflow_sweeps\n",
        "* https://docs.wandb.ai/tutorials/tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESSHH5_UzQ3o"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "print('wandb version:', wandb.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XBInWHaRm3i",
        "outputId": "6ec1c4ce-4f90-43a1-c42b-d072d3d78a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "wandb version: 0.15.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pip install wandb --upgrade"
      ],
      "metadata": {
        "id": "9dQM-CEBJGr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_Tjh1Sbz1tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e4edc1f-1318-4399-9619-dfe64b9248f1"
      },
      "source": [
        "!wandb login --relogin"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKxNLU83GV4q"
      },
      "source": [
        "## 4.1 Monitoring a neural network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "from wandb.integration.keras import WandbMetricsLogger\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Default values for hyperparameters\n",
        "defaults = dict(layer_1 = 8,\n",
        "                layer_2 = 8,\n",
        "                learn_rate = 0.001,\n",
        "                batch_size = 32,\n",
        "                epoch = 500)\n",
        "\n",
        "wandb.init(project=\"dl_week_wandb\", config= defaults, name=\"dl_week_wandb_run_01\")\n",
        "config = wandb.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnRgjavMSVxN",
        "outputId": "33e9e3cb-bd65-4012-8b17-ce38b7712d7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterrematte\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230918_131140-cf7esqce\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdl_week06_run_01\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/cf7esqce\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb6btCNjTaq7",
        "outputId": "51e34976-66f8-43db-9883-2b415f5b7754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'layer_1': 8, 'layer_2': 8, 'learn_rate': 0.001, 'batch_size': 32, 'epoch': 500}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bKBiY1q1QdJ"
      },
      "source": [
        "# Instantiate a simple classification model\n",
        "model = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(config.layer_1, activation=tf.nn.relu, dtype='float64'),\n",
        "  tf.keras.layers.Dense(config.layer_2, activation=tf.nn.relu, dtype='float64'),\n",
        "  tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, dtype='float64')\n",
        "])\n",
        "\n",
        "# Instantiate a logistic loss function that expects integer targets.\n",
        "loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# Instantiate an accuracy metric.\n",
        "accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "# Instantiate an optimizer.\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=config.learn_rate)\n",
        "\n",
        "# configure the optimizer, loss, and metrics to monitor.\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuzJG3XG2jjw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "73a69b38-14e7-4a0b-d5d3-1203a7f1da6d"
      },
      "source": [
        "%%wandb\n",
        "# Add WandbCallback() to the fit function\n",
        "model.fit(x=train_x,\n",
        "          y=train_y,\n",
        "          batch_size=config.batch_size,\n",
        "          epochs=config.epoch,\n",
        "          validation_data=(test_x,test_y),\n",
        "          callbacks=[WandbCallback(log_weights=True)],\n",
        "          verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<wandb.jupyter.IFrame at 0x7fc39268f5e0>"
            ],
            "text/html": [
              "<iframe src='https://wandb.ai/terrematte/dl_week06/runs/cf7esqce?jupyter=true' style='border:none;width:100%;height:420px;'></iframe>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/7 [===>..........................] - ETA: 5s - loss: 0.6891 - binary_accuracy: 0.5625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 270ms/step - loss: 0.6683 - binary_accuracy: 0.6220 - val_loss: 0.7790 - val_binary_accuracy: 0.3400\n",
            "Epoch 2/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6588 - binary_accuracy: 0.6555 - val_loss: 0.8038 - val_binary_accuracy: 0.3400\n",
            "Epoch 3/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6556 - binary_accuracy: 0.6603 - val_loss: 0.8104 - val_binary_accuracy: 0.3400\n",
            "Epoch 4/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6529 - binary_accuracy: 0.6603 - val_loss: 0.8138 - val_binary_accuracy: 0.3400\n",
            "Epoch 5/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6507 - binary_accuracy: 0.6603 - val_loss: 0.8257 - val_binary_accuracy: 0.3400\n",
            "Epoch 6/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6489 - binary_accuracy: 0.6603 - val_loss: 0.8361 - val_binary_accuracy: 0.3400\n",
            "Epoch 7/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6467 - binary_accuracy: 0.6603 - val_loss: 0.8393 - val_binary_accuracy: 0.3400\n",
            "Epoch 8/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6452 - binary_accuracy: 0.6603 - val_loss: 0.8330 - val_binary_accuracy: 0.3400\n",
            "Epoch 9/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6432 - binary_accuracy: 0.6603 - val_loss: 0.8349 - val_binary_accuracy: 0.3400\n",
            "Epoch 10/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6406 - binary_accuracy: 0.6603 - val_loss: 0.8415 - val_binary_accuracy: 0.3400\n",
            "Epoch 11/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6384 - binary_accuracy: 0.6603 - val_loss: 0.8246 - val_binary_accuracy: 0.3400\n",
            "Epoch 12/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6367 - binary_accuracy: 0.6603 - val_loss: 0.8217 - val_binary_accuracy: 0.3400\n",
            "Epoch 13/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6332 - binary_accuracy: 0.6603 - val_loss: 0.8213 - val_binary_accuracy: 0.3400\n",
            "Epoch 14/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6338 - binary_accuracy: 0.6603 - val_loss: 0.7984 - val_binary_accuracy: 0.3400\n",
            "Epoch 15/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6288 - binary_accuracy: 0.6651 - val_loss: 0.8250 - val_binary_accuracy: 0.3400\n",
            "Epoch 16/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5819 - binary_accuracy: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 149ms/step - loss: 0.6274 - binary_accuracy: 0.6603 - val_loss: 0.7583 - val_binary_accuracy: 0.3200\n",
            "Epoch 17/500\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.6271 - binary_accuracy: 0.6603 - val_loss: 0.7763 - val_binary_accuracy: 0.3400\n",
            "Epoch 18/500\n",
            "7/7 [==============================] - 0s 44ms/step - loss: 0.6229 - binary_accuracy: 0.6603 - val_loss: 0.7726 - val_binary_accuracy: 0.3400\n",
            "Epoch 19/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.6205 - binary_accuracy: 0.6651 - val_loss: 0.7863 - val_binary_accuracy: 0.3400\n",
            "Epoch 20/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6216 - binary_accuracy: 0.6651 - val_loss: 0.7772 - val_binary_accuracy: 0.3400\n",
            "Epoch 21/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6143 - binary_accuracy: 0.6603 - val_loss: 0.7673 - val_binary_accuracy: 0.3200\n",
            "Epoch 22/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5775 - binary_accuracy: 0.6875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 242ms/step - loss: 0.6126 - binary_accuracy: 0.6603 - val_loss: 0.7472 - val_binary_accuracy: 0.3400\n",
            "Epoch 23/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.6095 - binary_accuracy: 0.6507 - val_loss: 0.7997 - val_binary_accuracy: 0.3400\n",
            "Epoch 24/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6081 - binary_accuracy: 0.6507 - val_loss: 0.8154 - val_binary_accuracy: 0.3400\n",
            "Epoch 25/500\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.6135 - binary_accuracy: 0.6603 - val_loss: 0.7513 - val_binary_accuracy: 0.3400\n",
            "Epoch 26/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.6011 - binary_accuracy: 0.6555 - val_loss: 0.7854 - val_binary_accuracy: 0.3400\n",
            "Epoch 27/500\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6017 - binary_accuracy: 0.6555 - val_loss: 0.7575 - val_binary_accuracy: 0.3400\n",
            "Epoch 28/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5983 - binary_accuracy: 0.6555 - val_loss: 0.7879 - val_binary_accuracy: 0.3400\n",
            "Epoch 29/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.5972 - binary_accuracy: 0.6507 - val_loss: 0.7738 - val_binary_accuracy: 0.3600\n",
            "Epoch 30/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.5933 - binary_accuracy: 0.6507 - val_loss: 0.7731 - val_binary_accuracy: 0.3600\n",
            "Epoch 31/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5851 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 253ms/step - loss: 0.5939 - binary_accuracy: 0.6603 - val_loss: 0.7253 - val_binary_accuracy: 0.4200\n",
            "Epoch 32/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.5906 - binary_accuracy: 0.6555 - val_loss: 0.7710 - val_binary_accuracy: 0.3400\n",
            "Epoch 33/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5930 - binary_accuracy: 0.6746 - val_loss: 0.7435 - val_binary_accuracy: 0.4200\n",
            "Epoch 34/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.5942 - binary_accuracy: 0.6746 - val_loss: 0.7831 - val_binary_accuracy: 0.3600\n",
            "Epoch 35/500\n",
            "7/7 [==============================] - 0s 71ms/step - loss: 0.5868 - binary_accuracy: 0.6699 - val_loss: 0.8456 - val_binary_accuracy: 0.3400\n",
            "Epoch 36/500\n",
            "7/7 [==============================] - 1s 80ms/step - loss: 0.5868 - binary_accuracy: 0.6555 - val_loss: 0.7520 - val_binary_accuracy: 0.3400\n",
            "Epoch 37/500\n",
            "7/7 [==============================] - 0s 73ms/step - loss: 0.5792 - binary_accuracy: 0.6651 - val_loss: 0.7527 - val_binary_accuracy: 0.3600\n",
            "Epoch 38/500\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.5796 - binary_accuracy: 0.6651 - val_loss: 0.7550 - val_binary_accuracy: 0.3600\n",
            "Epoch 39/500\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5791 - binary_accuracy: 0.6651 - val_loss: 0.7630 - val_binary_accuracy: 0.3600\n",
            "Epoch 40/500\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5777 - binary_accuracy: 0.6842 - val_loss: 0.7817 - val_binary_accuracy: 0.3400\n",
            "Epoch 41/500\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.5752 - binary_accuracy: 0.6603"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 399ms/step - loss: 0.5752 - binary_accuracy: 0.6603 - val_loss: 0.7168 - val_binary_accuracy: 0.4000\n",
            "Epoch 42/500\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5787 - binary_accuracy: 0.6986 - val_loss: 0.7814 - val_binary_accuracy: 0.3400\n",
            "Epoch 43/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.5698 - binary_accuracy: 0.6699 - val_loss: 0.7372 - val_binary_accuracy: 0.4200\n",
            "Epoch 44/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5999 - binary_accuracy: 0.7188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 280ms/step - loss: 0.5719 - binary_accuracy: 0.6890 - val_loss: 0.7090 - val_binary_accuracy: 0.4400\n",
            "Epoch 45/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5753 - binary_accuracy: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 314ms/step - loss: 0.5656 - binary_accuracy: 0.6890 - val_loss: 0.6924 - val_binary_accuracy: 0.4800\n",
            "Epoch 46/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.5688 - binary_accuracy: 0.7033 - val_loss: 0.7571 - val_binary_accuracy: 0.4200\n",
            "Epoch 47/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.5647 - binary_accuracy: 0.7033 - val_loss: 0.7311 - val_binary_accuracy: 0.4000\n",
            "Epoch 48/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5079 - binary_accuracy: 0.8125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 244ms/step - loss: 0.5632 - binary_accuracy: 0.7033 - val_loss: 0.6815 - val_binary_accuracy: 0.5000\n",
            "Epoch 49/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5606 - binary_accuracy: 0.7129 - val_loss: 0.7460 - val_binary_accuracy: 0.4200\n",
            "Epoch 50/500\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.5544 - binary_accuracy: 0.6927"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 255ms/step - loss: 0.5623 - binary_accuracy: 0.6842 - val_loss: 0.6751 - val_binary_accuracy: 0.5600\n",
            "Epoch 51/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.5665 - binary_accuracy: 0.7273 - val_loss: 0.7651 - val_binary_accuracy: 0.4200\n",
            "Epoch 52/500\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5550 - binary_accuracy: 0.7081 - val_loss: 0.7818 - val_binary_accuracy: 0.4200\n",
            "Epoch 53/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.5578 - binary_accuracy: 0.7081 - val_loss: 0.7354 - val_binary_accuracy: 0.4000\n",
            "Epoch 54/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5537 - binary_accuracy: 0.7081 - val_loss: 0.7757 - val_binary_accuracy: 0.4200\n",
            "Epoch 55/500\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.5533 - binary_accuracy: 0.7129 - val_loss: 0.7263 - val_binary_accuracy: 0.4000\n",
            "Epoch 56/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5520 - binary_accuracy: 0.7129 - val_loss: 0.7261 - val_binary_accuracy: 0.4200\n",
            "Epoch 57/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5471 - binary_accuracy: 0.7273 - val_loss: 0.7689 - val_binary_accuracy: 0.4200\n",
            "Epoch 58/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.5513 - binary_accuracy: 0.7081 - val_loss: 0.7592 - val_binary_accuracy: 0.4000\n",
            "Epoch 59/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.5439 - binary_accuracy: 0.7273 - val_loss: 0.7555 - val_binary_accuracy: 0.4000\n",
            "Epoch 60/500\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.5422 - binary_accuracy: 0.6986 - val_loss: 0.7422 - val_binary_accuracy: 0.4200\n",
            "Epoch 61/500\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.5445 - binary_accuracy: 0.7081 - val_loss: 0.7601 - val_binary_accuracy: 0.4200\n",
            "Epoch 62/500\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.5443 - binary_accuracy: 0.7225 - val_loss: 0.7946 - val_binary_accuracy: 0.4000\n",
            "Epoch 63/500\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.5396 - binary_accuracy: 0.7225 - val_loss: 0.6892 - val_binary_accuracy: 0.5600\n",
            "Epoch 64/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.5400 - binary_accuracy: 0.7416 - val_loss: 0.6936 - val_binary_accuracy: 0.5600\n",
            "Epoch 65/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.5379 - binary_accuracy: 0.7464 - val_loss: 0.7462 - val_binary_accuracy: 0.4200\n",
            "Epoch 66/500\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5359 - binary_accuracy: 0.7321 - val_loss: 0.7587 - val_binary_accuracy: 0.4200\n",
            "Epoch 67/500\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.5327 - binary_accuracy: 0.7416 - val_loss: 0.7315 - val_binary_accuracy: 0.4400\n",
            "Epoch 68/500\n",
            "7/7 [==============================] - 0s 49ms/step - loss: 0.5322 - binary_accuracy: 0.7416 - val_loss: 0.6922 - val_binary_accuracy: 0.5600\n",
            "Epoch 69/500\n",
            "7/7 [==============================] - 0s 46ms/step - loss: 0.5329 - binary_accuracy: 0.7464 - val_loss: 0.7368 - val_binary_accuracy: 0.4600\n",
            "Epoch 70/500\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.5293 - binary_accuracy: 0.7416 - val_loss: 0.7326 - val_binary_accuracy: 0.4800\n",
            "Epoch 71/500\n",
            "7/7 [==============================] - 0s 38ms/step - loss: 0.5275 - binary_accuracy: 0.7416 - val_loss: 0.7535 - val_binary_accuracy: 0.4400\n",
            "Epoch 72/500\n",
            "7/7 [==============================] - 0s 43ms/step - loss: 0.5265 - binary_accuracy: 0.7416 - val_loss: 0.7009 - val_binary_accuracy: 0.5400\n",
            "Epoch 73/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.5246 - binary_accuracy: 0.7512 - val_loss: 0.6785 - val_binary_accuracy: 0.5800\n",
            "Epoch 74/500\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.5214 - binary_accuracy: 0.7708"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 314ms/step - loss: 0.5278 - binary_accuracy: 0.7560 - val_loss: 0.6743 - val_binary_accuracy: 0.6000\n",
            "Epoch 75/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.5238 - binary_accuracy: 0.7656 - val_loss: 0.7088 - val_binary_accuracy: 0.5400\n",
            "Epoch 76/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.5229 - binary_accuracy: 0.7464 - val_loss: 0.7413 - val_binary_accuracy: 0.4600\n",
            "Epoch 77/500\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.5211 - binary_accuracy: 0.7512 - val_loss: 0.6901 - val_binary_accuracy: 0.5800\n",
            "Epoch 78/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5199 - binary_accuracy: 0.7416 - val_loss: 0.6831 - val_binary_accuracy: 0.5600\n",
            "Epoch 79/500\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.5083 - binary_accuracy: 0.7656"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 333ms/step - loss: 0.5199 - binary_accuracy: 0.7512 - val_loss: 0.6479 - val_binary_accuracy: 0.6200\n",
            "Epoch 80/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5193 - binary_accuracy: 0.7895 - val_loss: 0.7259 - val_binary_accuracy: 0.5200\n",
            "Epoch 81/500\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.5202 - binary_accuracy: 0.7464 - val_loss: 0.7304 - val_binary_accuracy: 0.5000\n",
            "Epoch 82/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.5210 - binary_accuracy: 0.7321 - val_loss: 0.6527 - val_binary_accuracy: 0.6400\n",
            "Epoch 83/500\n",
            "6/7 [========================>.....] - ETA: 0s - loss: 0.5038 - binary_accuracy: 0.7865"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 225ms/step - loss: 0.5145 - binary_accuracy: 0.7608 - val_loss: 0.6283 - val_binary_accuracy: 0.6400\n",
            "Epoch 84/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5160 - binary_accuracy: 0.7990 - val_loss: 0.6783 - val_binary_accuracy: 0.5800\n",
            "Epoch 85/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.5098 - binary_accuracy: 0.7751 - val_loss: 0.6868 - val_binary_accuracy: 0.5600\n",
            "Epoch 86/500\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.5113 - binary_accuracy: 0.7703 - val_loss: 0.6770 - val_binary_accuracy: 0.6000\n",
            "Epoch 87/500\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.5064 - binary_accuracy: 0.7799 - val_loss: 0.7204 - val_binary_accuracy: 0.5400\n",
            "Epoch 88/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5057 - binary_accuracy: 0.7656 - val_loss: 0.7491 - val_binary_accuracy: 0.4800\n",
            "Epoch 89/500\n",
            "7/7 [==============================] - 0s 34ms/step - loss: 0.5103 - binary_accuracy: 0.7560 - val_loss: 0.6782 - val_binary_accuracy: 0.6200\n",
            "Epoch 90/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.5034 - binary_accuracy: 0.8038 - val_loss: 0.7434 - val_binary_accuracy: 0.5000\n",
            "Epoch 91/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5042 - binary_accuracy: 0.7560 - val_loss: 0.7170 - val_binary_accuracy: 0.5200\n",
            "Epoch 92/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.5005 - binary_accuracy: 0.7895 - val_loss: 0.6754 - val_binary_accuracy: 0.6000\n",
            "Epoch 93/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.5005 - binary_accuracy: 0.7990 - val_loss: 0.6746 - val_binary_accuracy: 0.6000\n",
            "Epoch 94/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.4970 - binary_accuracy: 0.7895 - val_loss: 0.6402 - val_binary_accuracy: 0.6200\n",
            "Epoch 95/500\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.4980 - binary_accuracy: 0.8038 - val_loss: 0.6763 - val_binary_accuracy: 0.6000\n",
            "Epoch 96/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4963 - binary_accuracy: 0.8038 - val_loss: 0.7086 - val_binary_accuracy: 0.5600\n",
            "Epoch 97/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4931 - binary_accuracy: 0.7847 - val_loss: 0.6673 - val_binary_accuracy: 0.6000\n",
            "Epoch 98/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4954 - binary_accuracy: 0.7799 - val_loss: 0.6718 - val_binary_accuracy: 0.6000\n",
            "Epoch 99/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4921 - binary_accuracy: 0.8038 - val_loss: 0.6886 - val_binary_accuracy: 0.6000\n",
            "Epoch 100/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4928 - binary_accuracy: 0.7847 - val_loss: 0.7167 - val_binary_accuracy: 0.5400\n",
            "Epoch 101/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4893 - binary_accuracy: 0.7847 - val_loss: 0.7008 - val_binary_accuracy: 0.5800\n",
            "Epoch 102/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4868 - binary_accuracy: 0.7847 - val_loss: 0.6767 - val_binary_accuracy: 0.6000\n",
            "Epoch 103/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4872 - binary_accuracy: 0.7990 - val_loss: 0.6487 - val_binary_accuracy: 0.6400\n",
            "Epoch 104/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4870 - binary_accuracy: 0.8086 - val_loss: 0.6680 - val_binary_accuracy: 0.6000\n",
            "Epoch 105/500\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.4833 - binary_accuracy: 0.7990 - val_loss: 0.6771 - val_binary_accuracy: 0.6200\n",
            "Epoch 106/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4936 - binary_accuracy: 0.8750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 229ms/step - loss: 0.4854 - binary_accuracy: 0.7943 - val_loss: 0.6046 - val_binary_accuracy: 0.7000\n",
            "Epoch 107/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4883 - binary_accuracy: 0.8230 - val_loss: 0.6395 - val_binary_accuracy: 0.6400\n",
            "Epoch 108/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4871 - binary_accuracy: 0.8086 - val_loss: 0.6770 - val_binary_accuracy: 0.6200\n",
            "Epoch 109/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4826 - binary_accuracy: 0.8134 - val_loss: 0.6565 - val_binary_accuracy: 0.6200\n",
            "Epoch 110/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4814 - binary_accuracy: 0.8086 - val_loss: 0.6489 - val_binary_accuracy: 0.6200\n",
            "Epoch 111/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4833 - binary_accuracy: 0.8086 - val_loss: 0.6761 - val_binary_accuracy: 0.6200\n",
            "Epoch 112/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4822 - binary_accuracy: 0.8086 - val_loss: 0.7121 - val_binary_accuracy: 0.5400\n",
            "Epoch 113/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.4744 - binary_accuracy: 0.7847 - val_loss: 0.6255 - val_binary_accuracy: 0.6200\n",
            "Epoch 114/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4782 - binary_accuracy: 0.7990 - val_loss: 0.6156 - val_binary_accuracy: 0.6400\n",
            "Epoch 115/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4761 - binary_accuracy: 0.8182 - val_loss: 0.6790 - val_binary_accuracy: 0.6200\n",
            "Epoch 116/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4726 - binary_accuracy: 0.7895 - val_loss: 0.6138 - val_binary_accuracy: 0.6400\n",
            "Epoch 117/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4703 - binary_accuracy: 0.8182 - val_loss: 0.6704 - val_binary_accuracy: 0.6200\n",
            "Epoch 118/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4687 - binary_accuracy: 0.8038 - val_loss: 0.6540 - val_binary_accuracy: 0.6200\n",
            "Epoch 119/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4687 - binary_accuracy: 0.8134 - val_loss: 0.7088 - val_binary_accuracy: 0.5800\n",
            "Epoch 120/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4664 - binary_accuracy: 0.8182 - val_loss: 0.6862 - val_binary_accuracy: 0.6200\n",
            "Epoch 121/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4651 - binary_accuracy: 0.8230 - val_loss: 0.6748 - val_binary_accuracy: 0.6400\n",
            "Epoch 122/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4641 - binary_accuracy: 0.8134 - val_loss: 0.6699 - val_binary_accuracy: 0.6400\n",
            "Epoch 123/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4648 - binary_accuracy: 0.8230 - val_loss: 0.6848 - val_binary_accuracy: 0.6400\n",
            "Epoch 124/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4614 - binary_accuracy: 0.8182 - val_loss: 0.6576 - val_binary_accuracy: 0.6000\n",
            "Epoch 125/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4566 - binary_accuracy: 0.8325 - val_loss: 0.7481 - val_binary_accuracy: 0.5400\n",
            "Epoch 126/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4625 - binary_accuracy: 0.8230 - val_loss: 0.6793 - val_binary_accuracy: 0.6200\n",
            "Epoch 127/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4581 - binary_accuracy: 0.8134 - val_loss: 0.6937 - val_binary_accuracy: 0.5800\n",
            "Epoch 128/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4565 - binary_accuracy: 0.8086 - val_loss: 0.6925 - val_binary_accuracy: 0.6000\n",
            "Epoch 129/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4578 - binary_accuracy: 0.8278 - val_loss: 0.6895 - val_binary_accuracy: 0.6000\n",
            "Epoch 130/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4532 - binary_accuracy: 0.8230 - val_loss: 0.6862 - val_binary_accuracy: 0.6000\n",
            "Epoch 131/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4521 - binary_accuracy: 0.8230 - val_loss: 0.6806 - val_binary_accuracy: 0.6400\n",
            "Epoch 132/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4527 - binary_accuracy: 0.8086 - val_loss: 0.6349 - val_binary_accuracy: 0.6400\n",
            "Epoch 133/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4558 - binary_accuracy: 0.8278 - val_loss: 0.6555 - val_binary_accuracy: 0.6200\n",
            "Epoch 134/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4523 - binary_accuracy: 0.8373 - val_loss: 0.6756 - val_binary_accuracy: 0.6400\n",
            "Epoch 135/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4473 - binary_accuracy: 0.8182 - val_loss: 0.7096 - val_binary_accuracy: 0.6000\n",
            "Epoch 136/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4472 - binary_accuracy: 0.8325 - val_loss: 0.6771 - val_binary_accuracy: 0.6400\n",
            "Epoch 137/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4513 - binary_accuracy: 0.8230 - val_loss: 0.6477 - val_binary_accuracy: 0.6200\n",
            "Epoch 138/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4613 - binary_accuracy: 0.8750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 154ms/step - loss: 0.4472 - binary_accuracy: 0.8278 - val_loss: 0.5826 - val_binary_accuracy: 0.7200\n",
            "Epoch 139/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4512 - binary_accuracy: 0.8278 - val_loss: 0.6706 - val_binary_accuracy: 0.6400\n",
            "Epoch 140/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4440 - binary_accuracy: 0.8230 - val_loss: 0.6337 - val_binary_accuracy: 0.6400\n",
            "Epoch 141/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4415 - binary_accuracy: 0.8325 - val_loss: 0.6475 - val_binary_accuracy: 0.6200\n",
            "Epoch 142/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4405 - binary_accuracy: 0.8325 - val_loss: 0.6481 - val_binary_accuracy: 0.6200\n",
            "Epoch 143/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4418 - binary_accuracy: 0.8278 - val_loss: 0.6635 - val_binary_accuracy: 0.6400\n",
            "Epoch 144/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4406 - binary_accuracy: 0.8325 - val_loss: 0.6092 - val_binary_accuracy: 0.6600\n",
            "Epoch 145/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4441 - binary_accuracy: 0.8469 - val_loss: 0.7113 - val_binary_accuracy: 0.5800\n",
            "Epoch 146/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4364 - binary_accuracy: 0.8469 - val_loss: 0.7140 - val_binary_accuracy: 0.5800\n",
            "Epoch 147/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4380 - binary_accuracy: 0.8708 - val_loss: 0.7329 - val_binary_accuracy: 0.5800\n",
            "Epoch 148/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4360 - binary_accuracy: 0.8230 - val_loss: 0.6281 - val_binary_accuracy: 0.6400\n",
            "Epoch 149/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4313 - binary_accuracy: 0.8565 - val_loss: 0.6939 - val_binary_accuracy: 0.5800\n",
            "Epoch 150/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4339 - binary_accuracy: 0.8325 - val_loss: 0.6576 - val_binary_accuracy: 0.6400\n",
            "Epoch 151/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4311 - binary_accuracy: 0.8469 - val_loss: 0.6568 - val_binary_accuracy: 0.6600\n",
            "Epoch 152/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4299 - binary_accuracy: 0.8612 - val_loss: 0.6460 - val_binary_accuracy: 0.6400\n",
            "Epoch 153/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4271 - binary_accuracy: 0.8373 - val_loss: 0.6647 - val_binary_accuracy: 0.6600\n",
            "Epoch 154/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4301 - binary_accuracy: 0.8373 - val_loss: 0.6497 - val_binary_accuracy: 0.6400\n",
            "Epoch 155/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4291 - binary_accuracy: 0.8565 - val_loss: 0.6532 - val_binary_accuracy: 0.6400\n",
            "Epoch 156/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4257 - binary_accuracy: 0.8517 - val_loss: 0.7296 - val_binary_accuracy: 0.5800\n",
            "Epoch 157/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4232 - binary_accuracy: 0.8373 - val_loss: 0.7125 - val_binary_accuracy: 0.5800\n",
            "Epoch 158/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4236 - binary_accuracy: 0.8517 - val_loss: 0.5945 - val_binary_accuracy: 0.6600\n",
            "Epoch 159/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4246 - binary_accuracy: 0.8517 - val_loss: 0.6762 - val_binary_accuracy: 0.6400\n",
            "Epoch 160/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4193 - binary_accuracy: 0.8565 - val_loss: 0.6332 - val_binary_accuracy: 0.6600\n",
            "Epoch 161/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4222 - binary_accuracy: 0.8469 - val_loss: 0.6341 - val_binary_accuracy: 0.6400\n",
            "Epoch 162/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4209 - binary_accuracy: 0.8612 - val_loss: 0.6952 - val_binary_accuracy: 0.6000\n",
            "Epoch 163/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4167 - binary_accuracy: 0.8517 - val_loss: 0.6399 - val_binary_accuracy: 0.6600\n",
            "Epoch 164/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4162 - binary_accuracy: 0.8612 - val_loss: 0.6888 - val_binary_accuracy: 0.6200\n",
            "Epoch 165/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4131 - binary_accuracy: 0.8660 - val_loss: 0.6784 - val_binary_accuracy: 0.6200\n",
            "Epoch 166/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4113 - binary_accuracy: 0.8660 - val_loss: 0.6125 - val_binary_accuracy: 0.6400\n",
            "Epoch 167/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4121 - binary_accuracy: 0.8660 - val_loss: 0.6250 - val_binary_accuracy: 0.6400\n",
            "Epoch 168/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4126 - binary_accuracy: 0.8804 - val_loss: 0.6139 - val_binary_accuracy: 0.6200\n",
            "Epoch 169/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4105 - binary_accuracy: 0.8565 - val_loss: 0.6451 - val_binary_accuracy: 0.6600\n",
            "Epoch 170/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4118 - binary_accuracy: 0.8708 - val_loss: 0.6466 - val_binary_accuracy: 0.6600\n",
            "Epoch 171/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4080 - binary_accuracy: 0.8612 - val_loss: 0.6419 - val_binary_accuracy: 0.6600\n",
            "Epoch 172/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4073 - binary_accuracy: 0.8804 - val_loss: 0.6305 - val_binary_accuracy: 0.6600\n",
            "Epoch 173/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4076 - binary_accuracy: 0.8612 - val_loss: 0.6761 - val_binary_accuracy: 0.6400\n",
            "Epoch 174/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4052 - binary_accuracy: 0.8612 - val_loss: 0.6036 - val_binary_accuracy: 0.6600\n",
            "Epoch 175/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4109 - binary_accuracy: 0.8804 - val_loss: 0.6293 - val_binary_accuracy: 0.6600\n",
            "Epoch 176/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4059 - binary_accuracy: 0.8756 - val_loss: 0.5861 - val_binary_accuracy: 0.6600\n",
            "Epoch 177/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4318 - binary_accuracy: 0.8438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 200ms/step - loss: 0.4043 - binary_accuracy: 0.8325 - val_loss: 0.5395 - val_binary_accuracy: 0.7600\n",
            "Epoch 178/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4107 - binary_accuracy: 0.8804 - val_loss: 0.6364 - val_binary_accuracy: 0.6600\n",
            "Epoch 179/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4012 - binary_accuracy: 0.8852 - val_loss: 0.6297 - val_binary_accuracy: 0.6600\n",
            "Epoch 180/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3963 - binary_accuracy: 0.8852 - val_loss: 0.5879 - val_binary_accuracy: 0.6600\n",
            "Epoch 181/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3991 - binary_accuracy: 0.8756 - val_loss: 0.6654 - val_binary_accuracy: 0.6400\n",
            "Epoch 182/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3960 - binary_accuracy: 0.8708 - val_loss: 0.6476 - val_binary_accuracy: 0.6600\n",
            "Epoch 183/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3966 - binary_accuracy: 0.8708 - val_loss: 0.5938 - val_binary_accuracy: 0.6600\n",
            "Epoch 184/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3993 - binary_accuracy: 0.9043 - val_loss: 0.6625 - val_binary_accuracy: 0.6400\n",
            "Epoch 185/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3894 - binary_accuracy: 0.8804 - val_loss: 0.5902 - val_binary_accuracy: 0.6600\n",
            "Epoch 186/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3895 - binary_accuracy: 0.9043 - val_loss: 0.6422 - val_binary_accuracy: 0.6600\n",
            "Epoch 187/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3897 - binary_accuracy: 0.8852 - val_loss: 0.6780 - val_binary_accuracy: 0.6200\n",
            "Epoch 188/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3916 - binary_accuracy: 0.8660 - val_loss: 0.6394 - val_binary_accuracy: 0.6600\n",
            "Epoch 189/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3854 - binary_accuracy: 0.8995 - val_loss: 0.6836 - val_binary_accuracy: 0.6400\n",
            "Epoch 190/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3885 - binary_accuracy: 0.8900 - val_loss: 0.6247 - val_binary_accuracy: 0.6600\n",
            "Epoch 191/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3835 - binary_accuracy: 0.8852 - val_loss: 0.6576 - val_binary_accuracy: 0.6600\n",
            "Epoch 192/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3894 - binary_accuracy: 0.8708 - val_loss: 0.6707 - val_binary_accuracy: 0.6200\n",
            "Epoch 193/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3852 - binary_accuracy: 0.8900 - val_loss: 0.6318 - val_binary_accuracy: 0.6600\n",
            "Epoch 194/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3799 - binary_accuracy: 0.9043 - val_loss: 0.7066 - val_binary_accuracy: 0.6000\n",
            "Epoch 195/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3846 - binary_accuracy: 0.8852 - val_loss: 0.6958 - val_binary_accuracy: 0.6400\n",
            "Epoch 196/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3796 - binary_accuracy: 0.8804 - val_loss: 0.6220 - val_binary_accuracy: 0.6600\n",
            "Epoch 197/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3782 - binary_accuracy: 0.9139 - val_loss: 0.6330 - val_binary_accuracy: 0.6600\n",
            "Epoch 198/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3785 - binary_accuracy: 0.8947 - val_loss: 0.6244 - val_binary_accuracy: 0.6600\n",
            "Epoch 199/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3778 - binary_accuracy: 0.8947 - val_loss: 0.6678 - val_binary_accuracy: 0.6200\n",
            "Epoch 200/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3785 - binary_accuracy: 0.8947 - val_loss: 0.6684 - val_binary_accuracy: 0.6400\n",
            "Epoch 201/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3751 - binary_accuracy: 0.8995 - val_loss: 0.5993 - val_binary_accuracy: 0.6800\n",
            "Epoch 202/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3741 - binary_accuracy: 0.8995 - val_loss: 0.5582 - val_binary_accuracy: 0.7000\n",
            "Epoch 203/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3751 - binary_accuracy: 0.8900 - val_loss: 0.6177 - val_binary_accuracy: 0.6600\n",
            "Epoch 204/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3699 - binary_accuracy: 0.9091 - val_loss: 0.6809 - val_binary_accuracy: 0.6200\n",
            "Epoch 205/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3734 - binary_accuracy: 0.8947 - val_loss: 0.6674 - val_binary_accuracy: 0.6400\n",
            "Epoch 206/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3728 - binary_accuracy: 0.8900 - val_loss: 0.7012 - val_binary_accuracy: 0.6200\n",
            "Epoch 207/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3677 - binary_accuracy: 0.8852 - val_loss: 0.6648 - val_binary_accuracy: 0.6400\n",
            "Epoch 208/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3656 - binary_accuracy: 0.8995 - val_loss: 0.6836 - val_binary_accuracy: 0.6000\n",
            "Epoch 209/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3668 - binary_accuracy: 0.8852 - val_loss: 0.6544 - val_binary_accuracy: 0.6600\n",
            "Epoch 210/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3645 - binary_accuracy: 0.8900 - val_loss: 0.6612 - val_binary_accuracy: 0.6600\n",
            "Epoch 211/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3673 - binary_accuracy: 0.8995 - val_loss: 0.5896 - val_binary_accuracy: 0.6600\n",
            "Epoch 212/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3633 - binary_accuracy: 0.9043 - val_loss: 0.6875 - val_binary_accuracy: 0.6000\n",
            "Epoch 213/500\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.3291 - binary_accuracy: 0.8750"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131140-cf7esqce/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 167ms/step - loss: 0.3702 - binary_accuracy: 0.8804 - val_loss: 0.5291 - val_binary_accuracy: 0.8000\n",
            "Epoch 214/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3640 - binary_accuracy: 0.8947 - val_loss: 0.6733 - val_binary_accuracy: 0.6600\n",
            "Epoch 215/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3574 - binary_accuracy: 0.9187 - val_loss: 0.6326 - val_binary_accuracy: 0.6600\n",
            "Epoch 216/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3605 - binary_accuracy: 0.9139 - val_loss: 0.7204 - val_binary_accuracy: 0.6000\n",
            "Epoch 217/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3571 - binary_accuracy: 0.8852 - val_loss: 0.5917 - val_binary_accuracy: 0.6800\n",
            "Epoch 218/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3571 - binary_accuracy: 0.9091 - val_loss: 0.5669 - val_binary_accuracy: 0.6800\n",
            "Epoch 219/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3604 - binary_accuracy: 0.8947 - val_loss: 0.7538 - val_binary_accuracy: 0.5800\n",
            "Epoch 220/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3546 - binary_accuracy: 0.8947 - val_loss: 0.6199 - val_binary_accuracy: 0.6600\n",
            "Epoch 221/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3517 - binary_accuracy: 0.9139 - val_loss: 0.6204 - val_binary_accuracy: 0.6600\n",
            "Epoch 222/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3542 - binary_accuracy: 0.8995 - val_loss: 0.6382 - val_binary_accuracy: 0.6600\n",
            "Epoch 223/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3503 - binary_accuracy: 0.8947 - val_loss: 0.5469 - val_binary_accuracy: 0.7400\n",
            "Epoch 224/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3541 - binary_accuracy: 0.9187 - val_loss: 0.7497 - val_binary_accuracy: 0.5800\n",
            "Epoch 225/500\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 0.3490 - binary_accuracy: 0.8947 - val_loss: 0.5940 - val_binary_accuracy: 0.6800\n",
            "Epoch 226/500\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3466 - binary_accuracy: 0.9187 - val_loss: 0.6452 - val_binary_accuracy: 0.6600\n",
            "Epoch 227/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3458 - binary_accuracy: 0.9139 - val_loss: 0.6361 - val_binary_accuracy: 0.6600\n",
            "Epoch 228/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3444 - binary_accuracy: 0.9187 - val_loss: 0.5573 - val_binary_accuracy: 0.7000\n",
            "Epoch 229/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3481 - binary_accuracy: 0.9187 - val_loss: 0.5980 - val_binary_accuracy: 0.6600\n",
            "Epoch 230/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3443 - binary_accuracy: 0.9139 - val_loss: 0.5854 - val_binary_accuracy: 0.6600\n",
            "Epoch 231/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3449 - binary_accuracy: 0.9091 - val_loss: 0.5644 - val_binary_accuracy: 0.7000\n",
            "Epoch 232/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3476 - binary_accuracy: 0.9043 - val_loss: 0.6843 - val_binary_accuracy: 0.6400\n",
            "Epoch 233/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3400 - binary_accuracy: 0.9043 - val_loss: 0.6296 - val_binary_accuracy: 0.6600\n",
            "Epoch 234/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3394 - binary_accuracy: 0.9043 - val_loss: 0.6156 - val_binary_accuracy: 0.6800\n",
            "Epoch 235/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3422 - binary_accuracy: 0.9139 - val_loss: 0.6195 - val_binary_accuracy: 0.6800\n",
            "Epoch 236/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3465 - binary_accuracy: 0.9139 - val_loss: 0.6436 - val_binary_accuracy: 0.6200\n",
            "Epoch 237/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3367 - binary_accuracy: 0.9187 - val_loss: 0.6405 - val_binary_accuracy: 0.6200\n",
            "Epoch 238/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3411 - binary_accuracy: 0.9091 - val_loss: 0.6286 - val_binary_accuracy: 0.6600\n",
            "Epoch 239/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3345 - binary_accuracy: 0.9139 - val_loss: 0.7015 - val_binary_accuracy: 0.6200\n",
            "Epoch 240/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3409 - binary_accuracy: 0.8995 - val_loss: 0.6030 - val_binary_accuracy: 0.6600\n",
            "Epoch 241/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3345 - binary_accuracy: 0.9330 - val_loss: 0.6401 - val_binary_accuracy: 0.6600\n",
            "Epoch 242/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3284 - binary_accuracy: 0.9282 - val_loss: 0.6183 - val_binary_accuracy: 0.6800\n",
            "Epoch 243/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3326 - binary_accuracy: 0.9139 - val_loss: 0.6240 - val_binary_accuracy: 0.6800\n",
            "Epoch 244/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3296 - binary_accuracy: 0.9282 - val_loss: 0.5907 - val_binary_accuracy: 0.6800\n",
            "Epoch 245/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3306 - binary_accuracy: 0.9330 - val_loss: 0.6140 - val_binary_accuracy: 0.6800\n",
            "Epoch 246/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3255 - binary_accuracy: 0.9330 - val_loss: 0.6297 - val_binary_accuracy: 0.6600\n",
            "Epoch 247/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3237 - binary_accuracy: 0.9234 - val_loss: 0.6152 - val_binary_accuracy: 0.6800\n",
            "Epoch 248/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3259 - binary_accuracy: 0.9139 - val_loss: 0.5935 - val_binary_accuracy: 0.6400\n",
            "Epoch 249/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3243 - binary_accuracy: 0.9139 - val_loss: 0.6235 - val_binary_accuracy: 0.6800\n",
            "Epoch 250/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3236 - binary_accuracy: 0.9187 - val_loss: 0.6064 - val_binary_accuracy: 0.6600\n",
            "Epoch 251/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3203 - binary_accuracy: 0.9234 - val_loss: 0.5849 - val_binary_accuracy: 0.7000\n",
            "Epoch 252/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3247 - binary_accuracy: 0.9282 - val_loss: 0.6007 - val_binary_accuracy: 0.6600\n",
            "Epoch 253/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3212 - binary_accuracy: 0.9282 - val_loss: 0.6112 - val_binary_accuracy: 0.6600\n",
            "Epoch 254/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3208 - binary_accuracy: 0.9330 - val_loss: 0.5750 - val_binary_accuracy: 0.6800\n",
            "Epoch 255/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3226 - binary_accuracy: 0.9234 - val_loss: 0.5935 - val_binary_accuracy: 0.6800\n",
            "Epoch 256/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3287 - binary_accuracy: 0.9043 - val_loss: 0.6127 - val_binary_accuracy: 0.6400\n",
            "Epoch 257/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3164 - binary_accuracy: 0.9282 - val_loss: 0.6588 - val_binary_accuracy: 0.6200\n",
            "Epoch 258/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3138 - binary_accuracy: 0.9282 - val_loss: 0.6194 - val_binary_accuracy: 0.6800\n",
            "Epoch 259/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3116 - binary_accuracy: 0.9282 - val_loss: 0.6711 - val_binary_accuracy: 0.6200\n",
            "Epoch 260/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3146 - binary_accuracy: 0.9330 - val_loss: 0.6220 - val_binary_accuracy: 0.6600\n",
            "Epoch 261/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3108 - binary_accuracy: 0.9282 - val_loss: 0.6295 - val_binary_accuracy: 0.6600\n",
            "Epoch 262/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3082 - binary_accuracy: 0.9234 - val_loss: 0.6968 - val_binary_accuracy: 0.6400\n",
            "Epoch 263/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3124 - binary_accuracy: 0.9091 - val_loss: 0.6625 - val_binary_accuracy: 0.6200\n",
            "Epoch 264/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3100 - binary_accuracy: 0.9330 - val_loss: 0.5813 - val_binary_accuracy: 0.6800\n",
            "Epoch 265/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3111 - binary_accuracy: 0.9187 - val_loss: 0.5691 - val_binary_accuracy: 0.6800\n",
            "Epoch 266/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3080 - binary_accuracy: 0.9378 - val_loss: 0.6307 - val_binary_accuracy: 0.6600\n",
            "Epoch 267/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3065 - binary_accuracy: 0.9282 - val_loss: 0.6544 - val_binary_accuracy: 0.6400\n",
            "Epoch 268/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3038 - binary_accuracy: 0.9282 - val_loss: 0.7277 - val_binary_accuracy: 0.6200\n",
            "Epoch 269/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3040 - binary_accuracy: 0.9282 - val_loss: 0.5817 - val_binary_accuracy: 0.7000\n",
            "Epoch 270/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3048 - binary_accuracy: 0.9234 - val_loss: 0.6449 - val_binary_accuracy: 0.6200\n",
            "Epoch 271/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3041 - binary_accuracy: 0.9378 - val_loss: 0.5916 - val_binary_accuracy: 0.6800\n",
            "Epoch 272/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3035 - binary_accuracy: 0.9330 - val_loss: 0.5602 - val_binary_accuracy: 0.7000\n",
            "Epoch 273/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2977 - binary_accuracy: 0.9378 - val_loss: 0.6752 - val_binary_accuracy: 0.6400\n",
            "Epoch 274/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2975 - binary_accuracy: 0.9330 - val_loss: 0.6158 - val_binary_accuracy: 0.6400\n",
            "Epoch 275/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2999 - binary_accuracy: 0.9282 - val_loss: 0.6608 - val_binary_accuracy: 0.6400\n",
            "Epoch 276/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3001 - binary_accuracy: 0.9282 - val_loss: 0.5797 - val_binary_accuracy: 0.7000\n",
            "Epoch 277/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2938 - binary_accuracy: 0.9426 - val_loss: 0.6686 - val_binary_accuracy: 0.6200\n",
            "Epoch 278/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2970 - binary_accuracy: 0.9282 - val_loss: 0.6542 - val_binary_accuracy: 0.6200\n",
            "Epoch 279/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2929 - binary_accuracy: 0.9330 - val_loss: 0.6226 - val_binary_accuracy: 0.6400\n",
            "Epoch 280/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2935 - binary_accuracy: 0.9330 - val_loss: 0.6552 - val_binary_accuracy: 0.6400\n",
            "Epoch 281/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2900 - binary_accuracy: 0.9234 - val_loss: 0.5834 - val_binary_accuracy: 0.6800\n",
            "Epoch 282/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2889 - binary_accuracy: 0.9378 - val_loss: 0.7140 - val_binary_accuracy: 0.6200\n",
            "Epoch 283/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2967 - binary_accuracy: 0.9139 - val_loss: 0.5424 - val_binary_accuracy: 0.7600\n",
            "Epoch 284/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2960 - binary_accuracy: 0.9378 - val_loss: 0.6089 - val_binary_accuracy: 0.6400\n",
            "Epoch 285/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2860 - binary_accuracy: 0.9426 - val_loss: 0.5544 - val_binary_accuracy: 0.7200\n",
            "Epoch 286/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2843 - binary_accuracy: 0.9378 - val_loss: 0.6708 - val_binary_accuracy: 0.6200\n",
            "Epoch 287/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2861 - binary_accuracy: 0.9426 - val_loss: 0.6258 - val_binary_accuracy: 0.6400\n",
            "Epoch 288/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2873 - binary_accuracy: 0.9330 - val_loss: 0.6495 - val_binary_accuracy: 0.6600\n",
            "Epoch 289/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2875 - binary_accuracy: 0.9330 - val_loss: 0.5493 - val_binary_accuracy: 0.7400\n",
            "Epoch 290/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2866 - binary_accuracy: 0.9282 - val_loss: 0.5616 - val_binary_accuracy: 0.7000\n",
            "Epoch 291/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2869 - binary_accuracy: 0.9426 - val_loss: 0.6635 - val_binary_accuracy: 0.6400\n",
            "Epoch 292/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2863 - binary_accuracy: 0.9378 - val_loss: 0.5580 - val_binary_accuracy: 0.7000\n",
            "Epoch 293/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2805 - binary_accuracy: 0.9426 - val_loss: 0.6536 - val_binary_accuracy: 0.6600\n",
            "Epoch 294/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2810 - binary_accuracy: 0.9426 - val_loss: 0.6619 - val_binary_accuracy: 0.6400\n",
            "Epoch 295/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2811 - binary_accuracy: 0.9474 - val_loss: 0.6720 - val_binary_accuracy: 0.6200\n",
            "Epoch 296/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2764 - binary_accuracy: 0.9330 - val_loss: 0.6460 - val_binary_accuracy: 0.6600\n",
            "Epoch 297/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2756 - binary_accuracy: 0.9378 - val_loss: 0.5892 - val_binary_accuracy: 0.6800\n",
            "Epoch 298/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2878 - binary_accuracy: 0.9234 - val_loss: 0.6105 - val_binary_accuracy: 0.6400\n",
            "Epoch 299/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2753 - binary_accuracy: 0.9426 - val_loss: 0.6089 - val_binary_accuracy: 0.6400\n",
            "Epoch 300/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2727 - binary_accuracy: 0.9474 - val_loss: 0.6492 - val_binary_accuracy: 0.6600\n",
            "Epoch 301/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2737 - binary_accuracy: 0.9378 - val_loss: 0.5900 - val_binary_accuracy: 0.6600\n",
            "Epoch 302/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2742 - binary_accuracy: 0.9378 - val_loss: 0.6178 - val_binary_accuracy: 0.6400\n",
            "Epoch 303/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2740 - binary_accuracy: 0.9474 - val_loss: 0.5782 - val_binary_accuracy: 0.6600\n",
            "Epoch 304/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2737 - binary_accuracy: 0.9426 - val_loss: 0.6211 - val_binary_accuracy: 0.6400\n",
            "Epoch 305/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2724 - binary_accuracy: 0.9426 - val_loss: 0.6932 - val_binary_accuracy: 0.6400\n",
            "Epoch 306/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2691 - binary_accuracy: 0.9474 - val_loss: 0.6938 - val_binary_accuracy: 0.6400\n",
            "Epoch 307/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2756 - binary_accuracy: 0.9234 - val_loss: 0.5804 - val_binary_accuracy: 0.6800\n",
            "Epoch 308/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2663 - binary_accuracy: 0.9522 - val_loss: 0.6528 - val_binary_accuracy: 0.6400\n",
            "Epoch 309/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2660 - binary_accuracy: 0.9522 - val_loss: 0.6463 - val_binary_accuracy: 0.6400\n",
            "Epoch 310/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2683 - binary_accuracy: 0.9234 - val_loss: 0.5821 - val_binary_accuracy: 0.6600\n",
            "Epoch 311/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2675 - binary_accuracy: 0.9474 - val_loss: 0.6067 - val_binary_accuracy: 0.6600\n",
            "Epoch 312/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2649 - binary_accuracy: 0.9474 - val_loss: 0.6672 - val_binary_accuracy: 0.6600\n",
            "Epoch 313/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2629 - binary_accuracy: 0.9378 - val_loss: 0.5992 - val_binary_accuracy: 0.6600\n",
            "Epoch 314/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2618 - binary_accuracy: 0.9474 - val_loss: 0.5725 - val_binary_accuracy: 0.6600\n",
            "Epoch 315/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2640 - binary_accuracy: 0.9474 - val_loss: 0.6756 - val_binary_accuracy: 0.6400\n",
            "Epoch 316/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2687 - binary_accuracy: 0.9378 - val_loss: 0.6097 - val_binary_accuracy: 0.6400\n",
            "Epoch 317/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2591 - binary_accuracy: 0.9522 - val_loss: 0.6916 - val_binary_accuracy: 0.6400\n",
            "Epoch 318/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2574 - binary_accuracy: 0.9474 - val_loss: 0.6044 - val_binary_accuracy: 0.6600\n",
            "Epoch 319/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2578 - binary_accuracy: 0.9426 - val_loss: 0.5713 - val_binary_accuracy: 0.6800\n",
            "Epoch 320/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2604 - binary_accuracy: 0.9426 - val_loss: 0.6076 - val_binary_accuracy: 0.6400\n",
            "Epoch 321/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2532 - binary_accuracy: 0.9474 - val_loss: 0.6665 - val_binary_accuracy: 0.6800\n",
            "Epoch 322/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2575 - binary_accuracy: 0.9330 - val_loss: 0.7384 - val_binary_accuracy: 0.6200\n",
            "Epoch 323/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2560 - binary_accuracy: 0.9330 - val_loss: 0.7078 - val_binary_accuracy: 0.6400\n",
            "Epoch 324/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2547 - binary_accuracy: 0.9474 - val_loss: 0.6014 - val_binary_accuracy: 0.6600\n",
            "Epoch 325/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2546 - binary_accuracy: 0.9426 - val_loss: 0.6585 - val_binary_accuracy: 0.6400\n",
            "Epoch 326/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2527 - binary_accuracy: 0.9426 - val_loss: 0.6968 - val_binary_accuracy: 0.6400\n",
            "Epoch 327/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2542 - binary_accuracy: 0.9426 - val_loss: 0.5986 - val_binary_accuracy: 0.6600\n",
            "Epoch 328/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2573 - binary_accuracy: 0.9378 - val_loss: 0.6653 - val_binary_accuracy: 0.6200\n",
            "Epoch 329/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2484 - binary_accuracy: 0.9569 - val_loss: 0.6382 - val_binary_accuracy: 0.6400\n",
            "Epoch 330/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2514 - binary_accuracy: 0.9378 - val_loss: 0.6040 - val_binary_accuracy: 0.6600\n",
            "Epoch 331/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2546 - binary_accuracy: 0.9378 - val_loss: 0.5745 - val_binary_accuracy: 0.6800\n",
            "Epoch 332/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2481 - binary_accuracy: 0.9426 - val_loss: 0.6757 - val_binary_accuracy: 0.6800\n",
            "Epoch 333/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2489 - binary_accuracy: 0.9426 - val_loss: 0.6465 - val_binary_accuracy: 0.6400\n",
            "Epoch 334/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2479 - binary_accuracy: 0.9474 - val_loss: 0.7495 - val_binary_accuracy: 0.6200\n",
            "Epoch 335/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2452 - binary_accuracy: 0.9474 - val_loss: 0.6026 - val_binary_accuracy: 0.6800\n",
            "Epoch 336/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2455 - binary_accuracy: 0.9426 - val_loss: 0.6412 - val_binary_accuracy: 0.6400\n",
            "Epoch 337/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2433 - binary_accuracy: 0.9522 - val_loss: 0.6044 - val_binary_accuracy: 0.6600\n",
            "Epoch 338/500\n",
            "7/7 [==============================] - 0s 26ms/step - loss: 0.2432 - binary_accuracy: 0.9474 - val_loss: 0.6569 - val_binary_accuracy: 0.6400\n",
            "Epoch 339/500\n",
            "7/7 [==============================] - 0s 58ms/step - loss: 0.2387 - binary_accuracy: 0.9522 - val_loss: 0.5711 - val_binary_accuracy: 0.7200\n",
            "Epoch 340/500\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.2402 - binary_accuracy: 0.9426 - val_loss: 0.7433 - val_binary_accuracy: 0.6200\n",
            "Epoch 341/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2427 - binary_accuracy: 0.9426 - val_loss: 0.5751 - val_binary_accuracy: 0.7000\n",
            "Epoch 342/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2430 - binary_accuracy: 0.9665 - val_loss: 0.6779 - val_binary_accuracy: 0.6600\n",
            "Epoch 343/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2366 - binary_accuracy: 0.9569 - val_loss: 0.6301 - val_binary_accuracy: 0.6600\n",
            "Epoch 344/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2361 - binary_accuracy: 0.9617 - val_loss: 0.5926 - val_binary_accuracy: 0.6600\n",
            "Epoch 345/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2413 - binary_accuracy: 0.9474 - val_loss: 0.6399 - val_binary_accuracy: 0.6600\n",
            "Epoch 346/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2393 - binary_accuracy: 0.9474 - val_loss: 0.6498 - val_binary_accuracy: 0.6200\n",
            "Epoch 347/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2342 - binary_accuracy: 0.9617 - val_loss: 0.6064 - val_binary_accuracy: 0.6600\n",
            "Epoch 348/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2339 - binary_accuracy: 0.9569 - val_loss: 0.6757 - val_binary_accuracy: 0.6600\n",
            "Epoch 349/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2326 - binary_accuracy: 0.9569 - val_loss: 0.6490 - val_binary_accuracy: 0.6400\n",
            "Epoch 350/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2366 - binary_accuracy: 0.9617 - val_loss: 0.6102 - val_binary_accuracy: 0.6600\n",
            "Epoch 351/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2318 - binary_accuracy: 0.9569 - val_loss: 0.6093 - val_binary_accuracy: 0.6600\n",
            "Epoch 352/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2316 - binary_accuracy: 0.9617 - val_loss: 0.6155 - val_binary_accuracy: 0.6600\n",
            "Epoch 353/500\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.2285 - binary_accuracy: 0.9617 - val_loss: 0.6487 - val_binary_accuracy: 0.6600\n",
            "Epoch 354/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2288 - binary_accuracy: 0.9569 - val_loss: 0.7000 - val_binary_accuracy: 0.6400\n",
            "Epoch 355/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2327 - binary_accuracy: 0.9522 - val_loss: 0.5710 - val_binary_accuracy: 0.7200\n",
            "Epoch 356/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2277 - binary_accuracy: 0.9569 - val_loss: 0.6573 - val_binary_accuracy: 0.6400\n",
            "Epoch 357/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2266 - binary_accuracy: 0.9569 - val_loss: 0.6595 - val_binary_accuracy: 0.6400\n",
            "Epoch 358/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2274 - binary_accuracy: 0.9426 - val_loss: 0.6120 - val_binary_accuracy: 0.6600\n",
            "Epoch 359/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2246 - binary_accuracy: 0.9569 - val_loss: 0.6403 - val_binary_accuracy: 0.6400\n",
            "Epoch 360/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2229 - binary_accuracy: 0.9665 - val_loss: 0.6032 - val_binary_accuracy: 0.6600\n",
            "Epoch 361/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.2235 - binary_accuracy: 0.9569 - val_loss: 0.6310 - val_binary_accuracy: 0.6400\n",
            "Epoch 362/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2210 - binary_accuracy: 0.9617 - val_loss: 0.6095 - val_binary_accuracy: 0.6600\n",
            "Epoch 363/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2197 - binary_accuracy: 0.9569 - val_loss: 0.6158 - val_binary_accuracy: 0.6600\n",
            "Epoch 364/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2221 - binary_accuracy: 0.9522 - val_loss: 0.5732 - val_binary_accuracy: 0.7200\n",
            "Epoch 365/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2256 - binary_accuracy: 0.9522 - val_loss: 0.5950 - val_binary_accuracy: 0.6600\n",
            "Epoch 366/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2201 - binary_accuracy: 0.9569 - val_loss: 0.5929 - val_binary_accuracy: 0.6600\n",
            "Epoch 367/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2194 - binary_accuracy: 0.9713 - val_loss: 0.6800 - val_binary_accuracy: 0.6600\n",
            "Epoch 368/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2184 - binary_accuracy: 0.9665 - val_loss: 0.6554 - val_binary_accuracy: 0.6400\n",
            "Epoch 369/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2148 - binary_accuracy: 0.9617 - val_loss: 0.7069 - val_binary_accuracy: 0.6800\n",
            "Epoch 370/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2230 - binary_accuracy: 0.9617 - val_loss: 0.6359 - val_binary_accuracy: 0.6400\n",
            "Epoch 371/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2155 - binary_accuracy: 0.9617 - val_loss: 0.5538 - val_binary_accuracy: 0.7600\n",
            "Epoch 372/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2220 - binary_accuracy: 0.9713 - val_loss: 0.5934 - val_binary_accuracy: 0.7000\n",
            "Epoch 373/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2153 - binary_accuracy: 0.9665 - val_loss: 0.6282 - val_binary_accuracy: 0.6400\n",
            "Epoch 374/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2115 - binary_accuracy: 0.9569 - val_loss: 0.6031 - val_binary_accuracy: 0.6600\n",
            "Epoch 375/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2117 - binary_accuracy: 0.9617 - val_loss: 0.6243 - val_binary_accuracy: 0.6400\n",
            "Epoch 376/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2107 - binary_accuracy: 0.9665 - val_loss: 0.7502 - val_binary_accuracy: 0.6400\n",
            "Epoch 377/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2138 - binary_accuracy: 0.9474 - val_loss: 0.5934 - val_binary_accuracy: 0.6800\n",
            "Epoch 378/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2103 - binary_accuracy: 0.9617 - val_loss: 0.7121 - val_binary_accuracy: 0.6400\n",
            "Epoch 379/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2137 - binary_accuracy: 0.9665 - val_loss: 0.5842 - val_binary_accuracy: 0.7200\n",
            "Epoch 380/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2098 - binary_accuracy: 0.9665 - val_loss: 0.6768 - val_binary_accuracy: 0.6600\n",
            "Epoch 381/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2060 - binary_accuracy: 0.9665 - val_loss: 0.6428 - val_binary_accuracy: 0.6400\n",
            "Epoch 382/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2065 - binary_accuracy: 0.9617 - val_loss: 0.7810 - val_binary_accuracy: 0.6200\n",
            "Epoch 383/500\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.2112 - binary_accuracy: 0.9474 - val_loss: 0.6297 - val_binary_accuracy: 0.6600\n",
            "Epoch 384/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.2047 - binary_accuracy: 0.9665 - val_loss: 0.7149 - val_binary_accuracy: 0.6400\n",
            "Epoch 385/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2072 - binary_accuracy: 0.9617 - val_loss: 0.5587 - val_binary_accuracy: 0.7400\n",
            "Epoch 386/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2040 - binary_accuracy: 0.9665 - val_loss: 0.6403 - val_binary_accuracy: 0.6400\n",
            "Epoch 387/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2048 - binary_accuracy: 0.9713 - val_loss: 0.6479 - val_binary_accuracy: 0.6400\n",
            "Epoch 388/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2036 - binary_accuracy: 0.9665 - val_loss: 0.6232 - val_binary_accuracy: 0.6600\n",
            "Epoch 389/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.2016 - binary_accuracy: 0.9665 - val_loss: 0.5740 - val_binary_accuracy: 0.7400\n",
            "Epoch 390/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2104 - binary_accuracy: 0.9617 - val_loss: 0.6541 - val_binary_accuracy: 0.6400\n",
            "Epoch 391/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1998 - binary_accuracy: 0.9665 - val_loss: 0.6172 - val_binary_accuracy: 0.6600\n",
            "Epoch 392/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1997 - binary_accuracy: 0.9761 - val_loss: 0.6478 - val_binary_accuracy: 0.6400\n",
            "Epoch 393/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1991 - binary_accuracy: 0.9665 - val_loss: 0.8211 - val_binary_accuracy: 0.6200\n",
            "Epoch 394/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2087 - binary_accuracy: 0.9522 - val_loss: 0.5516 - val_binary_accuracy: 0.7400\n",
            "Epoch 395/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1978 - binary_accuracy: 0.9617 - val_loss: 0.8407 - val_binary_accuracy: 0.6000\n",
            "Epoch 396/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2029 - binary_accuracy: 0.9569 - val_loss: 0.6546 - val_binary_accuracy: 0.6400\n",
            "Epoch 397/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1955 - binary_accuracy: 0.9713 - val_loss: 0.6491 - val_binary_accuracy: 0.6400\n",
            "Epoch 398/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2000 - binary_accuracy: 0.9665 - val_loss: 0.5813 - val_binary_accuracy: 0.7400\n",
            "Epoch 399/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1928 - binary_accuracy: 0.9713 - val_loss: 0.7924 - val_binary_accuracy: 0.6200\n",
            "Epoch 400/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1972 - binary_accuracy: 0.9713 - val_loss: 0.6499 - val_binary_accuracy: 0.6400\n",
            "Epoch 401/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1950 - binary_accuracy: 0.9713 - val_loss: 0.6789 - val_binary_accuracy: 0.6800\n",
            "Epoch 402/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1927 - binary_accuracy: 0.9713 - val_loss: 0.6639 - val_binary_accuracy: 0.6600\n",
            "Epoch 403/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1914 - binary_accuracy: 0.9665 - val_loss: 0.6289 - val_binary_accuracy: 0.6800\n",
            "Epoch 404/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1916 - binary_accuracy: 0.9761 - val_loss: 0.6422 - val_binary_accuracy: 0.6400\n",
            "Epoch 405/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1886 - binary_accuracy: 0.9713 - val_loss: 0.7102 - val_binary_accuracy: 0.6400\n",
            "Epoch 406/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1953 - binary_accuracy: 0.9665 - val_loss: 0.7010 - val_binary_accuracy: 0.6600\n",
            "Epoch 407/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1894 - binary_accuracy: 0.9713 - val_loss: 0.6918 - val_binary_accuracy: 0.6600\n",
            "Epoch 408/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1877 - binary_accuracy: 0.9761 - val_loss: 0.5981 - val_binary_accuracy: 0.7000\n",
            "Epoch 409/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1993 - binary_accuracy: 0.9569 - val_loss: 0.6340 - val_binary_accuracy: 0.6800\n",
            "Epoch 410/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1852 - binary_accuracy: 0.9713 - val_loss: 0.6810 - val_binary_accuracy: 0.6800\n",
            "Epoch 411/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1854 - binary_accuracy: 0.9761 - val_loss: 0.6586 - val_binary_accuracy: 0.6400\n",
            "Epoch 412/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1881 - binary_accuracy: 0.9617 - val_loss: 0.6105 - val_binary_accuracy: 0.7000\n",
            "Epoch 413/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1914 - binary_accuracy: 0.9569 - val_loss: 0.6329 - val_binary_accuracy: 0.6800\n",
            "Epoch 414/500\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1867 - binary_accuracy: 0.9713 - val_loss: 0.6440 - val_binary_accuracy: 0.6600\n",
            "Epoch 415/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1835 - binary_accuracy: 0.9761 - val_loss: 0.6739 - val_binary_accuracy: 0.6800\n",
            "Epoch 416/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1820 - binary_accuracy: 0.9761 - val_loss: 0.8082 - val_binary_accuracy: 0.6200\n",
            "Epoch 417/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1894 - binary_accuracy: 0.9522 - val_loss: 0.6808 - val_binary_accuracy: 0.6800\n",
            "Epoch 418/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1827 - binary_accuracy: 0.9761 - val_loss: 0.7094 - val_binary_accuracy: 0.6400\n",
            "Epoch 419/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1877 - binary_accuracy: 0.9617 - val_loss: 0.7161 - val_binary_accuracy: 0.6400\n",
            "Epoch 420/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1786 - binary_accuracy: 0.9713 - val_loss: 0.6147 - val_binary_accuracy: 0.7000\n",
            "Epoch 421/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1892 - binary_accuracy: 0.9617 - val_loss: 0.6550 - val_binary_accuracy: 0.6400\n",
            "Epoch 422/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1792 - binary_accuracy: 0.9761 - val_loss: 0.7260 - val_binary_accuracy: 0.6600\n",
            "Epoch 423/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1797 - binary_accuracy: 0.9713 - val_loss: 0.5797 - val_binary_accuracy: 0.7200\n",
            "Epoch 424/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1832 - binary_accuracy: 0.9665 - val_loss: 0.6412 - val_binary_accuracy: 0.6800\n",
            "Epoch 425/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1762 - binary_accuracy: 0.9761 - val_loss: 0.6503 - val_binary_accuracy: 0.6600\n",
            "Epoch 426/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1791 - binary_accuracy: 0.9713 - val_loss: 0.6543 - val_binary_accuracy: 0.6600\n",
            "Epoch 427/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1805 - binary_accuracy: 0.9665 - val_loss: 0.7623 - val_binary_accuracy: 0.6000\n",
            "Epoch 428/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1803 - binary_accuracy: 0.9617 - val_loss: 0.6350 - val_binary_accuracy: 0.6800\n",
            "Epoch 429/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1758 - binary_accuracy: 0.9713 - val_loss: 0.7819 - val_binary_accuracy: 0.6000\n",
            "Epoch 430/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1870 - binary_accuracy: 0.9713 - val_loss: 0.6428 - val_binary_accuracy: 0.6800\n",
            "Epoch 431/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1758 - binary_accuracy: 0.9761 - val_loss: 0.6795 - val_binary_accuracy: 0.6400\n",
            "Epoch 432/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1720 - binary_accuracy: 0.9761 - val_loss: 0.7148 - val_binary_accuracy: 0.6600\n",
            "Epoch 433/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1712 - binary_accuracy: 0.9809 - val_loss: 0.6400 - val_binary_accuracy: 0.6800\n",
            "Epoch 434/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1699 - binary_accuracy: 0.9809 - val_loss: 0.6851 - val_binary_accuracy: 0.6600\n",
            "Epoch 435/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1745 - binary_accuracy: 0.9809 - val_loss: 0.6127 - val_binary_accuracy: 0.7000\n",
            "Epoch 436/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1708 - binary_accuracy: 0.9809 - val_loss: 0.6505 - val_binary_accuracy: 0.6800\n",
            "Epoch 437/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1698 - binary_accuracy: 0.9713 - val_loss: 0.7395 - val_binary_accuracy: 0.6400\n",
            "Epoch 438/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1660 - binary_accuracy: 0.9761 - val_loss: 0.5797 - val_binary_accuracy: 0.7200\n",
            "Epoch 439/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1785 - binary_accuracy: 0.9617 - val_loss: 0.6947 - val_binary_accuracy: 0.6600\n",
            "Epoch 440/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1702 - binary_accuracy: 0.9665 - val_loss: 0.6864 - val_binary_accuracy: 0.6600\n",
            "Epoch 441/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1669 - binary_accuracy: 0.9761 - val_loss: 0.6533 - val_binary_accuracy: 0.6800\n",
            "Epoch 442/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1658 - binary_accuracy: 0.9761 - val_loss: 0.6327 - val_binary_accuracy: 0.7000\n",
            "Epoch 443/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1681 - binary_accuracy: 0.9713 - val_loss: 0.7932 - val_binary_accuracy: 0.6000\n",
            "Epoch 444/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1661 - binary_accuracy: 0.9665 - val_loss: 0.6847 - val_binary_accuracy: 0.6400\n",
            "Epoch 445/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1716 - binary_accuracy: 0.9713 - val_loss: 0.6114 - val_binary_accuracy: 0.6800\n",
            "Epoch 446/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1683 - binary_accuracy: 0.9665 - val_loss: 0.6516 - val_binary_accuracy: 0.6800\n",
            "Epoch 447/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1632 - binary_accuracy: 0.9809 - val_loss: 0.6588 - val_binary_accuracy: 0.6800\n",
            "Epoch 448/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1641 - binary_accuracy: 0.9761 - val_loss: 0.6553 - val_binary_accuracy: 0.6800\n",
            "Epoch 449/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1605 - binary_accuracy: 0.9761 - val_loss: 0.6815 - val_binary_accuracy: 0.6400\n",
            "Epoch 450/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1618 - binary_accuracy: 0.9761 - val_loss: 0.7653 - val_binary_accuracy: 0.6400\n",
            "Epoch 451/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1671 - binary_accuracy: 0.9665 - val_loss: 0.6378 - val_binary_accuracy: 0.7000\n",
            "Epoch 452/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1701 - binary_accuracy: 0.9761 - val_loss: 0.6365 - val_binary_accuracy: 0.7000\n",
            "Epoch 453/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1591 - binary_accuracy: 0.9809 - val_loss: 0.6645 - val_binary_accuracy: 0.6800\n",
            "Epoch 454/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1591 - binary_accuracy: 0.9809 - val_loss: 0.6602 - val_binary_accuracy: 0.6800\n",
            "Epoch 455/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1630 - binary_accuracy: 0.9713 - val_loss: 0.6107 - val_binary_accuracy: 0.7000\n",
            "Epoch 456/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1598 - binary_accuracy: 0.9761 - val_loss: 0.6921 - val_binary_accuracy: 0.6600\n",
            "Epoch 457/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1593 - binary_accuracy: 0.9761 - val_loss: 0.6248 - val_binary_accuracy: 0.6800\n",
            "Epoch 458/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1588 - binary_accuracy: 0.9713 - val_loss: 0.7341 - val_binary_accuracy: 0.6600\n",
            "Epoch 459/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1561 - binary_accuracy: 0.9761 - val_loss: 0.6684 - val_binary_accuracy: 0.6800\n",
            "Epoch 460/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1559 - binary_accuracy: 0.9761 - val_loss: 0.7395 - val_binary_accuracy: 0.6600\n",
            "Epoch 461/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1551 - binary_accuracy: 0.9761 - val_loss: 0.7060 - val_binary_accuracy: 0.6600\n",
            "Epoch 462/500\n",
            "7/7 [==============================] - 0s 30ms/step - loss: 0.1562 - binary_accuracy: 0.9809 - val_loss: 0.8116 - val_binary_accuracy: 0.6000\n",
            "Epoch 463/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1629 - binary_accuracy: 0.9713 - val_loss: 0.7503 - val_binary_accuracy: 0.6200\n",
            "Epoch 464/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1532 - binary_accuracy: 0.9809 - val_loss: 0.5970 - val_binary_accuracy: 0.7000\n",
            "Epoch 465/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1563 - binary_accuracy: 0.9761 - val_loss: 0.7447 - val_binary_accuracy: 0.6600\n",
            "Epoch 466/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1557 - binary_accuracy: 0.9665 - val_loss: 0.6339 - val_binary_accuracy: 0.6800\n",
            "Epoch 467/500\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.1547 - binary_accuracy: 0.9761 - val_loss: 0.6464 - val_binary_accuracy: 0.6800\n",
            "Epoch 468/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1516 - binary_accuracy: 0.9809 - val_loss: 0.6324 - val_binary_accuracy: 0.6800\n",
            "Epoch 469/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1527 - binary_accuracy: 0.9809 - val_loss: 0.6814 - val_binary_accuracy: 0.6800\n",
            "Epoch 470/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1519 - binary_accuracy: 0.9761 - val_loss: 0.6904 - val_binary_accuracy: 0.7000\n",
            "Epoch 471/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1505 - binary_accuracy: 0.9761 - val_loss: 0.6676 - val_binary_accuracy: 0.6800\n",
            "Epoch 472/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1509 - binary_accuracy: 0.9809 - val_loss: 0.8205 - val_binary_accuracy: 0.6000\n",
            "Epoch 473/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1508 - binary_accuracy: 0.9809 - val_loss: 0.6671 - val_binary_accuracy: 0.6800\n",
            "Epoch 474/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1470 - binary_accuracy: 0.9809 - val_loss: 0.7058 - val_binary_accuracy: 0.6600\n",
            "Epoch 475/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1465 - binary_accuracy: 0.9809 - val_loss: 0.7991 - val_binary_accuracy: 0.6000\n",
            "Epoch 476/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1491 - binary_accuracy: 0.9809 - val_loss: 0.7097 - val_binary_accuracy: 0.6600\n",
            "Epoch 477/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1453 - binary_accuracy: 0.9856 - val_loss: 0.7518 - val_binary_accuracy: 0.6600\n",
            "Epoch 478/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1476 - binary_accuracy: 0.9856 - val_loss: 0.7156 - val_binary_accuracy: 0.6600\n",
            "Epoch 479/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1480 - binary_accuracy: 0.9761 - val_loss: 0.8120 - val_binary_accuracy: 0.6000\n",
            "Epoch 480/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1508 - binary_accuracy: 0.9856 - val_loss: 0.7003 - val_binary_accuracy: 0.7000\n",
            "Epoch 481/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1474 - binary_accuracy: 0.9856 - val_loss: 0.6964 - val_binary_accuracy: 0.7000\n",
            "Epoch 482/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1480 - binary_accuracy: 0.9761 - val_loss: 0.7662 - val_binary_accuracy: 0.6400\n",
            "Epoch 483/500\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1495 - binary_accuracy: 0.9856 - val_loss: 0.7242 - val_binary_accuracy: 0.6600\n",
            "Epoch 484/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1481 - binary_accuracy: 0.9809 - val_loss: 0.6777 - val_binary_accuracy: 0.6800\n",
            "Epoch 485/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1422 - binary_accuracy: 0.9856 - val_loss: 0.7241 - val_binary_accuracy: 0.6600\n",
            "Epoch 486/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1431 - binary_accuracy: 0.9904 - val_loss: 0.6772 - val_binary_accuracy: 0.6800\n",
            "Epoch 487/500\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1409 - binary_accuracy: 0.9856 - val_loss: 0.7075 - val_binary_accuracy: 0.7000\n",
            "Epoch 488/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1424 - binary_accuracy: 0.9809 - val_loss: 0.7664 - val_binary_accuracy: 0.6600\n",
            "Epoch 489/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1383 - binary_accuracy: 0.9856 - val_loss: 0.6143 - val_binary_accuracy: 0.7000\n",
            "Epoch 490/500\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.1439 - binary_accuracy: 0.9761 - val_loss: 0.6003 - val_binary_accuracy: 0.7000\n",
            "Epoch 491/500\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.1389 - binary_accuracy: 0.9809 - val_loss: 0.7845 - val_binary_accuracy: 0.6200\n",
            "Epoch 492/500\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.1386 - binary_accuracy: 0.9904 - val_loss: 0.7038 - val_binary_accuracy: 0.7000\n",
            "Epoch 493/500\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.1441 - binary_accuracy: 0.9856 - val_loss: 0.6541 - val_binary_accuracy: 0.6800\n",
            "Epoch 494/500\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.1410 - binary_accuracy: 0.9904 - val_loss: 0.6936 - val_binary_accuracy: 0.6800\n",
            "Epoch 495/500\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1411 - binary_accuracy: 0.9856 - val_loss: 0.6363 - val_binary_accuracy: 0.7000\n",
            "Epoch 496/500\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1391 - binary_accuracy: 0.9761 - val_loss: 0.8116 - val_binary_accuracy: 0.6200\n",
            "Epoch 497/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1351 - binary_accuracy: 0.9809 - val_loss: 0.6801 - val_binary_accuracy: 0.6600\n",
            "Epoch 498/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1344 - binary_accuracy: 0.9856 - val_loss: 0.7460 - val_binary_accuracy: 0.6600\n",
            "Epoch 499/500\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1368 - binary_accuracy: 0.9856 - val_loss: 0.7009 - val_binary_accuracy: 0.7000\n",
            "Epoch 500/500\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1338 - binary_accuracy: 0.9904 - val_loss: 0.7244 - val_binary_accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fc321b33fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish() # Let wandb know you're finished!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgB8KIBZZY_f",
        "outputId": "aa731366-5819-4799-827b-085985a5c353"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best_epoch 212\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best_val_loss 0.52907\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy 0.99043\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 499\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss 0.13382\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy 0.7\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss 0.72438\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mdl_week06_run_01\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/cf7esqce\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 80 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230918_131140-cf7esqce/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh562csI3WFO"
      },
      "source": [
        "## 4.2 Sweeps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mo_cE96gG8Tq"
      },
      "source": [
        " # The sweep calls this function with each set of hyperparameters\n",
        "def train():\n",
        "    # Default values for hyper-parameters we're going to sweep over\n",
        "    defaults = dict(layer_1 = 8,\n",
        "                layer_2 = 8,\n",
        "                learn_rate = 0.001,\n",
        "                batch_size = 32,\n",
        "                epoch = 500)\n",
        "\n",
        "    # Initialize a new wandb run\n",
        "    wandb.init(project=\"dl_week06\", config= defaults)\n",
        "\n",
        "    # Config is a variable that holds and saves hyperparameters and inputs\n",
        "    config = wandb.config\n",
        "\n",
        "    # Instantiate a simple classification model\n",
        "    model = tf.keras.Sequential([\n",
        "                                 tf.keras.layers.Dense(config.layer_1, activation=tf.nn.relu, dtype='float64'),\n",
        "                                 tf.keras.layers.Dense(config.layer_2, activation=tf.nn.relu, dtype='float64'),\n",
        "                                 tf.keras.layers.Dense(1, activation=tf.nn.sigmoid, dtype='float64')\n",
        "                                 ])\n",
        "\n",
        "    # Instantiate a logistic loss function that expects integer targets.\n",
        "    loss = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "    # Instantiate an accuracy metric.\n",
        "    accuracy = tf.keras.metrics.BinaryAccuracy()\n",
        "\n",
        "    # Instantiate an optimizer.\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=config.learn_rate)\n",
        "\n",
        "    # configure the optimizer, loss, and metrics to monitor.\n",
        "    model.compile(optimizer=optimizer, loss=loss, metrics=[accuracy])\n",
        "\n",
        "    model.fit(train_x, train_y, batch_size=config.batch_size,\n",
        "              epochs=config.epoch,\n",
        "              validation_data=(test_x, test_y),\n",
        "              callbacks=[WandbCallback(),\n",
        "                          EarlyStopping(patience=100)]\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6whtzZ1eior"
      },
      "source": [
        "# See the source code in order to see other parameters\n",
        "# https://github.com/wandb/client/tree/master/wandb/sweeps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ibov1wrLgS9"
      },
      "source": [
        "# Configure the sweep  specify the parameters to search through, the search strategy, the optimization metric et all.\n",
        "sweep_config = {\n",
        "    'method': 'random', #grid, random\n",
        "    'metric': {\n",
        "      'name': 'binary_accuracy',\n",
        "      'goal': 'maximize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'layer_1': {\n",
        "            'max': 32,\n",
        "            'min': 8,\n",
        "            'distribution': 'int_uniform',\n",
        "        },\n",
        "        'layer_2': {\n",
        "            'max': 32,\n",
        "            'min': 8,\n",
        "            'distribution': 'int_uniform',\n",
        "        },\n",
        "        'learn_rate': {\n",
        "            'min': -4,\n",
        "            'max': -2,\n",
        "            'distribution': 'log_uniform',\n",
        "        },\n",
        "        'epoch': {\n",
        "            'values': [300,400,600]\n",
        "        },\n",
        "        'batch_size': {\n",
        "            'values': [32,64]\n",
        "        }\n",
        "    }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rCRIA2HMG1Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4615bb-252e-43e1-f78c-78f1c244a419"
      },
      "source": [
        "# Initialize a new sweep\n",
        "# Arguments:\n",
        "#      sweep_config: the sweep config dictionary defined above\n",
        "#      entity: Set the username for the sweep\n",
        "#      project: Set the project name for the sweep\n",
        "sweep_id = wandb.sweep(sweep_config, entity=\"terrematte\", project=\"dl_week06\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Malformed sweep config detected! This may cause your sweep to behave in unexpected ways.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m To avoid this, please fix the sweep config schema violations below:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m   Violation 1. learn_rate uses log_uniform, where min/max specify base-e exponents. Use log_uniform_values to specify limit values.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 5z67asm0\n",
            "Sweep URL: https://wandb.ai/terrematte/dl_week06/sweeps/5z67asm0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V0Cobv4MahM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7d61da4-8640-44c1-85fe-29e3c160d384"
      },
      "source": [
        "# Initialize a new sweep\n",
        "# Arguments:\n",
        "#      sweep_id: the sweep_id to run - this was returned above by wandb.sweep()\n",
        "#      function: function that defines your model architecture and trains it\n",
        "wandb.agent(sweep_id = sweep_id, function=train,count=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5viskuul with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 8\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 27\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearn_rate: 0.04798086029863364\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230918_131414-5viskuul\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mglorious-sweep-1\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/sweeps/5z67asm0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/5viskuul\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1/4 [======>.......................] - ETA: 2s - loss: 0.7375 - binary_accuracy: 0.3125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 2s 337ms/step - loss: 0.6872 - binary_accuracy: 0.5311 - val_loss: 1.3190 - val_binary_accuracy: 0.3400\n",
            "Epoch 2/400\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6677 - binary_accuracy: 0.6555 - val_loss: 1.4427 - val_binary_accuracy: 0.3400\n",
            "Epoch 3/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.7722 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 399ms/step - loss: 0.6974 - binary_accuracy: 0.6555 - val_loss: 0.6982 - val_binary_accuracy: 0.3400\n",
            "Epoch 4/400\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.6671 - binary_accuracy: 0.6555 - val_loss: 0.8948 - val_binary_accuracy: 0.3400\n",
            "Epoch 5/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6369 - binary_accuracy: 0.6555 - val_loss: 0.8366 - val_binary_accuracy: 0.3400\n",
            "Epoch 6/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6361 - binary_accuracy: 0.6555 - val_loss: 0.7148 - val_binary_accuracy: 0.3400\n",
            "Epoch 7/400\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.6281 - binary_accuracy: 0.6651 - val_loss: 1.1820 - val_binary_accuracy: 0.3400\n",
            "Epoch 8/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6524 - binary_accuracy: 0.6555 - val_loss: 0.7545 - val_binary_accuracy: 0.3400\n",
            "Epoch 9/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6286 - binary_accuracy: 0.6555 - val_loss: 0.7344 - val_binary_accuracy: 0.3400\n",
            "Epoch 10/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6443 - binary_accuracy: 0.6603 - val_loss: 0.7794 - val_binary_accuracy: 0.3400\n",
            "Epoch 11/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6571 - binary_accuracy: 0.6555 - val_loss: 0.7063 - val_binary_accuracy: 0.3400\n",
            "Epoch 12/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6182 - binary_accuracy: 0.6555 - val_loss: 0.7649 - val_binary_accuracy: 0.3400\n",
            "Epoch 13/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5935 - binary_accuracy: 0.6555 - val_loss: 0.8827 - val_binary_accuracy: 0.3400\n",
            "Epoch 14/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.5719 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 2s 568ms/step - loss: 0.5846 - binary_accuracy: 0.6555 - val_loss: 0.6886 - val_binary_accuracy: 0.4200\n",
            "Epoch 15/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6330 - binary_accuracy: 0.6364 - val_loss: 0.8801 - val_binary_accuracy: 0.3400\n",
            "Epoch 16/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6003 - binary_accuracy: 0.6555 - val_loss: 0.7144 - val_binary_accuracy: 0.3400\n",
            "Epoch 17/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6686 - binary_accuracy: 0.6603 - val_loss: 0.7211 - val_binary_accuracy: 0.3400\n",
            "Epoch 18/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6492 - binary_accuracy: 0.6603 - val_loss: 0.7096 - val_binary_accuracy: 0.3400\n",
            "Epoch 19/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5961 - binary_accuracy: 0.6603 - val_loss: 0.7162 - val_binary_accuracy: 0.3400\n",
            "Epoch 20/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5704 - binary_accuracy: 0.6555 - val_loss: 0.8487 - val_binary_accuracy: 0.3400\n",
            "Epoch 21/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6389 - binary_accuracy: 0.6842 - val_loss: 0.7228 - val_binary_accuracy: 0.3400\n",
            "Epoch 22/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6273 - binary_accuracy: 0.6555 - val_loss: 0.7743 - val_binary_accuracy: 0.3400\n",
            "Epoch 23/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5933 - binary_accuracy: 0.6555 - val_loss: 0.7469 - val_binary_accuracy: 0.3400\n",
            "Epoch 24/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5528 - binary_accuracy: 0.6555 - val_loss: 1.0724 - val_binary_accuracy: 0.3400\n",
            "Epoch 25/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6198 - binary_accuracy: 0.6555 - val_loss: 0.8424 - val_binary_accuracy: 0.3400\n",
            "Epoch 26/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5414 - binary_accuracy: 0.6555 - val_loss: 0.7208 - val_binary_accuracy: 0.3400\n",
            "Epoch 27/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6261 - binary_accuracy: 0.6603 - val_loss: 0.8566 - val_binary_accuracy: 0.3400\n",
            "Epoch 28/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5816 - binary_accuracy: 0.6603 - val_loss: 0.7048 - val_binary_accuracy: 0.3800\n",
            "Epoch 29/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6182 - binary_accuracy: 0.6699 - val_loss: 0.8157 - val_binary_accuracy: 0.3400\n",
            "Epoch 30/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5225 - binary_accuracy: 0.6746 - val_loss: 2.0971 - val_binary_accuracy: 0.3400\n",
            "Epoch 31/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.8242 - binary_accuracy: 0.6746 - val_loss: 0.7282 - val_binary_accuracy: 0.3400\n",
            "Epoch 32/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6549 - binary_accuracy: 0.6651 - val_loss: 0.7407 - val_binary_accuracy: 0.3400\n",
            "Epoch 33/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6468 - binary_accuracy: 0.6603 - val_loss: 0.7311 - val_binary_accuracy: 0.3400\n",
            "Epoch 34/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6264 - binary_accuracy: 0.6603 - val_loss: 0.7132 - val_binary_accuracy: 0.3400\n",
            "Epoch 35/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5782 - binary_accuracy: 0.6651 - val_loss: 0.7558 - val_binary_accuracy: 0.3400\n",
            "Epoch 36/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5572 - binary_accuracy: 0.6603 - val_loss: 0.8883 - val_binary_accuracy: 0.3400\n",
            "Epoch 37/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5822 - binary_accuracy: 0.6459 - val_loss: 0.8737 - val_binary_accuracy: 0.3800\n",
            "Epoch 38/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5275 - binary_accuracy: 0.6507 - val_loss: 1.7491 - val_binary_accuracy: 0.3400\n",
            "Epoch 39/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6502 - binary_accuracy: 0.6938 - val_loss: 0.8680 - val_binary_accuracy: 0.3400\n",
            "Epoch 40/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5239 - binary_accuracy: 0.6746 - val_loss: 1.2875 - val_binary_accuracy: 0.3400\n",
            "Epoch 41/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6723 - binary_accuracy: 0.6842 - val_loss: 0.7409 - val_binary_accuracy: 0.3400\n",
            "Epoch 42/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6058 - binary_accuracy: 0.6555 - val_loss: 0.7463 - val_binary_accuracy: 0.3400\n",
            "Epoch 43/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.5400 - binary_accuracy: 0.6406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 295ms/step - loss: 0.5272 - binary_accuracy: 0.6651 - val_loss: 0.6800 - val_binary_accuracy: 0.4800\n",
            "Epoch 44/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5592 - binary_accuracy: 0.6699 - val_loss: 0.7282 - val_binary_accuracy: 0.3400\n",
            "Epoch 45/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5329 - binary_accuracy: 0.6746 - val_loss: 0.7112 - val_binary_accuracy: 0.4000\n",
            "Epoch 46/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5113 - binary_accuracy: 0.6794 - val_loss: 0.6840 - val_binary_accuracy: 0.4200\n",
            "Epoch 47/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.4927 - binary_accuracy: 0.7081 - val_loss: 1.4379 - val_binary_accuracy: 0.3400\n",
            "Epoch 48/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.7142 - binary_accuracy: 0.6406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 285ms/step - loss: 0.6489 - binary_accuracy: 0.6890 - val_loss: 0.6632 - val_binary_accuracy: 0.5400\n",
            "Epoch 49/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6023 - binary_accuracy: 0.7031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 326ms/step - loss: 0.5642 - binary_accuracy: 0.6986 - val_loss: 0.6289 - val_binary_accuracy: 0.6200\n",
            "Epoch 50/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.5909 - binary_accuracy: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 285ms/step - loss: 0.5808 - binary_accuracy: 0.7129 - val_loss: 0.5344 - val_binary_accuracy: 0.7400\n",
            "Epoch 51/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.5323 - binary_accuracy: 0.6719"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 318ms/step - loss: 0.5097 - binary_accuracy: 0.6794 - val_loss: 0.5237 - val_binary_accuracy: 0.7400\n",
            "Epoch 52/400\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5872 - binary_accuracy: 0.6699 - val_loss: 0.7690 - val_binary_accuracy: 0.5000\n",
            "Epoch 53/400\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.5500 - binary_accuracy: 0.6938 - val_loss: 0.7475 - val_binary_accuracy: 0.3400\n",
            "Epoch 54/400\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.6139 - binary_accuracy: 0.6555 - val_loss: 0.7305 - val_binary_accuracy: 0.3400\n",
            "Epoch 55/400\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.5531 - binary_accuracy: 0.6555 - val_loss: 0.7991 - val_binary_accuracy: 0.3400\n",
            "Epoch 56/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5181 - binary_accuracy: 0.6603 - val_loss: 0.7240 - val_binary_accuracy: 0.3400\n",
            "Epoch 57/400\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.5198 - binary_accuracy: 0.6651 - val_loss: 1.3516 - val_binary_accuracy: 0.3400\n",
            "Epoch 58/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6498 - binary_accuracy: 0.6699 - val_loss: 0.7244 - val_binary_accuracy: 0.3600\n",
            "Epoch 59/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6031 - binary_accuracy: 0.6890 - val_loss: 0.6706 - val_binary_accuracy: 0.4600\n",
            "Epoch 60/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5421 - binary_accuracy: 0.7033 - val_loss: 1.3444 - val_binary_accuracy: 0.4200\n",
            "Epoch 61/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6716 - binary_accuracy: 0.6555 - val_loss: 0.6925 - val_binary_accuracy: 0.4600\n",
            "Epoch 62/400\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.5332 - binary_accuracy: 0.7033 - val_loss: 0.5760 - val_binary_accuracy: 0.7000\n",
            "Epoch 63/400\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.5013 - binary_accuracy: 0.7129 - val_loss: 1.3397 - val_binary_accuracy: 0.3400\n",
            "Epoch 64/400\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.5765 - binary_accuracy: 0.6890 - val_loss: 0.7452 - val_binary_accuracy: 0.4000\n",
            "Epoch 65/400\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.5069 - binary_accuracy: 0.6986 - val_loss: 0.5510 - val_binary_accuracy: 0.7400\n",
            "Epoch 66/400\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.4866 - binary_accuracy: 0.7273 - val_loss: 0.5602 - val_binary_accuracy: 0.6800\n",
            "Epoch 67/400\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.5094 - binary_accuracy: 0.6459 - val_loss: 0.6459 - val_binary_accuracy: 0.6000\n",
            "Epoch 68/400\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.5770 - binary_accuracy: 0.7321 - val_loss: 0.7079 - val_binary_accuracy: 0.4600\n",
            "Epoch 69/400\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.4537 - binary_accuracy: 0.7321 - val_loss: 0.6871 - val_binary_accuracy: 0.6800\n",
            "Epoch 70/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4300 - binary_accuracy: 0.7608 - val_loss: 1.9113 - val_binary_accuracy: 0.3400\n",
            "Epoch 71/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.8097 - binary_accuracy: 0.5981 - val_loss: 0.7426 - val_binary_accuracy: 0.3600\n",
            "Epoch 72/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.6273 - binary_accuracy: 0.6794 - val_loss: 0.7398 - val_binary_accuracy: 0.4000\n",
            "Epoch 73/400\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.6078 - binary_accuracy: 0.6842 - val_loss: 0.7119 - val_binary_accuracy: 0.4200\n",
            "Epoch 74/400\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.5751 - binary_accuracy: 0.6986 - val_loss: 0.7669 - val_binary_accuracy: 0.3400\n",
            "Epoch 75/400\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.5065 - binary_accuracy: 0.6699 - val_loss: 0.8279 - val_binary_accuracy: 0.3400\n",
            "Epoch 76/400\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.4833 - binary_accuracy: 0.6746 - val_loss: 0.7197 - val_binary_accuracy: 0.3800\n",
            "Epoch 77/400\n",
            "4/4 [==============================] - 0s 77ms/step - loss: 0.4924 - binary_accuracy: 0.6842 - val_loss: 0.7523 - val_binary_accuracy: 0.4000\n",
            "Epoch 78/400\n",
            "4/4 [==============================] - 0s 90ms/step - loss: 0.4720 - binary_accuracy: 0.6890 - val_loss: 0.9214 - val_binary_accuracy: 0.4600\n",
            "Epoch 79/400\n",
            "4/4 [==============================] - 0s 106ms/step - loss: 0.4890 - binary_accuracy: 0.7416 - val_loss: 0.7206 - val_binary_accuracy: 0.6000\n",
            "Epoch 80/400\n",
            "4/4 [==============================] - 0s 129ms/step - loss: 0.4147 - binary_accuracy: 0.7560 - val_loss: 0.7330 - val_binary_accuracy: 0.6200\n",
            "Epoch 81/400\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.4883 - binary_accuracy: 0.7081 - val_loss: 0.6672 - val_binary_accuracy: 0.5400\n",
            "Epoch 82/400\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.4283 - binary_accuracy: 0.7703 - val_loss: 0.9697 - val_binary_accuracy: 0.5000\n",
            "Epoch 83/400\n",
            "4/4 [==============================] - 0s 82ms/step - loss: 0.7175 - binary_accuracy: 0.5742 - val_loss: 0.6953 - val_binary_accuracy: 0.3400\n",
            "Epoch 84/400\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.5388 - binary_accuracy: 0.6794 - val_loss: 0.8010 - val_binary_accuracy: 0.3400\n",
            "Epoch 85/400\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.4589 - binary_accuracy: 0.6794 - val_loss: 0.9291 - val_binary_accuracy: 0.3600\n",
            "Epoch 86/400\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.4471 - binary_accuracy: 0.6794 - val_loss: 0.7308 - val_binary_accuracy: 0.4200\n",
            "Epoch 87/400\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.5720 - binary_accuracy: 0.6890 - val_loss: 0.6438 - val_binary_accuracy: 0.6000\n",
            "Epoch 88/400\n",
            "4/4 [==============================] - 0s 72ms/step - loss: 0.5932 - binary_accuracy: 0.7033 - val_loss: 0.5981 - val_binary_accuracy: 0.5800\n",
            "Epoch 89/400\n",
            "4/4 [==============================] - 0s 94ms/step - loss: 0.4560 - binary_accuracy: 0.7703 - val_loss: 0.9918 - val_binary_accuracy: 0.5800\n",
            "Epoch 90/400\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.7648 - binary_accuracy: 0.6459 - val_loss: 0.7636 - val_binary_accuracy: 0.3400\n",
            "Epoch 91/400\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.4641 - binary_accuracy: 0.6794 - val_loss: 0.8961 - val_binary_accuracy: 0.3600\n",
            "Epoch 92/400\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.4491 - binary_accuracy: 0.6794 - val_loss: 1.0812 - val_binary_accuracy: 0.3600\n",
            "Epoch 93/400\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.5473 - binary_accuracy: 0.6890 - val_loss: 0.9136 - val_binary_accuracy: 0.3400\n",
            "Epoch 94/400\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.4617 - binary_accuracy: 0.6794 - val_loss: 0.7948 - val_binary_accuracy: 0.4800\n",
            "Epoch 95/400\n",
            "4/4 [==============================] - 0s 35ms/step - loss: 0.4172 - binary_accuracy: 0.7368 - val_loss: 1.0035 - val_binary_accuracy: 0.4600\n",
            "Epoch 96/400\n",
            "4/4 [==============================] - 0s 34ms/step - loss: 0.4472 - binary_accuracy: 0.7129 - val_loss: 0.6075 - val_binary_accuracy: 0.6600\n",
            "Epoch 97/400\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.4477 - binary_accuracy: 0.7321 - val_loss: 0.6387 - val_binary_accuracy: 0.5600\n",
            "Epoch 98/400\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.5607 - binary_accuracy: 0.7512 - val_loss: 0.5596 - val_binary_accuracy: 0.6400\n",
            "Epoch 99/400\n",
            "4/4 [==============================] - 0s 32ms/step - loss: 0.4180 - binary_accuracy: 0.7656 - val_loss: 0.8674 - val_binary_accuracy: 0.4800\n",
            "Epoch 100/400\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.4285 - binary_accuracy: 0.7273 - val_loss: 0.6675 - val_binary_accuracy: 0.5800\n",
            "Epoch 101/400\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.4574 - binary_accuracy: 0.7081 - val_loss: 0.6592 - val_binary_accuracy: 0.5200\n",
            "Epoch 102/400\n",
            "4/4 [==============================] - 0s 71ms/step - loss: 0.5770 - binary_accuracy: 0.7129 - val_loss: 0.8093 - val_binary_accuracy: 0.4200\n",
            "Epoch 103/400\n",
            "4/4 [==============================] - 0s 36ms/step - loss: 0.4653 - binary_accuracy: 0.7177 - val_loss: 2.1488 - val_binary_accuracy: 0.4000\n",
            "Epoch 104/400\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.7861 - binary_accuracy: 0.6029 - val_loss: 0.9656 - val_binary_accuracy: 0.3600\n",
            "Epoch 105/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.6128 - binary_accuracy: 0.6890 - val_loss: 0.7118 - val_binary_accuracy: 0.4000\n",
            "Epoch 106/400\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.5864 - binary_accuracy: 0.6938 - val_loss: 0.8749 - val_binary_accuracy: 0.3800\n",
            "Epoch 107/400\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.5370 - binary_accuracy: 0.7081 - val_loss: 0.8437 - val_binary_accuracy: 0.4600\n",
            "Epoch 108/400\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.4625 - binary_accuracy: 0.7177 - val_loss: 0.7703 - val_binary_accuracy: 0.5600\n",
            "Epoch 109/400\n",
            "4/4 [==============================] - 0s 54ms/step - loss: 0.4834 - binary_accuracy: 0.7368 - val_loss: 0.6782 - val_binary_accuracy: 0.4800\n",
            "Epoch 110/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.4944 - binary_accuracy: 0.7188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131414-5viskuul/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 2s 584ms/step - loss: 0.4683 - binary_accuracy: 0.7416 - val_loss: 0.4886 - val_binary_accuracy: 0.7200\n",
            "Epoch 111/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3854 - binary_accuracy: 0.7560 - val_loss: 1.4600 - val_binary_accuracy: 0.4200\n",
            "Epoch 112/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6178 - binary_accuracy: 0.7129 - val_loss: 0.6459 - val_binary_accuracy: 0.5600\n",
            "Epoch 113/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5565 - binary_accuracy: 0.7368 - val_loss: 0.6311 - val_binary_accuracy: 0.5600\n",
            "Epoch 114/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5082 - binary_accuracy: 0.7703 - val_loss: 0.5166 - val_binary_accuracy: 0.7400\n",
            "Epoch 115/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5620 - binary_accuracy: 0.6172 - val_loss: 0.8324 - val_binary_accuracy: 0.3600\n",
            "Epoch 116/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4283 - binary_accuracy: 0.6890 - val_loss: 0.6915 - val_binary_accuracy: 0.4200\n",
            "Epoch 117/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4641 - binary_accuracy: 0.6986 - val_loss: 0.9218 - val_binary_accuracy: 0.4800\n",
            "Epoch 118/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3943 - binary_accuracy: 0.7703 - val_loss: 1.5105 - val_binary_accuracy: 0.3800\n",
            "Epoch 119/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4166 - binary_accuracy: 0.7703 - val_loss: 0.5294 - val_binary_accuracy: 0.6600\n",
            "Epoch 120/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4163 - binary_accuracy: 0.6890 - val_loss: 0.8246 - val_binary_accuracy: 0.5400\n",
            "Epoch 121/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3439 - binary_accuracy: 0.8038 - val_loss: 0.7674 - val_binary_accuracy: 0.6400\n",
            "Epoch 122/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5165 - binary_accuracy: 0.7560 - val_loss: 0.5868 - val_binary_accuracy: 0.6600\n",
            "Epoch 123/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6367 - binary_accuracy: 0.6220 - val_loss: 0.6669 - val_binary_accuracy: 0.4200\n",
            "Epoch 124/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5379 - binary_accuracy: 0.7081 - val_loss: 0.8051 - val_binary_accuracy: 0.4400\n",
            "Epoch 125/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4477 - binary_accuracy: 0.7321 - val_loss: 0.6700 - val_binary_accuracy: 0.5600\n",
            "Epoch 126/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4784 - binary_accuracy: 0.7129 - val_loss: 1.6620 - val_binary_accuracy: 0.4000\n",
            "Epoch 127/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5374 - binary_accuracy: 0.7464 - val_loss: 0.5469 - val_binary_accuracy: 0.7400\n",
            "Epoch 128/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5370 - binary_accuracy: 0.6459 - val_loss: 0.7240 - val_binary_accuracy: 0.4200\n",
            "Epoch 129/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4030 - binary_accuracy: 0.7033 - val_loss: 0.7311 - val_binary_accuracy: 0.4600\n",
            "Epoch 130/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4051 - binary_accuracy: 0.7177 - val_loss: 0.9535 - val_binary_accuracy: 0.4800\n",
            "Epoch 131/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3634 - binary_accuracy: 0.7560 - val_loss: 0.5607 - val_binary_accuracy: 0.6800\n",
            "Epoch 132/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5311 - binary_accuracy: 0.6555 - val_loss: 0.8067 - val_binary_accuracy: 0.4000\n",
            "Epoch 133/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4021 - binary_accuracy: 0.7129 - val_loss: 1.4002 - val_binary_accuracy: 0.4200\n",
            "Epoch 134/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5795 - binary_accuracy: 0.7321 - val_loss: 0.6108 - val_binary_accuracy: 0.5600\n",
            "Epoch 135/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4609 - binary_accuracy: 0.7656 - val_loss: 1.5024 - val_binary_accuracy: 0.5200\n",
            "Epoch 136/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5036 - binary_accuracy: 0.6890 - val_loss: 0.6289 - val_binary_accuracy: 0.6000\n",
            "Epoch 137/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5609 - binary_accuracy: 0.7416 - val_loss: 0.6507 - val_binary_accuracy: 0.4600\n",
            "Epoch 138/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4661 - binary_accuracy: 0.7464 - val_loss: 0.6423 - val_binary_accuracy: 0.6000\n",
            "Epoch 139/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3068 - binary_accuracy: 0.7990 - val_loss: 1.4582 - val_binary_accuracy: 0.4800\n",
            "Epoch 140/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5944 - binary_accuracy: 0.6746 - val_loss: 0.9331 - val_binary_accuracy: 0.4600\n",
            "Epoch 141/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3758 - binary_accuracy: 0.7273 - val_loss: 0.6182 - val_binary_accuracy: 0.6000\n",
            "Epoch 142/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3413 - binary_accuracy: 0.8038 - val_loss: 1.3658 - val_binary_accuracy: 0.4200\n",
            "Epoch 143/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4154 - binary_accuracy: 0.7608 - val_loss: 0.9374 - val_binary_accuracy: 0.5600\n",
            "Epoch 144/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3177 - binary_accuracy: 0.8134 - val_loss: 0.5353 - val_binary_accuracy: 0.6800\n",
            "Epoch 145/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5010 - binary_accuracy: 0.7129 - val_loss: 0.6762 - val_binary_accuracy: 0.4400\n",
            "Epoch 146/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4098 - binary_accuracy: 0.7368 - val_loss: 1.2003 - val_binary_accuracy: 0.4600\n",
            "Epoch 147/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4151 - binary_accuracy: 0.7656 - val_loss: 1.1249 - val_binary_accuracy: 0.4400\n",
            "Epoch 148/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4050 - binary_accuracy: 0.7512 - val_loss: 0.5841 - val_binary_accuracy: 0.6800\n",
            "Epoch 149/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5736 - binary_accuracy: 0.6411 - val_loss: 0.7634 - val_binary_accuracy: 0.4400\n",
            "Epoch 150/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4267 - binary_accuracy: 0.7368 - val_loss: 0.7579 - val_binary_accuracy: 0.5800\n",
            "Epoch 151/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2878 - binary_accuracy: 0.8134 - val_loss: 1.0063 - val_binary_accuracy: 0.5400\n",
            "Epoch 152/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4239 - binary_accuracy: 0.7416 - val_loss: 0.6951 - val_binary_accuracy: 0.4200\n",
            "Epoch 153/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3745 - binary_accuracy: 0.7081 - val_loss: 1.0171 - val_binary_accuracy: 0.4200\n",
            "Epoch 154/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3486 - binary_accuracy: 0.7512 - val_loss: 1.0754 - val_binary_accuracy: 0.6600\n",
            "Epoch 155/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4091 - binary_accuracy: 0.7656 - val_loss: 0.7203 - val_binary_accuracy: 0.6800\n",
            "Epoch 156/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2842 - binary_accuracy: 0.8708 - val_loss: 1.1666 - val_binary_accuracy: 0.5800\n",
            "Epoch 157/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2576 - binary_accuracy: 0.8756 - val_loss: 0.9895 - val_binary_accuracy: 0.6200\n",
            "Epoch 158/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2618 - binary_accuracy: 0.8660 - val_loss: 0.6315 - val_binary_accuracy: 0.7600\n",
            "Epoch 159/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2759 - binary_accuracy: 0.8565 - val_loss: 0.5887 - val_binary_accuracy: 0.7600\n",
            "Epoch 160/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2553 - binary_accuracy: 0.8660 - val_loss: 0.6040 - val_binary_accuracy: 0.7800\n",
            "Epoch 161/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2490 - binary_accuracy: 0.8995 - val_loss: 1.7464 - val_binary_accuracy: 0.4200\n",
            "Epoch 162/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6179 - binary_accuracy: 0.6842 - val_loss: 0.9609 - val_binary_accuracy: 0.6600\n",
            "Epoch 163/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3837 - binary_accuracy: 0.7799 - val_loss: 0.6417 - val_binary_accuracy: 0.8000\n",
            "Epoch 164/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4100 - binary_accuracy: 0.7512 - val_loss: 0.7069 - val_binary_accuracy: 0.8000\n",
            "Epoch 165/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3694 - binary_accuracy: 0.8134 - val_loss: 1.3752 - val_binary_accuracy: 0.6000\n",
            "Epoch 166/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5220 - binary_accuracy: 0.6077 - val_loss: 0.6246 - val_binary_accuracy: 0.7800\n",
            "Epoch 167/400\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4503 - binary_accuracy: 0.6842 - val_loss: 0.5586 - val_binary_accuracy: 0.8000\n",
            "Epoch 168/400\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3666 - binary_accuracy: 0.7560 - val_loss: 0.6978 - val_binary_accuracy: 0.7800\n",
            "Epoch 169/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3078 - binary_accuracy: 0.8182 - val_loss: 0.6913 - val_binary_accuracy: 0.7600\n",
            "Epoch 170/400\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.5317 - binary_accuracy: 0.6077 - val_loss: 0.6229 - val_binary_accuracy: 0.7400\n",
            "Epoch 171/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5428 - binary_accuracy: 0.5502 - val_loss: 0.6562 - val_binary_accuracy: 0.5200\n",
            "Epoch 172/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3294 - binary_accuracy: 0.8134 - val_loss: 0.6511 - val_binary_accuracy: 0.6600\n",
            "Epoch 173/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2846 - binary_accuracy: 0.8134 - val_loss: 0.5578 - val_binary_accuracy: 0.6400\n",
            "Epoch 174/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3874 - binary_accuracy: 0.8086 - val_loss: 1.1570 - val_binary_accuracy: 0.6200\n",
            "Epoch 175/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5255 - binary_accuracy: 0.6507 - val_loss: 1.6768 - val_binary_accuracy: 0.3400\n",
            "Epoch 176/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5792 - binary_accuracy: 0.6890 - val_loss: 0.6444 - val_binary_accuracy: 0.3800\n",
            "Epoch 177/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4620 - binary_accuracy: 0.6938 - val_loss: 0.9546 - val_binary_accuracy: 0.3800\n",
            "Epoch 178/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3304 - binary_accuracy: 0.6986 - val_loss: 1.0813 - val_binary_accuracy: 0.6000\n",
            "Epoch 179/400\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.3199 - binary_accuracy: 0.8469 - val_loss: 0.8790 - val_binary_accuracy: 0.6800\n",
            "Epoch 180/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2716 - binary_accuracy: 0.8900 - val_loss: 0.9286 - val_binary_accuracy: 0.6400\n",
            "Epoch 181/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2755 - binary_accuracy: 0.8565 - val_loss: 1.3243 - val_binary_accuracy: 0.5000\n",
            "Epoch 182/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3555 - binary_accuracy: 0.7847 - val_loss: 0.6289 - val_binary_accuracy: 0.8000\n",
            "Epoch 183/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2272 - binary_accuracy: 0.8947 - val_loss: 0.9750 - val_binary_accuracy: 0.6200\n",
            "Epoch 184/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2356 - binary_accuracy: 0.8804 - val_loss: 0.8621 - val_binary_accuracy: 0.7400\n",
            "Epoch 185/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4538 - binary_accuracy: 0.7656 - val_loss: 0.7017 - val_binary_accuracy: 0.7800\n",
            "Epoch 186/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.3260 - binary_accuracy: 0.8469 - val_loss: 0.6985 - val_binary_accuracy: 0.7400\n",
            "Epoch 187/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2861 - binary_accuracy: 0.8421 - val_loss: 1.9715 - val_binary_accuracy: 0.5200\n",
            "Epoch 188/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6234 - binary_accuracy: 0.5359 - val_loss: 0.8788 - val_binary_accuracy: 0.5600\n",
            "Epoch 189/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5126 - binary_accuracy: 0.6077 - val_loss: 1.4593 - val_binary_accuracy: 0.4000\n",
            "Epoch 190/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6125 - binary_accuracy: 0.5981 - val_loss: 0.6449 - val_binary_accuracy: 0.7600\n",
            "Epoch 191/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4704 - binary_accuracy: 0.7081 - val_loss: 1.0065 - val_binary_accuracy: 0.6600\n",
            "Epoch 192/400\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.3341 - binary_accuracy: 0.8660 - val_loss: 1.1644 - val_binary_accuracy: 0.6000\n",
            "Epoch 193/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3475 - binary_accuracy: 0.8421 - val_loss: 0.7798 - val_binary_accuracy: 0.6000\n",
            "Epoch 194/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3699 - binary_accuracy: 0.8038 - val_loss: 1.9379 - val_binary_accuracy: 0.5200\n",
            "Epoch 195/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.6545 - binary_accuracy: 0.6077 - val_loss: 0.9130 - val_binary_accuracy: 0.5200\n",
            "Epoch 196/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4739 - binary_accuracy: 0.7273 - val_loss: 0.9624 - val_binary_accuracy: 0.5600\n",
            "Epoch 197/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3658 - binary_accuracy: 0.8230 - val_loss: 1.0618 - val_binary_accuracy: 0.6800\n",
            "Epoch 198/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2993 - binary_accuracy: 0.8852 - val_loss: 0.7996 - val_binary_accuracy: 0.6800\n",
            "Epoch 199/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2932 - binary_accuracy: 0.8804 - val_loss: 1.2355 - val_binary_accuracy: 0.6200\n",
            "Epoch 200/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2540 - binary_accuracy: 0.8995 - val_loss: 1.0884 - val_binary_accuracy: 0.6600\n",
            "Epoch 201/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2059 - binary_accuracy: 0.8852 - val_loss: 0.9615 - val_binary_accuracy: 0.7000\n",
            "Epoch 202/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.2038 - binary_accuracy: 0.9187 - val_loss: 0.6774 - val_binary_accuracy: 0.7200\n",
            "Epoch 203/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3197 - binary_accuracy: 0.8325 - val_loss: 1.5114 - val_binary_accuracy: 0.4600\n",
            "Epoch 204/400\n",
            "4/4 [==============================] - 0s 31ms/step - loss: 0.2591 - binary_accuracy: 0.8612 - val_loss: 0.6237 - val_binary_accuracy: 0.7800\n",
            "Epoch 205/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3048 - binary_accuracy: 0.8325 - val_loss: 0.9190 - val_binary_accuracy: 0.7600\n",
            "Epoch 206/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.2224 - binary_accuracy: 0.8900 - val_loss: 1.1857 - val_binary_accuracy: 0.7400\n",
            "Epoch 207/400\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.2080 - binary_accuracy: 0.8947 - val_loss: 1.3203 - val_binary_accuracy: 0.5600\n",
            "Epoch 208/400\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1910 - binary_accuracy: 0.9330 - val_loss: 1.2504 - val_binary_accuracy: 0.6800\n",
            "Epoch 209/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1955 - binary_accuracy: 0.9234 - val_loss: 0.7319 - val_binary_accuracy: 0.7400\n",
            "Epoch 210/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1992 - binary_accuracy: 0.9139 - val_loss: 1.3297 - val_binary_accuracy: 0.6600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best_epoch 109\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best_val_loss 0.4886\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy 0.91388\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 209\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss 0.19923\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy 0.66\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss 1.32968\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mglorious-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/5viskuul\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 45 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230918_131414-5viskuul/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qrwyz9in with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 22\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 29\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearn_rate: 0.05528669539355413\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230918_131545-qrwyz9in\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdenim-sweep-2\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/sweeps/5z67asm0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/qrwyz9in\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1/7 [===>..........................] - ETA: 4s - loss: 0.7278 - binary_accuracy: 0.4688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 173ms/step - loss: 0.7281 - binary_accuracy: 0.6220 - val_loss: 0.7199 - val_binary_accuracy: 0.3400\n",
            "Epoch 2/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6644 - binary_accuracy: 0.6507 - val_loss: 0.7363 - val_binary_accuracy: 0.3400\n",
            "Epoch 3/400\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.6531 - binary_accuracy: 0.6555 - val_loss: 0.8900 - val_binary_accuracy: 0.3400\n",
            "Epoch 4/400\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6517 - binary_accuracy: 0.6555 - val_loss: 0.8327 - val_binary_accuracy: 0.3400\n",
            "Epoch 5/400\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.6285 - binary_accuracy: 0.6555 - val_loss: 0.9087 - val_binary_accuracy: 0.3400\n",
            "Epoch 6/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6318 - binary_accuracy: 0.6555 - val_loss: 0.7578 - val_binary_accuracy: 0.3400\n",
            "Epoch 7/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6295 - binary_accuracy: 0.6555 - val_loss: 0.8702 - val_binary_accuracy: 0.3400\n",
            "Epoch 8/400\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.5982 - binary_accuracy: 0.6555 - val_loss: 0.7483 - val_binary_accuracy: 0.3400\n",
            "Epoch 9/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6090 - binary_accuracy: 0.6555 - val_loss: 0.7400 - val_binary_accuracy: 0.3400\n",
            "Epoch 10/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6390 - binary_accuracy: 0.6555 - val_loss: 0.7871 - val_binary_accuracy: 0.3400\n",
            "Epoch 11/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6327 - binary_accuracy: 0.6555 - val_loss: 0.7212 - val_binary_accuracy: 0.3400\n",
            "Epoch 12/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6173 - binary_accuracy: 0.6875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 201ms/step - loss: 0.6041 - binary_accuracy: 0.6555 - val_loss: 0.7190 - val_binary_accuracy: 0.3600\n",
            "Epoch 13/400\n",
            "7/7 [==============================] - 0s 45ms/step - loss: 0.6083 - binary_accuracy: 0.6555 - val_loss: 0.9362 - val_binary_accuracy: 0.3400\n",
            "Epoch 14/400\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.6139 - binary_accuracy: 0.6746 - val_loss: 0.7792 - val_binary_accuracy: 0.3400\n",
            "Epoch 15/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.5963 - binary_accuracy: 0.6459 - val_loss: 0.9172 - val_binary_accuracy: 0.3400\n",
            "Epoch 16/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5844 - binary_accuracy: 0.6555 - val_loss: 1.4478 - val_binary_accuracy: 0.3400\n",
            "Epoch 17/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6167 - binary_accuracy: 0.6603 - val_loss: 0.7614 - val_binary_accuracy: 0.3400\n",
            "Epoch 18/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5500 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 160ms/step - loss: 0.5717 - binary_accuracy: 0.6603 - val_loss: 0.6867 - val_binary_accuracy: 0.3400\n",
            "Epoch 19/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5449 - binary_accuracy: 0.6603 - val_loss: 1.4991 - val_binary_accuracy: 0.3400\n",
            "Epoch 20/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4350 - binary_accuracy: 0.7812"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 188ms/step - loss: 0.5318 - binary_accuracy: 0.6411 - val_loss: 0.6801 - val_binary_accuracy: 0.3400\n",
            "Epoch 21/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5842 - binary_accuracy: 0.6603 - val_loss: 0.6951 - val_binary_accuracy: 0.3600\n",
            "Epoch 22/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5593 - binary_accuracy: 0.6411 - val_loss: 0.7233 - val_binary_accuracy: 0.3400\n",
            "Epoch 23/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5451 - binary_accuracy: 0.6555 - val_loss: 0.7474 - val_binary_accuracy: 0.3400\n",
            "Epoch 24/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5145 - binary_accuracy: 0.6746 - val_loss: 0.8818 - val_binary_accuracy: 0.3600\n",
            "Epoch 25/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5142 - binary_accuracy: 0.6555 - val_loss: 1.1885 - val_binary_accuracy: 0.3600\n",
            "Epoch 26/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5118 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 151ms/step - loss: 0.5647 - binary_accuracy: 0.6746 - val_loss: 0.6764 - val_binary_accuracy: 0.3400\n",
            "Epoch 27/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5918 - binary_accuracy: 0.7188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 156ms/step - loss: 0.6082 - binary_accuracy: 0.6172 - val_loss: 0.6722 - val_binary_accuracy: 0.3400\n",
            "Epoch 28/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5536 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 168ms/step - loss: 0.5308 - binary_accuracy: 0.6794 - val_loss: 0.6720 - val_binary_accuracy: 0.5400\n",
            "Epoch 29/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4888 - binary_accuracy: 0.7033 - val_loss: 0.8943 - val_binary_accuracy: 0.5400\n",
            "Epoch 30/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6009 - binary_accuracy: 0.6220 - val_loss: 0.6761 - val_binary_accuracy: 0.3800\n",
            "Epoch 31/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5674 - binary_accuracy: 0.6890 - val_loss: 0.7891 - val_binary_accuracy: 0.5200\n",
            "Epoch 32/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6448 - binary_accuracy: 0.4688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 153ms/step - loss: 0.5312 - binary_accuracy: 0.6507 - val_loss: 0.6682 - val_binary_accuracy: 0.6800\n",
            "Epoch 33/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5570 - binary_accuracy: 0.6651 - val_loss: 0.7096 - val_binary_accuracy: 0.5400\n",
            "Epoch 34/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4806 - binary_accuracy: 0.7273 - val_loss: 1.4974 - val_binary_accuracy: 0.3400\n",
            "Epoch 35/400\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.5695 - binary_accuracy: 0.6603 - val_loss: 1.7036 - val_binary_accuracy: 0.3400\n",
            "Epoch 36/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.7069 - binary_accuracy: 0.6875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 157ms/step - loss: 0.5950 - binary_accuracy: 0.6555 - val_loss: 0.6541 - val_binary_accuracy: 0.7000\n",
            "Epoch 37/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5628 - binary_accuracy: 0.6794 - val_loss: 0.7257 - val_binary_accuracy: 0.5400\n",
            "Epoch 38/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5410 - binary_accuracy: 0.6842 - val_loss: 0.9313 - val_binary_accuracy: 0.3800\n",
            "Epoch 39/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5146 - binary_accuracy: 0.7033 - val_loss: 1.1579 - val_binary_accuracy: 0.3400\n",
            "Epoch 40/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5646 - binary_accuracy: 0.6250"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 153ms/step - loss: 0.5163 - binary_accuracy: 0.6938 - val_loss: 0.6227 - val_binary_accuracy: 0.7200\n",
            "Epoch 41/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5861 - binary_accuracy: 0.6459 - val_loss: 0.7009 - val_binary_accuracy: 0.4000\n",
            "Epoch 42/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4879 - binary_accuracy: 0.7273 - val_loss: 0.6402 - val_binary_accuracy: 0.6600\n",
            "Epoch 43/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.4124 - binary_accuracy: 0.8438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 161ms/step - loss: 0.4843 - binary_accuracy: 0.7368 - val_loss: 0.6087 - val_binary_accuracy: 0.7800\n",
            "Epoch 44/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5295 - binary_accuracy: 0.7812"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 308ms/step - loss: 0.5108 - binary_accuracy: 0.7464 - val_loss: 0.5834 - val_binary_accuracy: 0.6800\n",
            "Epoch 45/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5841 - binary_accuracy: 0.6459 - val_loss: 0.7035 - val_binary_accuracy: 0.4200\n",
            "Epoch 46/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4747 - binary_accuracy: 0.7368 - val_loss: 0.8140 - val_binary_accuracy: 0.6200\n",
            "Epoch 47/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5160 - binary_accuracy: 0.6842 - val_loss: 0.6261 - val_binary_accuracy: 0.6800\n",
            "Epoch 48/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4476 - binary_accuracy: 0.7464 - val_loss: 0.5999 - val_binary_accuracy: 0.8200\n",
            "Epoch 49/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4147 - binary_accuracy: 0.8182 - val_loss: 1.7219 - val_binary_accuracy: 0.3400\n",
            "Epoch 50/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5567 - binary_accuracy: 0.6794 - val_loss: 1.1361 - val_binary_accuracy: 0.3600\n",
            "Epoch 51/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4840 - binary_accuracy: 0.7033 - val_loss: 0.6660 - val_binary_accuracy: 0.6600\n",
            "Epoch 52/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4934 - binary_accuracy: 0.7225 - val_loss: 0.7701 - val_binary_accuracy: 0.6400\n",
            "Epoch 53/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4354 - binary_accuracy: 0.7703 - val_loss: 1.3435 - val_binary_accuracy: 0.3200\n",
            "Epoch 54/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5045 - binary_accuracy: 0.6986 - val_loss: 0.7125 - val_binary_accuracy: 0.6600\n",
            "Epoch 55/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.5005 - binary_accuracy: 0.7033 - val_loss: 0.7079 - val_binary_accuracy: 0.5800\n",
            "Epoch 56/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4551 - binary_accuracy: 0.7177 - val_loss: 0.7579 - val_binary_accuracy: 0.7000\n",
            "Epoch 57/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.3364 - binary_accuracy: 0.8438"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 176ms/step - loss: 0.3908 - binary_accuracy: 0.8278 - val_loss: 0.5760 - val_binary_accuracy: 0.7800\n",
            "Epoch 58/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5547 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 167ms/step - loss: 0.3893 - binary_accuracy: 0.8134 - val_loss: 0.5164 - val_binary_accuracy: 0.7800\n",
            "Epoch 59/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3635 - binary_accuracy: 0.8086 - val_loss: 3.1708 - val_binary_accuracy: 0.3400\n",
            "Epoch 60/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6070 - binary_accuracy: 0.7273 - val_loss: 0.5617 - val_binary_accuracy: 0.7800\n",
            "Epoch 61/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4992 - binary_accuracy: 0.7560 - val_loss: 0.8018 - val_binary_accuracy: 0.3800\n",
            "Epoch 62/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3909 - binary_accuracy: 0.8038 - val_loss: 2.2950 - val_binary_accuracy: 0.3400\n",
            "Epoch 63/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6516 - binary_accuracy: 0.7273 - val_loss: 0.8350 - val_binary_accuracy: 0.4200\n",
            "Epoch 64/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3845 - binary_accuracy: 0.8230 - val_loss: 0.8342 - val_binary_accuracy: 0.6800\n",
            "Epoch 65/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5207 - binary_accuracy: 0.7656 - val_loss: 0.8082 - val_binary_accuracy: 0.4200\n",
            "Epoch 66/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4414 - binary_accuracy: 0.7943 - val_loss: 0.6873 - val_binary_accuracy: 0.5800\n",
            "Epoch 67/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4081 - binary_accuracy: 0.7943 - val_loss: 1.5874 - val_binary_accuracy: 0.3400\n",
            "Epoch 68/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4593 - binary_accuracy: 0.7273 - val_loss: 0.6606 - val_binary_accuracy: 0.5000\n",
            "Epoch 69/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4338 - binary_accuracy: 0.7225 - val_loss: 0.6295 - val_binary_accuracy: 0.4800\n",
            "Epoch 70/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3778 - binary_accuracy: 0.7703 - val_loss: 0.6774 - val_binary_accuracy: 0.7200\n",
            "Epoch 71/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5309 - binary_accuracy: 0.6986 - val_loss: 1.0118 - val_binary_accuracy: 0.3600\n",
            "Epoch 72/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4256 - binary_accuracy: 0.7321 - val_loss: 0.9698 - val_binary_accuracy: 0.4200\n",
            "Epoch 73/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4446 - binary_accuracy: 0.7608 - val_loss: 0.6597 - val_binary_accuracy: 0.8000\n",
            "Epoch 74/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3028 - binary_accuracy: 0.8900 - val_loss: 1.2241 - val_binary_accuracy: 0.5000\n",
            "Epoch 75/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3298 - binary_accuracy: 0.8278 - val_loss: 0.7268 - val_binary_accuracy: 0.7200\n",
            "Epoch 76/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4945 - binary_accuracy: 0.7703 - val_loss: 0.6456 - val_binary_accuracy: 0.7800\n",
            "Epoch 77/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4388 - binary_accuracy: 0.7608 - val_loss: 0.7753 - val_binary_accuracy: 0.6800\n",
            "Epoch 78/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4149 - binary_accuracy: 0.7608 - val_loss: 1.3727 - val_binary_accuracy: 0.4200\n",
            "Epoch 79/400\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.4326 - binary_accuracy: 0.8038 - val_loss: 1.3100 - val_binary_accuracy: 0.4200\n",
            "Epoch 80/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3348 - binary_accuracy: 0.8469 - val_loss: 0.6972 - val_binary_accuracy: 0.7400\n",
            "Epoch 81/400\n",
            "7/7 [==============================] - 0s 41ms/step - loss: 0.4258 - binary_accuracy: 0.8182 - val_loss: 1.5469 - val_binary_accuracy: 0.3200\n",
            "Epoch 82/400\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.3962 - binary_accuracy: 0.8612 - val_loss: 0.8414 - val_binary_accuracy: 0.5800\n",
            "Epoch 83/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2548 - binary_accuracy: 0.8947 - val_loss: 0.9299 - val_binary_accuracy: 0.6800\n",
            "Epoch 84/400\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.2314 - binary_accuracy: 0.8852 - val_loss: 1.5067 - val_binary_accuracy: 0.5200\n",
            "Epoch 85/400\n",
            "7/7 [==============================] - 0s 24ms/step - loss: 0.3740 - binary_accuracy: 0.7990 - val_loss: 0.8297 - val_binary_accuracy: 0.7000\n",
            "Epoch 86/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4886 - binary_accuracy: 0.7033 - val_loss: 0.6728 - val_binary_accuracy: 0.7200\n",
            "Epoch 87/400\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.3786 - binary_accuracy: 0.7703 - val_loss: 1.6714 - val_binary_accuracy: 0.4600\n",
            "Epoch 88/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5085 - binary_accuracy: 0.7273 - val_loss: 0.6611 - val_binary_accuracy: 0.7400\n",
            "Epoch 89/400\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.4425 - binary_accuracy: 0.7751 - val_loss: 0.5848 - val_binary_accuracy: 0.7400\n",
            "Epoch 90/400\n",
            "7/7 [==============================] - 0s 35ms/step - loss: 0.2729 - binary_accuracy: 0.8852 - val_loss: 0.9915 - val_binary_accuracy: 0.5200\n",
            "Epoch 91/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2596 - binary_accuracy: 0.8900 - val_loss: 0.5892 - val_binary_accuracy: 0.7600\n",
            "Epoch 92/400\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.3828 - binary_accuracy: 0.7847 - val_loss: 0.7180 - val_binary_accuracy: 0.5600\n",
            "Epoch 93/400\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.4606 - binary_accuracy: 0.7608 - val_loss: 0.5996 - val_binary_accuracy: 0.7600\n",
            "Epoch 94/400\n",
            "7/7 [==============================] - 0s 36ms/step - loss: 0.3465 - binary_accuracy: 0.8373 - val_loss: 0.6298 - val_binary_accuracy: 0.7600\n",
            "Epoch 95/400\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.3052 - binary_accuracy: 0.8612 - val_loss: 0.8592 - val_binary_accuracy: 0.6000\n",
            "Epoch 96/400\n",
            "7/7 [==============================] - 0s 47ms/step - loss: 0.3286 - binary_accuracy: 0.8373 - val_loss: 2.7701 - val_binary_accuracy: 0.3200\n",
            "Epoch 97/400\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.4263 - binary_accuracy: 0.8182 - val_loss: 1.0961 - val_binary_accuracy: 0.4200\n",
            "Epoch 98/400\n",
            "5/7 [====================>.........] - ETA: 0s - loss: 0.3976 - binary_accuracy: 0.8000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 263ms/step - loss: 0.3604 - binary_accuracy: 0.8182 - val_loss: 0.5096 - val_binary_accuracy: 0.8400\n",
            "Epoch 99/400\n",
            "7/7 [==============================] - 0s 20ms/step - loss: 0.5375 - binary_accuracy: 0.8278 - val_loss: 0.5478 - val_binary_accuracy: 0.7400\n",
            "Epoch 100/400\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5619 - binary_accuracy: 0.5000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131545-qrwyz9in/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 306ms/step - loss: 0.4237 - binary_accuracy: 0.7847 - val_loss: 0.4972 - val_binary_accuracy: 0.8000\n",
            "Epoch 101/400\n",
            "7/7 [==============================] - 0s 27ms/step - loss: 0.2937 - binary_accuracy: 0.8469 - val_loss: 1.1105 - val_binary_accuracy: 0.5000\n",
            "Epoch 102/400\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.5987 - binary_accuracy: 0.6459 - val_loss: 0.5700 - val_binary_accuracy: 0.8200\n",
            "Epoch 103/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4223 - binary_accuracy: 0.8086 - val_loss: 0.5848 - val_binary_accuracy: 0.6600\n",
            "Epoch 104/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4227 - binary_accuracy: 0.7799 - val_loss: 0.5529 - val_binary_accuracy: 0.8000\n",
            "Epoch 105/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3386 - binary_accuracy: 0.8517 - val_loss: 0.7329 - val_binary_accuracy: 0.7200\n",
            "Epoch 106/400\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3392 - binary_accuracy: 0.8469 - val_loss: 0.5120 - val_binary_accuracy: 0.7600\n",
            "Epoch 107/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2910 - binary_accuracy: 0.8421 - val_loss: 1.5878 - val_binary_accuracy: 0.4400\n",
            "Epoch 108/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4451 - binary_accuracy: 0.7608 - val_loss: 0.6934 - val_binary_accuracy: 0.6800\n",
            "Epoch 109/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4766 - binary_accuracy: 0.7656 - val_loss: 1.1604 - val_binary_accuracy: 0.6000\n",
            "Epoch 110/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5039 - binary_accuracy: 0.6890 - val_loss: 0.6029 - val_binary_accuracy: 0.8000\n",
            "Epoch 111/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3233 - binary_accuracy: 0.8469 - val_loss: 0.7016 - val_binary_accuracy: 0.7000\n",
            "Epoch 112/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2812 - binary_accuracy: 0.8660 - val_loss: 0.9833 - val_binary_accuracy: 0.6600\n",
            "Epoch 113/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3111 - binary_accuracy: 0.8517 - val_loss: 3.6061 - val_binary_accuracy: 0.3800\n",
            "Epoch 114/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.9060 - binary_accuracy: 0.4785 - val_loss: 0.6112 - val_binary_accuracy: 0.7600\n",
            "Epoch 115/400\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4783 - binary_accuracy: 0.7081 - val_loss: 0.6366 - val_binary_accuracy: 0.7200\n",
            "Epoch 116/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4472 - binary_accuracy: 0.7416 - val_loss: 0.6419 - val_binary_accuracy: 0.6800\n",
            "Epoch 117/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3660 - binary_accuracy: 0.8230 - val_loss: 0.7778 - val_binary_accuracy: 0.5800\n",
            "Epoch 118/400\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.4764 - binary_accuracy: 0.7081 - val_loss: 0.5788 - val_binary_accuracy: 0.7800\n",
            "Epoch 119/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3586 - binary_accuracy: 0.8182 - val_loss: 1.0744 - val_binary_accuracy: 0.5400\n",
            "Epoch 120/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4253 - binary_accuracy: 0.7751 - val_loss: 0.6364 - val_binary_accuracy: 0.6600\n",
            "Epoch 121/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4303 - binary_accuracy: 0.8086 - val_loss: 0.6704 - val_binary_accuracy: 0.6800\n",
            "Epoch 122/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4484 - binary_accuracy: 0.7512 - val_loss: 0.6305 - val_binary_accuracy: 0.6400\n",
            "Epoch 123/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3701 - binary_accuracy: 0.7512 - val_loss: 0.5297 - val_binary_accuracy: 0.8200\n",
            "Epoch 124/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3455 - binary_accuracy: 0.8230 - val_loss: 1.4353 - val_binary_accuracy: 0.4800\n",
            "Epoch 125/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3201 - binary_accuracy: 0.8134 - val_loss: 0.5471 - val_binary_accuracy: 0.8000\n",
            "Epoch 126/400\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3640 - binary_accuracy: 0.8134 - val_loss: 0.7370 - val_binary_accuracy: 0.6600\n",
            "Epoch 127/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.4790 - binary_accuracy: 0.6124 - val_loss: 0.7293 - val_binary_accuracy: 0.7200\n",
            "Epoch 128/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3848 - binary_accuracy: 0.7512 - val_loss: 0.8684 - val_binary_accuracy: 0.5400\n",
            "Epoch 129/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2956 - binary_accuracy: 0.8756 - val_loss: 0.5759 - val_binary_accuracy: 0.7800\n",
            "Epoch 130/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.7294 - binary_accuracy: 0.7321 - val_loss: 0.5396 - val_binary_accuracy: 0.5800\n",
            "Epoch 131/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2862 - binary_accuracy: 0.8517 - val_loss: 0.7624 - val_binary_accuracy: 0.6800\n",
            "Epoch 132/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3184 - binary_accuracy: 0.8278 - val_loss: 0.7128 - val_binary_accuracy: 0.5800\n",
            "Epoch 133/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3619 - binary_accuracy: 0.8182 - val_loss: 0.5361 - val_binary_accuracy: 0.5800\n",
            "Epoch 134/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3280 - binary_accuracy: 0.8469 - val_loss: 0.5634 - val_binary_accuracy: 0.6000\n",
            "Epoch 135/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2211 - binary_accuracy: 0.9091 - val_loss: 0.7367 - val_binary_accuracy: 0.6800\n",
            "Epoch 136/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3695 - binary_accuracy: 0.7943 - val_loss: 0.5274 - val_binary_accuracy: 0.7800\n",
            "Epoch 137/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2354 - binary_accuracy: 0.8804 - val_loss: 0.6263 - val_binary_accuracy: 0.7800\n",
            "Epoch 138/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5058 - binary_accuracy: 0.8038 - val_loss: 0.5583 - val_binary_accuracy: 0.5800\n",
            "Epoch 139/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2680 - binary_accuracy: 0.8660 - val_loss: 0.5202 - val_binary_accuracy: 0.7800\n",
            "Epoch 140/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2653 - binary_accuracy: 0.8708 - val_loss: 0.6731 - val_binary_accuracy: 0.6600\n",
            "Epoch 141/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3343 - binary_accuracy: 0.8421 - val_loss: 0.5961 - val_binary_accuracy: 0.5600\n",
            "Epoch 142/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3120 - binary_accuracy: 0.8421 - val_loss: 0.8186 - val_binary_accuracy: 0.6000\n",
            "Epoch 143/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3309 - binary_accuracy: 0.8230 - val_loss: 0.9644 - val_binary_accuracy: 0.6000\n",
            "Epoch 144/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2308 - binary_accuracy: 0.8708 - val_loss: 0.5310 - val_binary_accuracy: 0.7400\n",
            "Epoch 145/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2549 - binary_accuracy: 0.8708 - val_loss: 0.8420 - val_binary_accuracy: 0.7200\n",
            "Epoch 146/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5506 - binary_accuracy: 0.7990 - val_loss: 0.8366 - val_binary_accuracy: 0.4000\n",
            "Epoch 147/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5365 - binary_accuracy: 0.7368 - val_loss: 0.6655 - val_binary_accuracy: 0.4200\n",
            "Epoch 148/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3935 - binary_accuracy: 0.7895 - val_loss: 1.6817 - val_binary_accuracy: 0.3400\n",
            "Epoch 149/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3750 - binary_accuracy: 0.7990 - val_loss: 0.5614 - val_binary_accuracy: 0.7400\n",
            "Epoch 150/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3477 - binary_accuracy: 0.7416 - val_loss: 0.9399 - val_binary_accuracy: 0.4800\n",
            "Epoch 151/400\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.2008 - binary_accuracy: 0.9139 - val_loss: 0.7029 - val_binary_accuracy: 0.7400\n",
            "Epoch 152/400\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.3393 - binary_accuracy: 0.8517 - val_loss: 0.5173 - val_binary_accuracy: 0.7800\n",
            "Epoch 153/400\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.2213 - binary_accuracy: 0.9091 - val_loss: 0.7826 - val_binary_accuracy: 0.6200\n",
            "Epoch 154/400\n",
            "7/7 [==============================] - 0s 29ms/step - loss: 0.1543 - binary_accuracy: 0.9234 - val_loss: 0.7222 - val_binary_accuracy: 0.7200\n",
            "Epoch 155/400\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3055 - binary_accuracy: 0.8612 - val_loss: 0.6216 - val_binary_accuracy: 0.6600\n",
            "Epoch 156/400\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.1735 - binary_accuracy: 0.9234 - val_loss: 0.7405 - val_binary_accuracy: 0.6800\n",
            "Epoch 157/400\n",
            "7/7 [==============================] - 0s 31ms/step - loss: 0.2253 - binary_accuracy: 0.8947 - val_loss: 0.7410 - val_binary_accuracy: 0.4800\n",
            "Epoch 158/400\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.5300 - binary_accuracy: 0.7847 - val_loss: 0.5603 - val_binary_accuracy: 0.6000\n",
            "Epoch 159/400\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.3100 - binary_accuracy: 0.8612 - val_loss: 0.6436 - val_binary_accuracy: 0.7400\n",
            "Epoch 160/400\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.1467 - binary_accuracy: 0.9187 - val_loss: 0.5993 - val_binary_accuracy: 0.7800\n",
            "Epoch 161/400\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.2953 - binary_accuracy: 0.8134 - val_loss: 0.8543 - val_binary_accuracy: 0.5600\n",
            "Epoch 162/400\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.1980 - binary_accuracy: 0.8900 - val_loss: 0.8857 - val_binary_accuracy: 0.6600\n",
            "Epoch 163/400\n",
            "7/7 [==============================] - 0s 32ms/step - loss: 0.1455 - binary_accuracy: 0.9522 - val_loss: 0.5776 - val_binary_accuracy: 0.8000\n",
            "Epoch 164/400\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.3617 - binary_accuracy: 0.8708 - val_loss: 2.1450 - val_binary_accuracy: 0.3800\n",
            "Epoch 165/400\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.5956 - binary_accuracy: 0.7273 - val_loss: 0.6717 - val_binary_accuracy: 0.6400\n",
            "Epoch 166/400\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4542 - binary_accuracy: 0.7321 - val_loss: 0.7676 - val_binary_accuracy: 0.4600\n",
            "Epoch 167/400\n",
            "7/7 [==============================] - 0s 22ms/step - loss: 0.2806 - binary_accuracy: 0.7990 - val_loss: 0.7870 - val_binary_accuracy: 0.5400\n",
            "Epoch 168/400\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2640 - binary_accuracy: 0.8038 - val_loss: 0.7498 - val_binary_accuracy: 0.6400\n",
            "Epoch 169/400\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.3176 - binary_accuracy: 0.7560 - val_loss: 0.7243 - val_binary_accuracy: 0.6200\n",
            "Epoch 170/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5154 - binary_accuracy: 0.7129 - val_loss: 0.7436 - val_binary_accuracy: 0.3600\n",
            "Epoch 171/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4690 - binary_accuracy: 0.7416 - val_loss: 0.8350 - val_binary_accuracy: 0.4600\n",
            "Epoch 172/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4363 - binary_accuracy: 0.7943 - val_loss: 0.6482 - val_binary_accuracy: 0.4200\n",
            "Epoch 173/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5529 - binary_accuracy: 0.7703 - val_loss: 0.6455 - val_binary_accuracy: 0.4200\n",
            "Epoch 174/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3803 - binary_accuracy: 0.7943 - val_loss: 1.0947 - val_binary_accuracy: 0.4800\n",
            "Epoch 175/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2472 - binary_accuracy: 0.8373 - val_loss: 0.8767 - val_binary_accuracy: 0.6800\n",
            "Epoch 176/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2436 - binary_accuracy: 0.8182 - val_loss: 1.3044 - val_binary_accuracy: 0.5600\n",
            "Epoch 177/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5016 - binary_accuracy: 0.7751 - val_loss: 0.6779 - val_binary_accuracy: 0.4600\n",
            "Epoch 178/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3358 - binary_accuracy: 0.7512 - val_loss: 0.8307 - val_binary_accuracy: 0.4600\n",
            "Epoch 179/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2526 - binary_accuracy: 0.8373 - val_loss: 0.6269 - val_binary_accuracy: 0.6400\n",
            "Epoch 180/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1893 - binary_accuracy: 0.9187 - val_loss: 0.6437 - val_binary_accuracy: 0.6600\n",
            "Epoch 181/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3263 - binary_accuracy: 0.8086 - val_loss: 1.0673 - val_binary_accuracy: 0.5400\n",
            "Epoch 182/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2305 - binary_accuracy: 0.8469 - val_loss: 0.6783 - val_binary_accuracy: 0.7200\n",
            "Epoch 183/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2367 - binary_accuracy: 0.8708 - val_loss: 0.9312 - val_binary_accuracy: 0.6600\n",
            "Epoch 184/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1806 - binary_accuracy: 0.9139 - val_loss: 0.6513 - val_binary_accuracy: 0.7400\n",
            "Epoch 185/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2595 - binary_accuracy: 0.8756 - val_loss: 1.1714 - val_binary_accuracy: 0.6600\n",
            "Epoch 186/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1172 - binary_accuracy: 0.9378 - val_loss: 0.6735 - val_binary_accuracy: 0.7600\n",
            "Epoch 187/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2005 - binary_accuracy: 0.8756 - val_loss: 0.9879 - val_binary_accuracy: 0.7600\n",
            "Epoch 188/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1097 - binary_accuracy: 0.9330 - val_loss: 1.3156 - val_binary_accuracy: 0.7200\n",
            "Epoch 189/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2471 - binary_accuracy: 0.8852 - val_loss: 1.2956 - val_binary_accuracy: 0.5800\n",
            "Epoch 190/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1805 - binary_accuracy: 0.9139 - val_loss: 1.1516 - val_binary_accuracy: 0.6600\n",
            "Epoch 191/400\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1409 - binary_accuracy: 0.9091 - val_loss: 1.5132 - val_binary_accuracy: 0.6200\n",
            "Epoch 192/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0948 - binary_accuracy: 0.9330 - val_loss: 0.7194 - val_binary_accuracy: 0.7800\n",
            "Epoch 193/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1934 - binary_accuracy: 0.8995 - val_loss: 0.9425 - val_binary_accuracy: 0.7200\n",
            "Epoch 194/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2121 - binary_accuracy: 0.8756 - val_loss: 0.9483 - val_binary_accuracy: 0.7600\n",
            "Epoch 195/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1039 - binary_accuracy: 0.9330 - val_loss: 0.7515 - val_binary_accuracy: 0.8000\n",
            "Epoch 196/400\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1187 - binary_accuracy: 0.9282 - val_loss: 0.9134 - val_binary_accuracy: 0.7800\n",
            "Epoch 197/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1026 - binary_accuracy: 0.9330 - val_loss: 0.9144 - val_binary_accuracy: 0.7400\n",
            "Epoch 198/400\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.8449 - binary_accuracy: 0.7895 - val_loss: 0.6444 - val_binary_accuracy: 0.7400\n",
            "Epoch 199/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3981 - binary_accuracy: 0.7943 - val_loss: 1.3938 - val_binary_accuracy: 0.5600\n",
            "Epoch 200/400\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3462 - binary_accuracy: 0.8517 - val_loss: 1.0016 - val_binary_accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best_epoch 99\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best_val_loss 0.49717\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy 0.85167\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 199\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss 0.34621\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy 0.68\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss 1.00165\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mdenim-sweep-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/qrwyz9in\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 80 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230918_131545-qrwyz9in/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 198zlqqw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 600\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 29\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 28\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearn_rate: 0.019620246446749427\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230918_131811-198zlqqw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtwilight-sweep-3\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/sweeps/5z67asm0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/198zlqqw\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "1/7 [===>..........................] - ETA: 4s - loss: 0.6992 - binary_accuracy: 0.4688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 166ms/step - loss: 0.7166 - binary_accuracy: 0.5933 - val_loss: 1.3553 - val_binary_accuracy: 0.3400\n",
            "Epoch 2/600\n",
            "7/7 [==============================] - ETA: 0s - loss: 0.6820 - binary_accuracy: 0.6507"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 162ms/step - loss: 0.6820 - binary_accuracy: 0.6507 - val_loss: 1.0361 - val_binary_accuracy: 0.3400\n",
            "Epoch 3/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6391 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 222ms/step - loss: 0.6375 - binary_accuracy: 0.6555 - val_loss: 0.7709 - val_binary_accuracy: 0.3400\n",
            "Epoch 4/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6247 - binary_accuracy: 0.6459 - val_loss: 0.7994 - val_binary_accuracy: 0.3400\n",
            "Epoch 5/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5593 - binary_accuracy: 0.7188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 143ms/step - loss: 0.6275 - binary_accuracy: 0.6316 - val_loss: 0.6928 - val_binary_accuracy: 0.4400\n",
            "Epoch 6/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6338 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 146ms/step - loss: 0.6000 - binary_accuracy: 0.6651 - val_loss: 0.6265 - val_binary_accuracy: 0.7200\n",
            "Epoch 7/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5952 - binary_accuracy: 0.6794 - val_loss: 0.7431 - val_binary_accuracy: 0.3600\n",
            "Epoch 8/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6024 - binary_accuracy: 0.6651 - val_loss: 0.8390 - val_binary_accuracy: 0.3400\n",
            "Epoch 9/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5645 - binary_accuracy: 0.7129 - val_loss: 0.6382 - val_binary_accuracy: 0.6800\n",
            "Epoch 10/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6339 - binary_accuracy: 0.6746 - val_loss: 0.8013 - val_binary_accuracy: 0.3600\n",
            "Epoch 11/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.5739 - binary_accuracy: 0.6986 - val_loss: 0.9080 - val_binary_accuracy: 0.3400\n",
            "Epoch 12/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6067 - binary_accuracy: 0.6562"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 142ms/step - loss: 0.5660 - binary_accuracy: 0.6746 - val_loss: 0.5848 - val_binary_accuracy: 0.7200\n",
            "Epoch 13/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6060 - binary_accuracy: 0.6459 - val_loss: 0.8726 - val_binary_accuracy: 0.3400\n",
            "Epoch 14/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5945 - binary_accuracy: 0.6794 - val_loss: 0.6520 - val_binary_accuracy: 0.5800\n",
            "Epoch 15/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5626 - binary_accuracy: 0.6875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 146ms/step - loss: 0.5356 - binary_accuracy: 0.7225 - val_loss: 0.5729 - val_binary_accuracy: 0.8000\n",
            "Epoch 16/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5151 - binary_accuracy: 0.7464 - val_loss: 0.8097 - val_binary_accuracy: 0.4600\n",
            "Epoch 17/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5661 - binary_accuracy: 0.6890 - val_loss: 0.9893 - val_binary_accuracy: 0.3400\n",
            "Epoch 18/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5515 - binary_accuracy: 0.6938 - val_loss: 0.6203 - val_binary_accuracy: 0.7200\n",
            "Epoch 19/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5294 - binary_accuracy: 0.7321 - val_loss: 0.5949 - val_binary_accuracy: 0.7200\n",
            "Epoch 20/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.5537 - binary_accuracy: 0.8125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 273ms/step - loss: 0.5449 - binary_accuracy: 0.7512 - val_loss: 0.5292 - val_binary_accuracy: 0.7600\n",
            "Epoch 21/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.5423 - binary_accuracy: 0.7129 - val_loss: 0.5884 - val_binary_accuracy: 0.7400\n",
            "Epoch 22/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5334 - binary_accuracy: 0.7464 - val_loss: 0.8719 - val_binary_accuracy: 0.4400\n",
            "Epoch 23/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5429 - binary_accuracy: 0.7081 - val_loss: 0.7808 - val_binary_accuracy: 0.4400\n",
            "Epoch 24/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4954 - binary_accuracy: 0.7703 - val_loss: 0.7324 - val_binary_accuracy: 0.4800\n",
            "Epoch 25/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.4819 - binary_accuracy: 0.7751 - val_loss: 0.6253 - val_binary_accuracy: 0.6800\n",
            "Epoch 26/600\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.4587 - binary_accuracy: 0.8086 - val_loss: 0.5762 - val_binary_accuracy: 0.7000\n",
            "Epoch 27/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.3870 - binary_accuracy: 0.9688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 206ms/step - loss: 0.4302 - binary_accuracy: 0.8421 - val_loss: 0.4860 - val_binary_accuracy: 0.8000\n",
            "Epoch 28/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.5361 - binary_accuracy: 0.7129 - val_loss: 1.5051 - val_binary_accuracy: 0.3400\n",
            "Epoch 29/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.5182 - binary_accuracy: 0.7321 - val_loss: 0.5785 - val_binary_accuracy: 0.7200\n",
            "Epoch 30/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4634 - binary_accuracy: 0.7847 - val_loss: 0.5247 - val_binary_accuracy: 0.7600\n",
            "Epoch 31/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4794 - binary_accuracy: 0.7608 - val_loss: 0.5498 - val_binary_accuracy: 0.7600\n",
            "Epoch 32/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4423 - binary_accuracy: 0.7990 - val_loss: 0.4929 - val_binary_accuracy: 0.8000\n",
            "Epoch 33/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4214 - binary_accuracy: 0.7751 - val_loss: 0.7205 - val_binary_accuracy: 0.6000\n",
            "Epoch 34/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4083 - binary_accuracy: 0.8278 - val_loss: 0.4964 - val_binary_accuracy: 0.8000\n",
            "Epoch 35/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4597 - binary_accuracy: 0.7703 - val_loss: 1.6403 - val_binary_accuracy: 0.3400\n",
            "Epoch 36/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4664 - binary_accuracy: 0.7943 - val_loss: 1.3207 - val_binary_accuracy: 0.3400\n",
            "Epoch 37/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4514 - binary_accuracy: 0.7799 - val_loss: 1.1566 - val_binary_accuracy: 0.3600\n",
            "Epoch 38/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4409 - binary_accuracy: 0.8182 - val_loss: 0.7542 - val_binary_accuracy: 0.6200\n",
            "Epoch 39/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.3631 - binary_accuracy: 0.8373 - val_loss: 0.7926 - val_binary_accuracy: 0.5200\n",
            "Epoch 40/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3492 - binary_accuracy: 0.8565 - val_loss: 0.5404 - val_binary_accuracy: 0.7400\n",
            "Epoch 41/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.5700 - binary_accuracy: 0.7273 - val_loss: 0.9879 - val_binary_accuracy: 0.4400\n",
            "Epoch 42/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3646 - binary_accuracy: 0.8852 - val_loss: 0.5582 - val_binary_accuracy: 0.7200\n",
            "Epoch 43/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.4631 - binary_accuracy: 0.7799 - val_loss: 0.4932 - val_binary_accuracy: 0.8000\n",
            "Epoch 44/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3432 - binary_accuracy: 0.8660 - val_loss: 0.5573 - val_binary_accuracy: 0.7800\n",
            "Epoch 45/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3837 - binary_accuracy: 0.8182 - val_loss: 0.6635 - val_binary_accuracy: 0.6200\n",
            "Epoch 46/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.4837 - binary_accuracy: 0.7321 - val_loss: 0.5955 - val_binary_accuracy: 0.7000\n",
            "Epoch 47/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3763 - binary_accuracy: 0.8373 - val_loss: 0.8996 - val_binary_accuracy: 0.5400\n",
            "Epoch 48/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.3243 - binary_accuracy: 0.8708 - val_loss: 0.5471 - val_binary_accuracy: 0.7400\n",
            "Epoch 49/600\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.4062 - binary_accuracy: 0.8373 - val_loss: 0.6528 - val_binary_accuracy: 0.7000\n",
            "Epoch 50/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.5075 - binary_accuracy: 0.7608 - val_loss: 0.6441 - val_binary_accuracy: 0.5800\n",
            "Epoch 51/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.3894 - binary_accuracy: 0.8134 - val_loss: 0.7498 - val_binary_accuracy: 0.6600\n",
            "Epoch 52/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3314 - binary_accuracy: 0.8517 - val_loss: 0.5080 - val_binary_accuracy: 0.7600\n",
            "Epoch 53/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3393 - binary_accuracy: 0.8517 - val_loss: 2.3435 - val_binary_accuracy: 0.3400\n",
            "Epoch 54/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4531 - binary_accuracy: 0.8612 - val_loss: 0.4913 - val_binary_accuracy: 0.8000\n",
            "Epoch 55/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3089 - binary_accuracy: 0.8517 - val_loss: 0.7382 - val_binary_accuracy: 0.5800\n",
            "Epoch 56/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4371 - binary_accuracy: 0.7656 - val_loss: 0.6137 - val_binary_accuracy: 0.7200\n",
            "Epoch 57/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3449 - binary_accuracy: 0.8565 - val_loss: 1.4404 - val_binary_accuracy: 0.3800\n",
            "Epoch 58/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3755 - binary_accuracy: 0.8373 - val_loss: 0.8215 - val_binary_accuracy: 0.6400\n",
            "Epoch 59/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3265 - binary_accuracy: 0.8517 - val_loss: 0.5585 - val_binary_accuracy: 0.7600\n",
            "Epoch 60/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2533 - binary_accuracy: 0.9091 - val_loss: 1.0470 - val_binary_accuracy: 0.4800\n",
            "Epoch 61/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2563 - binary_accuracy: 0.8900 - val_loss: 0.7896 - val_binary_accuracy: 0.7000\n",
            "Epoch 62/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.4538 - binary_accuracy: 0.7751 - val_loss: 0.5454 - val_binary_accuracy: 0.7400\n",
            "Epoch 63/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2640 - binary_accuracy: 0.9139 - val_loss: 2.3112 - val_binary_accuracy: 0.4000\n",
            "Epoch 64/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.7559 - binary_accuracy: 0.6507 - val_loss: 0.5577 - val_binary_accuracy: 0.7600\n",
            "Epoch 65/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.3734 - binary_accuracy: 0.7943 - val_loss: 0.5052 - val_binary_accuracy: 0.8000\n",
            "Epoch 66/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2696 - binary_accuracy: 0.9091 - val_loss: 0.6792 - val_binary_accuracy: 0.7400\n",
            "Epoch 67/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2165 - binary_accuracy: 0.9426 - val_loss: 0.7741 - val_binary_accuracy: 0.6800\n",
            "Epoch 68/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.4108 - binary_accuracy: 0.7751 - val_loss: 0.7690 - val_binary_accuracy: 0.6000\n",
            "Epoch 69/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3366 - binary_accuracy: 0.8325 - val_loss: 0.8738 - val_binary_accuracy: 0.6200\n",
            "Epoch 70/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2752 - binary_accuracy: 0.8708 - val_loss: 1.0093 - val_binary_accuracy: 0.5000\n",
            "Epoch 71/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2319 - binary_accuracy: 0.9330 - val_loss: 0.6683 - val_binary_accuracy: 0.7800\n",
            "Epoch 72/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.2295 - binary_accuracy: 0.9062"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131811-198zlqqw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 141ms/step - loss: 0.3011 - binary_accuracy: 0.8708 - val_loss: 0.4642 - val_binary_accuracy: 0.7600\n",
            "Epoch 73/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.3179 - binary_accuracy: 0.8565 - val_loss: 0.5648 - val_binary_accuracy: 0.7400\n",
            "Epoch 74/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.2033 - binary_accuracy: 0.9282 - val_loss: 0.7294 - val_binary_accuracy: 0.6600\n",
            "Epoch 75/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2992 - binary_accuracy: 0.8756 - val_loss: 0.5862 - val_binary_accuracy: 0.7800\n",
            "Epoch 76/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2157 - binary_accuracy: 0.9282 - val_loss: 1.0441 - val_binary_accuracy: 0.5800\n",
            "Epoch 77/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2845 - binary_accuracy: 0.8565 - val_loss: 0.5110 - val_binary_accuracy: 0.8200\n",
            "Epoch 78/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2275 - binary_accuracy: 0.9187 - val_loss: 0.5215 - val_binary_accuracy: 0.7600\n",
            "Epoch 79/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3854 - binary_accuracy: 0.7990 - val_loss: 0.7091 - val_binary_accuracy: 0.6400\n",
            "Epoch 80/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.2286 - binary_accuracy: 0.9139 - val_loss: 1.3531 - val_binary_accuracy: 0.4400\n",
            "Epoch 81/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.4766 - binary_accuracy: 0.7656 - val_loss: 0.8743 - val_binary_accuracy: 0.6600\n",
            "Epoch 82/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1977 - binary_accuracy: 0.9330 - val_loss: 0.6759 - val_binary_accuracy: 0.7800\n",
            "Epoch 83/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1456 - binary_accuracy: 0.9617 - val_loss: 0.7062 - val_binary_accuracy: 0.7200\n",
            "Epoch 84/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1339 - binary_accuracy: 0.9713 - val_loss: 0.5605 - val_binary_accuracy: 0.7800\n",
            "Epoch 85/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1759 - binary_accuracy: 0.9474 - val_loss: 1.0990 - val_binary_accuracy: 0.5400\n",
            "Epoch 86/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.3402 - binary_accuracy: 0.8565 - val_loss: 0.8359 - val_binary_accuracy: 0.6600\n",
            "Epoch 87/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1552 - binary_accuracy: 0.9617 - val_loss: 0.8537 - val_binary_accuracy: 0.7600\n",
            "Epoch 88/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1244 - binary_accuracy: 0.9713 - val_loss: 1.0617 - val_binary_accuracy: 0.6600\n",
            "Epoch 89/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1925 - binary_accuracy: 0.9187 - val_loss: 0.6527 - val_binary_accuracy: 0.7800\n",
            "Epoch 90/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.3121 - binary_accuracy: 0.8469 - val_loss: 0.8756 - val_binary_accuracy: 0.6800\n",
            "Epoch 91/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1750 - binary_accuracy: 0.9282 - val_loss: 0.7437 - val_binary_accuracy: 0.7200\n",
            "Epoch 92/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1254 - binary_accuracy: 0.9761 - val_loss: 0.6129 - val_binary_accuracy: 0.8200\n",
            "Epoch 93/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1228 - binary_accuracy: 0.9617 - val_loss: 0.6032 - val_binary_accuracy: 0.8000\n",
            "Epoch 94/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.2086 - binary_accuracy: 0.9330 - val_loss: 1.2776 - val_binary_accuracy: 0.5600\n",
            "Epoch 95/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.2966 - binary_accuracy: 0.8804 - val_loss: 0.8018 - val_binary_accuracy: 0.7000\n",
            "Epoch 96/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1290 - binary_accuracy: 0.9617 - val_loss: 1.1198 - val_binary_accuracy: 0.6800\n",
            "Epoch 97/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.1401 - binary_accuracy: 0.9282 - val_loss: 0.8183 - val_binary_accuracy: 0.6800\n",
            "Epoch 98/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.1119 - binary_accuracy: 0.9617 - val_loss: 0.7316 - val_binary_accuracy: 0.8000\n",
            "Epoch 99/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1091 - binary_accuracy: 0.9617 - val_loss: 0.6717 - val_binary_accuracy: 0.8000\n",
            "Epoch 100/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0786 - binary_accuracy: 0.9856 - val_loss: 1.3224 - val_binary_accuracy: 0.6000\n",
            "Epoch 101/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.1448 - binary_accuracy: 0.9474 - val_loss: 0.6379 - val_binary_accuracy: 0.7800\n",
            "Epoch 102/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.1044 - binary_accuracy: 0.9617 - val_loss: 0.9847 - val_binary_accuracy: 0.7000\n",
            "Epoch 103/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0745 - binary_accuracy: 0.9904 - val_loss: 0.6668 - val_binary_accuracy: 0.7800\n",
            "Epoch 104/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0728 - binary_accuracy: 0.9809 - val_loss: 1.1170 - val_binary_accuracy: 0.6600\n",
            "Epoch 105/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0748 - binary_accuracy: 0.9856 - val_loss: 0.7322 - val_binary_accuracy: 0.7600\n",
            "Epoch 106/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0666 - binary_accuracy: 0.9952 - val_loss: 0.6075 - val_binary_accuracy: 0.7800\n",
            "Epoch 107/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0811 - binary_accuracy: 0.9856 - val_loss: 0.6435 - val_binary_accuracy: 0.8200\n",
            "Epoch 108/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0931 - binary_accuracy: 0.9809 - val_loss: 0.9506 - val_binary_accuracy: 0.6600\n",
            "Epoch 109/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0815 - binary_accuracy: 0.9809 - val_loss: 0.6884 - val_binary_accuracy: 0.8000\n",
            "Epoch 110/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6734 - binary_accuracy: 0.7799 - val_loss: 0.7864 - val_binary_accuracy: 0.6800\n",
            "Epoch 111/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.1495 - binary_accuracy: 0.9713 - val_loss: 0.8282 - val_binary_accuracy: 0.7400\n",
            "Epoch 112/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0992 - binary_accuracy: 0.9856 - val_loss: 0.7769 - val_binary_accuracy: 0.7400\n",
            "Epoch 113/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.1995 - binary_accuracy: 0.9187 - val_loss: 1.7494 - val_binary_accuracy: 0.4200\n",
            "Epoch 114/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.2219 - binary_accuracy: 0.9091 - val_loss: 0.7518 - val_binary_accuracy: 0.7400\n",
            "Epoch 115/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0656 - binary_accuracy: 1.0000 - val_loss: 0.7993 - val_binary_accuracy: 0.7600\n",
            "Epoch 116/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0689 - binary_accuracy: 0.9856 - val_loss: 0.8118 - val_binary_accuracy: 0.7800\n",
            "Epoch 117/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0505 - binary_accuracy: 0.9952 - val_loss: 0.8405 - val_binary_accuracy: 0.7600\n",
            "Epoch 118/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0588 - binary_accuracy: 1.0000 - val_loss: 0.8618 - val_binary_accuracy: 0.7600\n",
            "Epoch 119/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0561 - binary_accuracy: 0.9856 - val_loss: 0.8196 - val_binary_accuracy: 0.7600\n",
            "Epoch 120/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0729 - binary_accuracy: 0.9809 - val_loss: 0.7236 - val_binary_accuracy: 0.7600\n",
            "Epoch 121/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0450 - binary_accuracy: 0.9952 - val_loss: 0.9905 - val_binary_accuracy: 0.7200\n",
            "Epoch 122/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0449 - binary_accuracy: 0.9904 - val_loss: 0.8221 - val_binary_accuracy: 0.8000\n",
            "Epoch 123/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0416 - binary_accuracy: 0.9952 - val_loss: 0.8047 - val_binary_accuracy: 0.7600\n",
            "Epoch 124/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0346 - binary_accuracy: 1.0000 - val_loss: 0.9516 - val_binary_accuracy: 0.7600\n",
            "Epoch 125/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0372 - binary_accuracy: 1.0000 - val_loss: 0.9645 - val_binary_accuracy: 0.8000\n",
            "Epoch 126/600\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.0362 - binary_accuracy: 0.9952 - val_loss: 1.0836 - val_binary_accuracy: 0.7400\n",
            "Epoch 127/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0428 - binary_accuracy: 0.9952 - val_loss: 1.2827 - val_binary_accuracy: 0.6800\n",
            "Epoch 128/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0484 - binary_accuracy: 0.9856 - val_loss: 0.9753 - val_binary_accuracy: 0.7400\n",
            "Epoch 129/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0306 - binary_accuracy: 1.0000 - val_loss: 0.8636 - val_binary_accuracy: 0.7600\n",
            "Epoch 130/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0376 - binary_accuracy: 0.9952 - val_loss: 1.0274 - val_binary_accuracy: 0.7200\n",
            "Epoch 131/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0268 - binary_accuracy: 1.0000 - val_loss: 0.8896 - val_binary_accuracy: 0.7600\n",
            "Epoch 132/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0250 - binary_accuracy: 1.0000 - val_loss: 0.9242 - val_binary_accuracy: 0.7600\n",
            "Epoch 133/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0248 - binary_accuracy: 1.0000 - val_loss: 1.3012 - val_binary_accuracy: 0.6800\n",
            "Epoch 134/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0316 - binary_accuracy: 0.9904 - val_loss: 0.8889 - val_binary_accuracy: 0.7800\n",
            "Epoch 135/600\n",
            "7/7 [==============================] - 0s 23ms/step - loss: 0.0680 - binary_accuracy: 0.9856 - val_loss: 0.8980 - val_binary_accuracy: 0.7600\n",
            "Epoch 136/600\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0255 - binary_accuracy: 1.0000 - val_loss: 0.9864 - val_binary_accuracy: 0.7600\n",
            "Epoch 137/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0250 - binary_accuracy: 1.0000 - val_loss: 0.9489 - val_binary_accuracy: 0.7600\n",
            "Epoch 138/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0239 - binary_accuracy: 0.9952 - val_loss: 0.8671 - val_binary_accuracy: 0.7600\n",
            "Epoch 139/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0382 - binary_accuracy: 0.9952 - val_loss: 0.8754 - val_binary_accuracy: 0.7600\n",
            "Epoch 140/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0231 - binary_accuracy: 1.0000 - val_loss: 0.8873 - val_binary_accuracy: 0.8000\n",
            "Epoch 141/600\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.0317 - binary_accuracy: 0.9952 - val_loss: 0.9373 - val_binary_accuracy: 0.7600\n",
            "Epoch 142/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0183 - binary_accuracy: 1.0000 - val_loss: 1.0524 - val_binary_accuracy: 0.7600\n",
            "Epoch 143/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0243 - binary_accuracy: 1.0000 - val_loss: 0.9497 - val_binary_accuracy: 0.7600\n",
            "Epoch 144/600\n",
            "7/7 [==============================] - 0s 28ms/step - loss: 0.0177 - binary_accuracy: 1.0000 - val_loss: 0.9089 - val_binary_accuracy: 0.7600\n",
            "Epoch 145/600\n",
            "7/7 [==============================] - 0s 33ms/step - loss: 0.0160 - binary_accuracy: 1.0000 - val_loss: 1.0444 - val_binary_accuracy: 0.7600\n",
            "Epoch 146/600\n",
            "7/7 [==============================] - 0s 39ms/step - loss: 0.0151 - binary_accuracy: 1.0000 - val_loss: 0.9445 - val_binary_accuracy: 0.7600\n",
            "Epoch 147/600\n",
            "7/7 [==============================] - 0s 25ms/step - loss: 0.0147 - binary_accuracy: 1.0000 - val_loss: 0.9650 - val_binary_accuracy: 0.7600\n",
            "Epoch 148/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.0150 - binary_accuracy: 1.0000 - val_loss: 0.9632 - val_binary_accuracy: 0.7600\n",
            "Epoch 149/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0158 - binary_accuracy: 1.0000 - val_loss: 1.0006 - val_binary_accuracy: 0.7600\n",
            "Epoch 150/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0130 - binary_accuracy: 1.0000 - val_loss: 1.0829 - val_binary_accuracy: 0.7600\n",
            "Epoch 151/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0148 - binary_accuracy: 1.0000 - val_loss: 0.9061 - val_binary_accuracy: 0.7600\n",
            "Epoch 152/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0164 - binary_accuracy: 1.0000 - val_loss: 1.0562 - val_binary_accuracy: 0.7600\n",
            "Epoch 153/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.0126 - binary_accuracy: 1.0000 - val_loss: 1.0068 - val_binary_accuracy: 0.7600\n",
            "Epoch 154/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0125 - binary_accuracy: 1.0000 - val_loss: 0.9757 - val_binary_accuracy: 0.7600\n",
            "Epoch 155/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0116 - binary_accuracy: 1.0000 - val_loss: 1.0820 - val_binary_accuracy: 0.7600\n",
            "Epoch 156/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0150 - binary_accuracy: 1.0000 - val_loss: 1.0783 - val_binary_accuracy: 0.7600\n",
            "Epoch 157/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0111 - binary_accuracy: 1.0000 - val_loss: 1.0791 - val_binary_accuracy: 0.7600\n",
            "Epoch 158/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0104 - binary_accuracy: 1.0000 - val_loss: 0.9882 - val_binary_accuracy: 0.7600\n",
            "Epoch 159/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0122 - binary_accuracy: 1.0000 - val_loss: 1.1642 - val_binary_accuracy: 0.7600\n",
            "Epoch 160/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0108 - binary_accuracy: 1.0000 - val_loss: 0.9955 - val_binary_accuracy: 0.7600\n",
            "Epoch 161/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0128 - binary_accuracy: 1.0000 - val_loss: 0.9978 - val_binary_accuracy: 0.7600\n",
            "Epoch 162/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0114 - binary_accuracy: 1.0000 - val_loss: 1.0325 - val_binary_accuracy: 0.7600\n",
            "Epoch 163/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.0129 - binary_accuracy: 1.0000 - val_loss: 1.1005 - val_binary_accuracy: 0.7400\n",
            "Epoch 164/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0093 - binary_accuracy: 1.0000 - val_loss: 1.0747 - val_binary_accuracy: 0.7600\n",
            "Epoch 165/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0094 - binary_accuracy: 1.0000 - val_loss: 1.1026 - val_binary_accuracy: 0.7600\n",
            "Epoch 166/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0102 - binary_accuracy: 1.0000 - val_loss: 1.0136 - val_binary_accuracy: 0.7400\n",
            "Epoch 167/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.0106 - binary_accuracy: 1.0000 - val_loss: 1.0408 - val_binary_accuracy: 0.7600\n",
            "Epoch 168/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.0096 - binary_accuracy: 1.0000 - val_loss: 1.1086 - val_binary_accuracy: 0.7600\n",
            "Epoch 169/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0085 - binary_accuracy: 1.0000 - val_loss: 1.0734 - val_binary_accuracy: 0.7600\n",
            "Epoch 170/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0084 - binary_accuracy: 1.0000 - val_loss: 1.1074 - val_binary_accuracy: 0.7600\n",
            "Epoch 171/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.0103 - binary_accuracy: 1.0000 - val_loss: 1.1326 - val_binary_accuracy: 0.7600\n",
            "Epoch 172/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.0094 - binary_accuracy: 1.0000 - val_loss: 1.0830 - val_binary_accuracy: 0.7600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best_epoch 71\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best_val_loss 0.46418\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy 1.0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 171\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss 0.00936\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy 0.76\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss 1.08297\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mtwilight-sweep-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/198zlqqw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 50 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230918_131811-198zlqqw/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m5d85it4 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 400\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 24\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 29\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearn_rate: 0.04294850410510114\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230918_131921-m5d85it4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstellar-sweep-4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/sweeps/5z67asm0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/m5d85it4\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "1/4 [======>.......................] - ETA: 3s - loss: 0.6956 - binary_accuracy: 0.5625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131921-m5d85it4/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 2s 332ms/step - loss: 0.6787 - binary_accuracy: 0.6364 - val_loss: 0.8986 - val_binary_accuracy: 0.3400\n",
            "Epoch 2/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6415 - binary_accuracy: 0.6603 - val_loss: 1.5560 - val_binary_accuracy: 0.3400\n",
            "Epoch 3/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.8618 - binary_accuracy: 0.6406"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131921-m5d85it4/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 294ms/step - loss: 0.7480 - binary_accuracy: 0.5550 - val_loss: 0.6423 - val_binary_accuracy: 0.6400\n",
            "Epoch 4/400\n",
            "4/4 [==============================] - 0s 33ms/step - loss: 0.6618 - binary_accuracy: 0.5981 - val_loss: 0.9858 - val_binary_accuracy: 0.3400\n",
            "Epoch 5/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.6326 - binary_accuracy: 0.6651 - val_loss: 0.6601 - val_binary_accuracy: 0.7800\n",
            "Epoch 6/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.6480 - binary_accuracy: 0.6459 - val_loss: 0.7683 - val_binary_accuracy: 0.3400\n",
            "Epoch 7/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.6353 - binary_accuracy: 0.6555 - val_loss: 0.8867 - val_binary_accuracy: 0.3400\n",
            "Epoch 8/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.6098 - binary_accuracy: 0.6875"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131921-m5d85it4/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 2s 620ms/step - loss: 0.6518 - binary_accuracy: 0.6555 - val_loss: 0.6010 - val_binary_accuracy: 0.6600\n",
            "Epoch 9/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.6739 - binary_accuracy: 0.5933 - val_loss: 0.8914 - val_binary_accuracy: 0.3400\n",
            "Epoch 10/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.6252 - binary_accuracy: 0.6555 - val_loss: 1.0932 - val_binary_accuracy: 0.3400\n",
            "Epoch 11/400\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6214 - binary_accuracy: 0.6507 - val_loss: 0.7455 - val_binary_accuracy: 0.4400\n",
            "Epoch 12/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6967 - binary_accuracy: 0.5742 - val_loss: 0.7065 - val_binary_accuracy: 0.4000\n",
            "Epoch 13/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6117 - binary_accuracy: 0.6603 - val_loss: 0.6771 - val_binary_accuracy: 0.5800\n",
            "Epoch 14/400\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.6204 - binary_accuracy: 0.7081 - val_loss: 1.1507 - val_binary_accuracy: 0.3400\n",
            "Epoch 15/400\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.6295 - binary_accuracy: 0.6699 - val_loss: 0.6215 - val_binary_accuracy: 0.7600\n",
            "Epoch 16/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.6470 - binary_accuracy: 0.6077 - val_loss: 1.3571 - val_binary_accuracy: 0.3400\n",
            "Epoch 17/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6577 - binary_accuracy: 0.6651 - val_loss: 1.0119 - val_binary_accuracy: 0.3400\n",
            "Epoch 18/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.6358 - binary_accuracy: 0.6411 - val_loss: 0.6340 - val_binary_accuracy: 0.7600\n",
            "Epoch 19/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.6167 - binary_accuracy: 0.6890 - val_loss: 1.0588 - val_binary_accuracy: 0.3400\n",
            "Epoch 20/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.6645 - binary_accuracy: 0.5981 - val_loss: 1.0190 - val_binary_accuracy: 0.3400\n",
            "Epoch 21/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.6062 - binary_accuracy: 0.6699 - val_loss: 0.6577 - val_binary_accuracy: 0.7800\n",
            "Epoch 22/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6122 - binary_accuracy: 0.6077 - val_loss: 0.7991 - val_binary_accuracy: 0.4000\n",
            "Epoch 23/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5619 - binary_accuracy: 0.6794 - val_loss: 0.6711 - val_binary_accuracy: 0.6800\n",
            "Epoch 24/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6691 - binary_accuracy: 0.6029 - val_loss: 0.7392 - val_binary_accuracy: 0.3800\n",
            "Epoch 25/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6423 - binary_accuracy: 0.6603 - val_loss: 0.7514 - val_binary_accuracy: 0.3600\n",
            "Epoch 26/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5635 - binary_accuracy: 0.6746 - val_loss: 0.8375 - val_binary_accuracy: 0.4200\n",
            "Epoch 27/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6067 - binary_accuracy: 0.6794 - val_loss: 0.7088 - val_binary_accuracy: 0.3800\n",
            "Epoch 28/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6621 - binary_accuracy: 0.6555 - val_loss: 0.7175 - val_binary_accuracy: 0.3400\n",
            "Epoch 29/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.6270 - binary_accuracy: 0.6651 - val_loss: 0.7173 - val_binary_accuracy: 0.3400\n",
            "Epoch 30/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5645 - binary_accuracy: 0.6603 - val_loss: 0.7102 - val_binary_accuracy: 0.3400\n",
            "Epoch 31/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5896 - binary_accuracy: 0.6651 - val_loss: 0.8256 - val_binary_accuracy: 0.3400\n",
            "Epoch 32/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5595 - binary_accuracy: 0.6651 - val_loss: 1.0930 - val_binary_accuracy: 0.3400\n",
            "Epoch 33/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6351 - binary_accuracy: 0.6603 - val_loss: 0.7117 - val_binary_accuracy: 0.3600\n",
            "Epoch 34/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5402 - binary_accuracy: 0.6794 - val_loss: 0.6752 - val_binary_accuracy: 0.6600\n",
            "Epoch 35/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6295 - binary_accuracy: 0.6507 - val_loss: 0.7076 - val_binary_accuracy: 0.3600\n",
            "Epoch 36/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5501 - binary_accuracy: 0.6651 - val_loss: 0.7092 - val_binary_accuracy: 0.3600\n",
            "Epoch 37/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5500 - binary_accuracy: 0.6890 - val_loss: 0.6972 - val_binary_accuracy: 0.5800\n",
            "Epoch 38/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6411 - binary_accuracy: 0.6411 - val_loss: 1.0834 - val_binary_accuracy: 0.3400\n",
            "Epoch 39/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5717 - binary_accuracy: 0.6699 - val_loss: 0.6935 - val_binary_accuracy: 0.4000\n",
            "Epoch 40/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.6305 - binary_accuracy: 0.6746 - val_loss: 0.7139 - val_binary_accuracy: 0.3600\n",
            "Epoch 41/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5364 - binary_accuracy: 0.6746 - val_loss: 0.6857 - val_binary_accuracy: 0.4600\n",
            "Epoch 42/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5759 - binary_accuracy: 0.6890 - val_loss: 0.7021 - val_binary_accuracy: 0.4400\n",
            "Epoch 43/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.5387 - binary_accuracy: 0.7500"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131921-m5d85it4/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 283ms/step - loss: 0.5296 - binary_accuracy: 0.7081 - val_loss: 0.5905 - val_binary_accuracy: 0.8200\n",
            "Epoch 44/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5436 - binary_accuracy: 0.7081 - val_loss: 0.7462 - val_binary_accuracy: 0.3400\n",
            "Epoch 45/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5192 - binary_accuracy: 0.6699 - val_loss: 0.6723 - val_binary_accuracy: 0.6200\n",
            "Epoch 46/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6122 - binary_accuracy: 0.7225 - val_loss: 0.7958 - val_binary_accuracy: 0.3600\n",
            "Epoch 47/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5130 - binary_accuracy: 0.7129 - val_loss: 1.3659 - val_binary_accuracy: 0.3400\n",
            "Epoch 48/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5902 - binary_accuracy: 0.6890 - val_loss: 1.0736 - val_binary_accuracy: 0.4200\n",
            "Epoch 49/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5143 - binary_accuracy: 0.7416 - val_loss: 0.6063 - val_binary_accuracy: 0.8400\n",
            "Epoch 50/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5685 - binary_accuracy: 0.6890 - val_loss: 0.9753 - val_binary_accuracy: 0.4000\n",
            "Epoch 51/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5535 - binary_accuracy: 0.6890 - val_loss: 0.7435 - val_binary_accuracy: 0.6000\n",
            "Epoch 52/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.4276 - binary_accuracy: 0.8125"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131921-m5d85it4/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 363ms/step - loss: 0.4702 - binary_accuracy: 0.7847 - val_loss: 0.5501 - val_binary_accuracy: 0.7400\n",
            "Epoch 53/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6022 - binary_accuracy: 0.5837 - val_loss: 1.1133 - val_binary_accuracy: 0.3400\n",
            "Epoch 54/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5558 - binary_accuracy: 0.6651 - val_loss: 1.3867 - val_binary_accuracy: 0.3400\n",
            "Epoch 55/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6194 - binary_accuracy: 0.6651 - val_loss: 0.9538 - val_binary_accuracy: 0.3400\n",
            "Epoch 56/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5275 - binary_accuracy: 0.6651 - val_loss: 0.7570 - val_binary_accuracy: 0.4000\n",
            "Epoch 57/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5036 - binary_accuracy: 0.6699 - val_loss: 0.6862 - val_binary_accuracy: 0.5000\n",
            "Epoch 58/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4846 - binary_accuracy: 0.6986 - val_loss: 0.7849 - val_binary_accuracy: 0.6000\n",
            "Epoch 59/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5887 - binary_accuracy: 0.6172 - val_loss: 0.6903 - val_binary_accuracy: 0.5200\n",
            "Epoch 60/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5155 - binary_accuracy: 0.7129 - val_loss: 0.7845 - val_binary_accuracy: 0.4600\n",
            "Epoch 61/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4825 - binary_accuracy: 0.7273 - val_loss: 0.6447 - val_binary_accuracy: 0.6000\n",
            "Epoch 62/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5593 - binary_accuracy: 0.6459 - val_loss: 0.9732 - val_binary_accuracy: 0.3800\n",
            "Epoch 63/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5327 - binary_accuracy: 0.6938 - val_loss: 0.6521 - val_binary_accuracy: 0.6400\n",
            "Epoch 64/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5381 - binary_accuracy: 0.6794 - val_loss: 0.6801 - val_binary_accuracy: 0.5200\n",
            "Epoch 65/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5382 - binary_accuracy: 0.7129 - val_loss: 1.6683 - val_binary_accuracy: 0.3400\n",
            "Epoch 66/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7559 - binary_accuracy: 0.6699 - val_loss: 0.7188 - val_binary_accuracy: 0.3600\n",
            "Epoch 67/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5767 - binary_accuracy: 0.6746 - val_loss: 0.7092 - val_binary_accuracy: 0.3800\n",
            "Epoch 68/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5705 - binary_accuracy: 0.6699 - val_loss: 0.6907 - val_binary_accuracy: 0.4800\n",
            "Epoch 69/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6043 - binary_accuracy: 0.6794 - val_loss: 0.7867 - val_binary_accuracy: 0.3400\n",
            "Epoch 70/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5662 - binary_accuracy: 0.6794 - val_loss: 1.0255 - val_binary_accuracy: 0.3600\n",
            "Epoch 71/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5713 - binary_accuracy: 0.7321 - val_loss: 0.7656 - val_binary_accuracy: 0.5000\n",
            "Epoch 72/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4962 - binary_accuracy: 0.7464 - val_loss: 1.6345 - val_binary_accuracy: 0.3600\n",
            "Epoch 73/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6282 - binary_accuracy: 0.6699 - val_loss: 0.7686 - val_binary_accuracy: 0.5000\n",
            "Epoch 74/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5216 - binary_accuracy: 0.7368 - val_loss: 0.8589 - val_binary_accuracy: 0.4600\n",
            "Epoch 75/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5420 - binary_accuracy: 0.6986 - val_loss: 1.0328 - val_binary_accuracy: 0.4000\n",
            "Epoch 76/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5416 - binary_accuracy: 0.7368 - val_loss: 0.8274 - val_binary_accuracy: 0.3800\n",
            "Epoch 77/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4958 - binary_accuracy: 0.7081 - val_loss: 0.6214 - val_binary_accuracy: 0.7600\n",
            "Epoch 78/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.5192 - binary_accuracy: 0.7273 - val_loss: 0.5863 - val_binary_accuracy: 0.8200\n",
            "Epoch 79/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5178 - binary_accuracy: 0.7129 - val_loss: 0.6428 - val_binary_accuracy: 0.6400\n",
            "Epoch 80/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5090 - binary_accuracy: 0.7416 - val_loss: 0.6731 - val_binary_accuracy: 0.6600\n",
            "Epoch 81/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.5497 - binary_accuracy: 0.7033 - val_loss: 0.9961 - val_binary_accuracy: 0.3600\n",
            "Epoch 82/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5287 - binary_accuracy: 0.7225 - val_loss: 0.5897 - val_binary_accuracy: 0.6600\n",
            "Epoch 83/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.6996 - binary_accuracy: 0.5981 - val_loss: 0.6884 - val_binary_accuracy: 0.4800\n",
            "Epoch 84/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.6076 - binary_accuracy: 0.7416 - val_loss: 0.6195 - val_binary_accuracy: 0.6600\n",
            "Epoch 85/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5934 - binary_accuracy: 0.6986 - val_loss: 0.5910 - val_binary_accuracy: 0.8200\n",
            "Epoch 86/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5419 - binary_accuracy: 0.7273 - val_loss: 0.7452 - val_binary_accuracy: 0.5400\n",
            "Epoch 87/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4649 - binary_accuracy: 0.7416 - val_loss: 0.8186 - val_binary_accuracy: 0.5600\n",
            "Epoch 88/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4180 - binary_accuracy: 0.8230 - val_loss: 0.6495 - val_binary_accuracy: 0.7000\n",
            "Epoch 89/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3630 - binary_accuracy: 0.8281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131921-m5d85it4/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 307ms/step - loss: 0.4007 - binary_accuracy: 0.7990 - val_loss: 0.5138 - val_binary_accuracy: 0.7600\n",
            "Epoch 90/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.5380 - binary_accuracy: 0.6603 - val_loss: 0.6644 - val_binary_accuracy: 0.4800\n",
            "Epoch 91/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.5364 - binary_accuracy: 0.7560 - val_loss: 0.7053 - val_binary_accuracy: 0.6200\n",
            "Epoch 92/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3940 - binary_accuracy: 0.8038 - val_loss: 0.6200 - val_binary_accuracy: 0.7600\n",
            "Epoch 93/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4198 - binary_accuracy: 0.7751 - val_loss: 1.3088 - val_binary_accuracy: 0.4200\n",
            "Epoch 94/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5988 - binary_accuracy: 0.7177 - val_loss: 0.6308 - val_binary_accuracy: 0.6000\n",
            "Epoch 95/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4224 - binary_accuracy: 0.8517 - val_loss: 0.8412 - val_binary_accuracy: 0.6400\n",
            "Epoch 96/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4733 - binary_accuracy: 0.7656 - val_loss: 0.8831 - val_binary_accuracy: 0.3400\n",
            "Epoch 97/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4550 - binary_accuracy: 0.7368 - val_loss: 0.8692 - val_binary_accuracy: 0.5400\n",
            "Epoch 98/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4105 - binary_accuracy: 0.8278 - val_loss: 0.8203 - val_binary_accuracy: 0.6400\n",
            "Epoch 99/400\n",
            "1/4 [======>.......................] - ETA: 0s - loss: 0.3590 - binary_accuracy: 0.8281"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_131921-m5d85it4/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r4/4 [==============================] - 1s 281ms/step - loss: 0.3759 - binary_accuracy: 0.8278 - val_loss: 0.4602 - val_binary_accuracy: 0.8000\n",
            "Epoch 100/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4585 - binary_accuracy: 0.7799 - val_loss: 0.7568 - val_binary_accuracy: 0.3400\n",
            "Epoch 101/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.5202 - binary_accuracy: 0.6746 - val_loss: 0.9942 - val_binary_accuracy: 0.3400\n",
            "Epoch 102/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4865 - binary_accuracy: 0.6986 - val_loss: 0.7570 - val_binary_accuracy: 0.7000\n",
            "Epoch 103/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4672 - binary_accuracy: 0.7368 - val_loss: 0.8713 - val_binary_accuracy: 0.3600\n",
            "Epoch 104/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4730 - binary_accuracy: 0.6842 - val_loss: 0.8153 - val_binary_accuracy: 0.4800\n",
            "Epoch 105/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4030 - binary_accuracy: 0.7751 - val_loss: 0.5566 - val_binary_accuracy: 0.6800\n",
            "Epoch 106/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6050 - binary_accuracy: 0.6842 - val_loss: 0.6352 - val_binary_accuracy: 0.6600\n",
            "Epoch 107/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4109 - binary_accuracy: 0.7608 - val_loss: 0.5958 - val_binary_accuracy: 0.7000\n",
            "Epoch 108/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7405 - binary_accuracy: 0.6268 - val_loss: 0.6941 - val_binary_accuracy: 0.4600\n",
            "Epoch 109/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.4426 - binary_accuracy: 0.7656 - val_loss: 0.7608 - val_binary_accuracy: 0.5000\n",
            "Epoch 110/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.3934 - binary_accuracy: 0.7703 - val_loss: 0.7194 - val_binary_accuracy: 0.5600\n",
            "Epoch 111/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.7589 - binary_accuracy: 0.5789 - val_loss: 0.6974 - val_binary_accuracy: 0.4000\n",
            "Epoch 112/400\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.5355 - binary_accuracy: 0.7177 - val_loss: 0.8294 - val_binary_accuracy: 0.4000\n",
            "Epoch 113/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.4370 - binary_accuracy: 0.7129 - val_loss: 0.7399 - val_binary_accuracy: 0.6000\n",
            "Epoch 114/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3715 - binary_accuracy: 0.8134 - val_loss: 0.9399 - val_binary_accuracy: 0.4600\n",
            "Epoch 115/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3467 - binary_accuracy: 0.8182 - val_loss: 0.4883 - val_binary_accuracy: 0.7800\n",
            "Epoch 116/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3915 - binary_accuracy: 0.8182 - val_loss: 0.5308 - val_binary_accuracy: 0.7400\n",
            "Epoch 117/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5196 - binary_accuracy: 0.6651 - val_loss: 0.7457 - val_binary_accuracy: 0.5800\n",
            "Epoch 118/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3715 - binary_accuracy: 0.7943 - val_loss: 0.7746 - val_binary_accuracy: 0.6400\n",
            "Epoch 119/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3215 - binary_accuracy: 0.8278 - val_loss: 0.9411 - val_binary_accuracy: 0.6800\n",
            "Epoch 120/400\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.6073 - binary_accuracy: 0.7033 - val_loss: 0.9944 - val_binary_accuracy: 0.3800\n",
            "Epoch 121/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.6118 - binary_accuracy: 0.6746 - val_loss: 0.7533 - val_binary_accuracy: 0.4600\n",
            "Epoch 122/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.5852 - binary_accuracy: 0.7560 - val_loss: 0.6660 - val_binary_accuracy: 0.6800\n",
            "Epoch 123/400\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.5675 - binary_accuracy: 0.7703 - val_loss: 0.6070 - val_binary_accuracy: 0.8000\n",
            "Epoch 124/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.5914 - binary_accuracy: 0.6938 - val_loss: 0.7286 - val_binary_accuracy: 0.4600\n",
            "Epoch 125/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.4822 - binary_accuracy: 0.7512 - val_loss: 0.5503 - val_binary_accuracy: 0.6800\n",
            "Epoch 126/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.5634 - binary_accuracy: 0.6746 - val_loss: 1.1064 - val_binary_accuracy: 0.3800\n",
            "Epoch 127/400\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4730 - binary_accuracy: 0.7990 - val_loss: 0.8668 - val_binary_accuracy: 0.5000\n",
            "Epoch 128/400\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.5014 - binary_accuracy: 0.7081 - val_loss: 0.5841 - val_binary_accuracy: 0.7400\n",
            "Epoch 129/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.5443 - binary_accuracy: 0.6986 - val_loss: 0.7802 - val_binary_accuracy: 0.5400\n",
            "Epoch 130/400\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.4502 - binary_accuracy: 0.7656 - val_loss: 0.6698 - val_binary_accuracy: 0.5000\n",
            "Epoch 131/400\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.4035 - binary_accuracy: 0.7943 - val_loss: 0.6681 - val_binary_accuracy: 0.6800\n",
            "Epoch 132/400\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.4339 - binary_accuracy: 0.7799 - val_loss: 0.6420 - val_binary_accuracy: 0.6800\n",
            "Epoch 133/400\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.7014 - binary_accuracy: 0.6220 - val_loss: 0.6285 - val_binary_accuracy: 0.7600\n",
            "Epoch 134/400\n",
            "4/4 [==============================] - 0s 85ms/step - loss: 0.4300 - binary_accuracy: 0.8182 - val_loss: 0.6782 - val_binary_accuracy: 0.7600\n",
            "Epoch 135/400\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.3419 - binary_accuracy: 0.8230 - val_loss: 0.5314 - val_binary_accuracy: 0.7600\n",
            "Epoch 136/400\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.4317 - binary_accuracy: 0.7321 - val_loss: 0.7271 - val_binary_accuracy: 0.7400\n",
            "Epoch 137/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.3563 - binary_accuracy: 0.8230 - val_loss: 0.7230 - val_binary_accuracy: 0.7800\n",
            "Epoch 138/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.3237 - binary_accuracy: 0.8421 - val_loss: 0.8319 - val_binary_accuracy: 0.6200\n",
            "Epoch 139/400\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.3244 - binary_accuracy: 0.8230 - val_loss: 0.8918 - val_binary_accuracy: 0.7200\n",
            "Epoch 140/400\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.3913 - binary_accuracy: 0.7847 - val_loss: 0.9048 - val_binary_accuracy: 0.6600\n",
            "Epoch 141/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3315 - binary_accuracy: 0.8469 - val_loss: 1.5693 - val_binary_accuracy: 0.3800\n",
            "Epoch 142/400\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.5248 - binary_accuracy: 0.7368 - val_loss: 0.5845 - val_binary_accuracy: 0.7800\n",
            "Epoch 143/400\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.3711 - binary_accuracy: 0.8182 - val_loss: 0.9388 - val_binary_accuracy: 0.7000\n",
            "Epoch 144/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3676 - binary_accuracy: 0.7943 - val_loss: 0.9533 - val_binary_accuracy: 0.3800\n",
            "Epoch 145/400\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4273 - binary_accuracy: 0.7177 - val_loss: 0.6273 - val_binary_accuracy: 0.5400\n",
            "Epoch 146/400\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.4036 - binary_accuracy: 0.8038 - val_loss: 0.6668 - val_binary_accuracy: 0.6400\n",
            "Epoch 147/400\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.4433 - binary_accuracy: 0.7416 - val_loss: 0.6427 - val_binary_accuracy: 0.6600\n",
            "Epoch 148/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.3481 - binary_accuracy: 0.8421 - val_loss: 0.7353 - val_binary_accuracy: 0.7200\n",
            "Epoch 149/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.2666 - binary_accuracy: 0.8852 - val_loss: 1.2574 - val_binary_accuracy: 0.4800\n",
            "Epoch 150/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.3379 - binary_accuracy: 0.8517 - val_loss: 0.7254 - val_binary_accuracy: 0.7200\n",
            "Epoch 151/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2496 - binary_accuracy: 0.8852 - val_loss: 0.7912 - val_binary_accuracy: 0.7200\n",
            "Epoch 152/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2598 - binary_accuracy: 0.8852 - val_loss: 1.5944 - val_binary_accuracy: 0.5000\n",
            "Epoch 153/400\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.5154 - binary_accuracy: 0.7608 - val_loss: 0.5739 - val_binary_accuracy: 0.7400\n",
            "Epoch 154/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4789 - binary_accuracy: 0.7703 - val_loss: 0.9834 - val_binary_accuracy: 0.4600\n",
            "Epoch 155/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4151 - binary_accuracy: 0.8038 - val_loss: 0.6072 - val_binary_accuracy: 0.5400\n",
            "Epoch 156/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4126 - binary_accuracy: 0.8086 - val_loss: 0.6668 - val_binary_accuracy: 0.6600\n",
            "Epoch 157/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3017 - binary_accuracy: 0.8660 - val_loss: 0.6102 - val_binary_accuracy: 0.7000\n",
            "Epoch 158/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.4254 - binary_accuracy: 0.7751 - val_loss: 0.6823 - val_binary_accuracy: 0.6200\n",
            "Epoch 159/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4374 - binary_accuracy: 0.7895 - val_loss: 0.8820 - val_binary_accuracy: 0.5600\n",
            "Epoch 160/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3189 - binary_accuracy: 0.8421 - val_loss: 0.8207 - val_binary_accuracy: 0.6800\n",
            "Epoch 161/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2295 - binary_accuracy: 0.9091 - val_loss: 1.2099 - val_binary_accuracy: 0.6600\n",
            "Epoch 162/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.6245 - binary_accuracy: 0.6986 - val_loss: 1.0903 - val_binary_accuracy: 0.4000\n",
            "Epoch 163/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3735 - binary_accuracy: 0.7225 - val_loss: 1.0289 - val_binary_accuracy: 0.4600\n",
            "Epoch 164/400\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3454 - binary_accuracy: 0.7608 - val_loss: 0.9013 - val_binary_accuracy: 0.4800\n",
            "Epoch 165/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3787 - binary_accuracy: 0.7512 - val_loss: 1.1142 - val_binary_accuracy: 0.4600\n",
            "Epoch 166/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3174 - binary_accuracy: 0.8038 - val_loss: 0.8452 - val_binary_accuracy: 0.5200\n",
            "Epoch 167/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2657 - binary_accuracy: 0.8230 - val_loss: 0.9344 - val_binary_accuracy: 0.5600\n",
            "Epoch 168/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2652 - binary_accuracy: 0.8182 - val_loss: 0.9343 - val_binary_accuracy: 0.5600\n",
            "Epoch 169/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2905 - binary_accuracy: 0.7943 - val_loss: 0.8803 - val_binary_accuracy: 0.5200\n",
            "Epoch 170/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2607 - binary_accuracy: 0.8373 - val_loss: 0.6541 - val_binary_accuracy: 0.6200\n",
            "Epoch 171/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2322 - binary_accuracy: 0.8852 - val_loss: 0.8696 - val_binary_accuracy: 0.7000\n",
            "Epoch 172/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2089 - binary_accuracy: 0.8947 - val_loss: 0.8188 - val_binary_accuracy: 0.7000\n",
            "Epoch 173/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1917 - binary_accuracy: 0.9187 - val_loss: 0.8135 - val_binary_accuracy: 0.6800\n",
            "Epoch 174/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2810 - binary_accuracy: 0.8660 - val_loss: 0.6590 - val_binary_accuracy: 0.6000\n",
            "Epoch 175/400\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2408 - binary_accuracy: 0.8469 - val_loss: 1.1237 - val_binary_accuracy: 0.6400\n",
            "Epoch 176/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2156 - binary_accuracy: 0.8995 - val_loss: 0.8400 - val_binary_accuracy: 0.7200\n",
            "Epoch 177/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3061 - binary_accuracy: 0.8230 - val_loss: 0.6433 - val_binary_accuracy: 0.7000\n",
            "Epoch 178/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4297 - binary_accuracy: 0.8134 - val_loss: 0.6383 - val_binary_accuracy: 0.7800\n",
            "Epoch 179/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2169 - binary_accuracy: 0.9378 - val_loss: 0.5430 - val_binary_accuracy: 0.7000\n",
            "Epoch 180/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2476 - binary_accuracy: 0.8708 - val_loss: 0.6001 - val_binary_accuracy: 0.8000\n",
            "Epoch 181/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2000 - binary_accuracy: 0.9091 - val_loss: 0.8241 - val_binary_accuracy: 0.6000\n",
            "Epoch 182/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2626 - binary_accuracy: 0.8612 - val_loss: 1.2436 - val_binary_accuracy: 0.7400\n",
            "Epoch 183/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.3676 - binary_accuracy: 0.8182 - val_loss: 0.7143 - val_binary_accuracy: 0.6200\n",
            "Epoch 184/400\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.2229 - binary_accuracy: 0.9043 - val_loss: 0.7623 - val_binary_accuracy: 0.8200\n",
            "Epoch 185/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.6564 - binary_accuracy: 0.7368 - val_loss: 0.7250 - val_binary_accuracy: 0.4800\n",
            "Epoch 186/400\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.4168 - binary_accuracy: 0.7799 - val_loss: 0.9238 - val_binary_accuracy: 0.4800\n",
            "Epoch 187/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2935 - binary_accuracy: 0.8565 - val_loss: 0.9223 - val_binary_accuracy: 0.6600\n",
            "Epoch 188/400\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.4703 - binary_accuracy: 0.7847 - val_loss: 0.6988 - val_binary_accuracy: 0.4600\n",
            "Epoch 189/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4265 - binary_accuracy: 0.7990 - val_loss: 0.8229 - val_binary_accuracy: 0.6400\n",
            "Epoch 190/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.3407 - binary_accuracy: 0.8038 - val_loss: 0.7661 - val_binary_accuracy: 0.6400\n",
            "Epoch 191/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2702 - binary_accuracy: 0.8612 - val_loss: 0.8712 - val_binary_accuracy: 0.7600\n",
            "Epoch 192/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2407 - binary_accuracy: 0.8804 - val_loss: 1.2360 - val_binary_accuracy: 0.5600\n",
            "Epoch 193/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.4020 - binary_accuracy: 0.7943 - val_loss: 0.7825 - val_binary_accuracy: 0.6200\n",
            "Epoch 194/400\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.2779 - binary_accuracy: 0.8565 - val_loss: 0.7677 - val_binary_accuracy: 0.7600\n",
            "Epoch 195/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.4092 - binary_accuracy: 0.7990 - val_loss: 0.5825 - val_binary_accuracy: 0.7200\n",
            "Epoch 196/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.3415 - binary_accuracy: 0.8325 - val_loss: 1.0576 - val_binary_accuracy: 0.5200\n",
            "Epoch 197/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2759 - binary_accuracy: 0.8612 - val_loss: 0.5653 - val_binary_accuracy: 0.7000\n",
            "Epoch 198/400\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.4529 - binary_accuracy: 0.7321 - val_loss: 0.9266 - val_binary_accuracy: 0.6000\n",
            "Epoch 199/400\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2453 - binary_accuracy: 0.8612 - val_loss: 0.8010 - val_binary_accuracy: 0.7800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:          best_epoch 98\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       best_val_loss 0.4602\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:     binary_accuracy 0.86124\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:               epoch 198\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                loss 0.24526\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: val_binary_accuracy 0.78\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            val_loss 0.80098\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mstellar-sweep-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/m5d85it4\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 1 media file(s), 35 artifact file(s) and 1 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230918_131921-m5d85it4/logs\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: thxvxodw with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepoch: 600\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_1: 18\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlayer_2: 9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearn_rate: 0.06344718181598742\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20230918_132025-thxvxodw\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View project at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/sweeps/5z67asm0\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/terrematte/dl_week06/runs/thxvxodw\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/600\n",
            "1/7 [===>..........................] - ETA: 4s - loss: 0.6788 - binary_accuracy: 0.5625"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_132025-thxvxodw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 2s 216ms/step - loss: 0.8458 - binary_accuracy: 0.5694 - val_loss: 0.9188 - val_binary_accuracy: 0.3400\n",
            "Epoch 2/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6065 - binary_accuracy: 0.7188"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20230918_132025-thxvxodw/files/model-best)... Done. 0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 1s 156ms/step - loss: 0.6761 - binary_accuracy: 0.6555 - val_loss: 0.6994 - val_binary_accuracy: 0.3400\n",
            "Epoch 3/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6828 - binary_accuracy: 0.6555 - val_loss: 0.7151 - val_binary_accuracy: 0.3400\n",
            "Epoch 4/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6721 - binary_accuracy: 0.6555 - val_loss: 0.7282 - val_binary_accuracy: 0.3400\n",
            "Epoch 5/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6654 - binary_accuracy: 0.6555 - val_loss: 0.7398 - val_binary_accuracy: 0.3400\n",
            "Epoch 6/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6600 - binary_accuracy: 0.6555 - val_loss: 0.7586 - val_binary_accuracy: 0.3400\n",
            "Epoch 7/600\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 0.6575 - binary_accuracy: 0.6555 - val_loss: 0.7630 - val_binary_accuracy: 0.3400\n",
            "Epoch 8/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6532 - binary_accuracy: 0.6555 - val_loss: 0.7728 - val_binary_accuracy: 0.3400\n",
            "Epoch 9/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6489 - binary_accuracy: 0.6555 - val_loss: 0.9590 - val_binary_accuracy: 0.3400\n",
            "Epoch 10/600\n",
            "7/7 [==============================] - 0s 21ms/step - loss: 0.6517 - binary_accuracy: 0.6555 - val_loss: 0.7847 - val_binary_accuracy: 0.3400\n",
            "Epoch 11/600\n",
            "7/7 [==============================] - 0s 42ms/step - loss: 0.6390 - binary_accuracy: 0.6555 - val_loss: 0.7873 - val_binary_accuracy: 0.3400\n",
            "Epoch 12/600\n",
            "7/7 [==============================] - 0s 48ms/step - loss: 0.7025 - binary_accuracy: 0.6555 - val_loss: 0.7852 - val_binary_accuracy: 0.3400\n",
            "Epoch 13/600\n",
            "7/7 [==============================] - 0s 37ms/step - loss: 0.6487 - binary_accuracy: 0.6555 - val_loss: 0.7925 - val_binary_accuracy: 0.3400\n",
            "Epoch 14/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6473 - binary_accuracy: 0.6555 - val_loss: 0.7999 - val_binary_accuracy: 0.3400\n",
            "Epoch 15/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6464 - binary_accuracy: 0.6555 - val_loss: 0.8084 - val_binary_accuracy: 0.3400\n",
            "Epoch 16/600\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6454 - binary_accuracy: 0.6555 - val_loss: 0.8134 - val_binary_accuracy: 0.3400\n",
            "Epoch 17/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6451 - binary_accuracy: 0.6555 - val_loss: 0.8168 - val_binary_accuracy: 0.3400\n",
            "Epoch 18/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6449 - binary_accuracy: 0.6555 - val_loss: 0.8215 - val_binary_accuracy: 0.3400\n",
            "Epoch 19/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6443 - binary_accuracy: 0.6555 - val_loss: 0.8252 - val_binary_accuracy: 0.3400\n",
            "Epoch 20/600\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6444 - binary_accuracy: 0.6555 - val_loss: 0.8256 - val_binary_accuracy: 0.3400\n",
            "Epoch 21/600\n",
            "7/7 [==============================] - 0s 13ms/step - loss: 0.6440 - binary_accuracy: 0.6555 - val_loss: 0.8278 - val_binary_accuracy: 0.3400\n",
            "Epoch 22/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6440 - binary_accuracy: 0.6555 - val_loss: 0.8305 - val_binary_accuracy: 0.3400\n",
            "Epoch 23/600\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6439 - binary_accuracy: 0.6555 - val_loss: 0.8357 - val_binary_accuracy: 0.3400\n",
            "Epoch 24/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6436 - binary_accuracy: 0.6555 - val_loss: 0.8365 - val_binary_accuracy: 0.3400\n",
            "Epoch 25/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6435 - binary_accuracy: 0.6555 - val_loss: 0.8365 - val_binary_accuracy: 0.3400\n",
            "Epoch 26/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6434 - binary_accuracy: 0.6555 - val_loss: 0.8378 - val_binary_accuracy: 0.3400\n",
            "Epoch 27/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6431 - binary_accuracy: 0.6555 - val_loss: 0.8380 - val_binary_accuracy: 0.3400\n",
            "Epoch 28/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6433 - binary_accuracy: 0.6555 - val_loss: 0.8388 - val_binary_accuracy: 0.3400\n",
            "Epoch 29/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6435 - binary_accuracy: 0.6555 - val_loss: 0.8411 - val_binary_accuracy: 0.3400\n",
            "Epoch 30/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6434 - binary_accuracy: 0.6555 - val_loss: 0.8410 - val_binary_accuracy: 0.3400\n",
            "Epoch 31/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6436 - binary_accuracy: 0.6555 - val_loss: 0.8442 - val_binary_accuracy: 0.3400\n",
            "Epoch 32/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6434 - binary_accuracy: 0.6555 - val_loss: 0.8422 - val_binary_accuracy: 0.3400\n",
            "Epoch 33/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6426 - binary_accuracy: 0.6555 - val_loss: 0.8414 - val_binary_accuracy: 0.3400\n",
            "Epoch 34/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6430 - binary_accuracy: 0.6555 - val_loss: 0.8446 - val_binary_accuracy: 0.3400\n",
            "Epoch 35/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6429 - binary_accuracy: 0.6555 - val_loss: 0.8424 - val_binary_accuracy: 0.3400\n",
            "Epoch 36/600\n",
            "7/7 [==============================] - 0s 19ms/step - loss: 0.6423 - binary_accuracy: 0.6555 - val_loss: 0.8436 - val_binary_accuracy: 0.3400\n",
            "Epoch 37/600\n",
            "7/7 [==============================] - 0s 17ms/step - loss: 0.6445 - binary_accuracy: 0.6555 - val_loss: 0.8467 - val_binary_accuracy: 0.3400\n",
            "Epoch 38/600\n",
            "7/7 [==============================] - 0s 18ms/step - loss: 0.6430 - binary_accuracy: 0.6555 - val_loss: 0.8473 - val_binary_accuracy: 0.3400\n",
            "Epoch 39/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6426 - binary_accuracy: 0.6555 - val_loss: 0.8458 - val_binary_accuracy: 0.3400\n",
            "Epoch 40/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6427 - binary_accuracy: 0.6555 - val_loss: 0.8485 - val_binary_accuracy: 0.3400\n",
            "Epoch 41/600\n",
            "7/7 [==============================] - 0s 16ms/step - loss: 0.6425 - binary_accuracy: 0.6555 - val_loss: 0.8448 - val_binary_accuracy: 0.3400\n",
            "Epoch 42/600\n",
            "7/7 [==============================] - 0s 15ms/step - loss: 0.6424 - binary_accuracy: 0.6555 - val_loss: 0.8409 - val_binary_accuracy: 0.3400\n",
            "Epoch 43/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6420 - binary_accuracy: 0.6555 - val_loss: 0.8474 - val_binary_accuracy: 0.3400\n",
            "Epoch 44/600\n",
            "7/7 [==============================] - 0s 12ms/step - loss: 0.6411 - binary_accuracy: 0.6555 - val_loss: 0.8469 - val_binary_accuracy: 0.3400\n",
            "Epoch 45/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6418 - binary_accuracy: 0.6555 - val_loss: 0.8506 - val_binary_accuracy: 0.3400\n",
            "Epoch 46/600\n",
            "7/7 [==============================] - 0s 11ms/step - loss: 0.6419 - binary_accuracy: 0.6555 - val_loss: 0.8471 - val_binary_accuracy: 0.3400\n",
            "Epoch 47/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6415 - binary_accuracy: 0.6555 - val_loss: 0.8650 - val_binary_accuracy: 0.3400\n",
            "Epoch 48/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6416 - binary_accuracy: 0.6555 - val_loss: 0.8482 - val_binary_accuracy: 0.3400\n",
            "Epoch 49/600\n",
            "7/7 [==============================] - 0s 14ms/step - loss: 0.6422 - binary_accuracy: 0.6555 - val_loss: 0.8433 - val_binary_accuracy: 0.3400\n",
            "Epoch 50/600\n",
            "1/7 [===>..........................] - ETA: 0s - loss: 0.6796 - binary_accuracy: 0.5938"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r7/7 [==============================] - 0s 16ms/step - loss: 0.6396 - binary_accuracy: 0.6555 - val_loss: 0.8399 - val_binary_accuracy: 0.3400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish() # Let wandb know you're finished!"
      ],
      "metadata": {
        "id": "ssOyV63AW_GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_dpK2SHjIlu"
      },
      "source": [
        "### 4.2.1 Restore a model\n",
        "\n",
        "Restore a file, such as a model checkpoint, into your local run folder to access in your script.\n",
        "\n",
        "See [the restore docs](https://docs.wandb.com/library/restore) for more details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ikTvdN61mm0"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xi-Fv1nfAU6q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1319a7a-f27c-4fe2-a09f-bcb5c6282800"
      },
      "source": [
        " import wandb\n",
        "\n",
        " wandb.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0.15.10'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zhf0Gix1nYD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4f2edb-bdcf-456e-816c-5dd52063a23b"
      },
      "source": [
        "!wandb login"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mterrematte\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LB6j3O-jIsd"
      },
      "source": [
        "# restore the raw model file \"model-best.h5\" from a specific run by user \"terrematte\"\n",
        "# in project \"dl_week06\" from run \"5z67asm0\"\n",
        "best_model = wandb.restore('model-best.h5', run_path=\"terrematte/dl_week06/5z67asm0\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wo_JI5RPHzKu"
      },
      "source": [
        "# restore the model for tf.keras\n",
        "model = tf.keras.models.load_model(best_model.name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeM9gLcrDiz7"
      },
      "source": [
        "# execute the loss and accuracy using the test dataset\n",
        "loss_, acc_ = model.evaluate(x=test_x,y=test_y, batch_size=64)\n",
        "print('Test loss: %.3f - acc: %.3f' % (loss_, acc_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a55_JCKuR4kJ"
      },
      "source": [
        "# source: https://github.com/wandb/awesome-dl-projects/blob/master/ml-tutorial/EMNIST_Dense_Classification.ipynb\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "predictions = np.greater_equal(model.predict(test_x),0.5).astype(int)\n",
        "cm = confusion_matrix(y_true = test_y, y_pred = predictions)\n",
        "\n",
        "plt.figure(figsize=(6,6));\n",
        "sns.heatmap(cm, annot=True)\n",
        "plt.savefig('confusion_matrix.png', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTu0f6DiR7oW"
      },
      "source": [
        "wandb.init(project=\"dl_week06\")\n",
        "wandb.log({\"image_confusion_matrix\": [wandb.Image('confusion_matrix.png')]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XM5q_a_zqMY0"
      },
      "source": [
        "# visualize the images and instances with error\n",
        "# ground-truth\n",
        "print(\"Ground-truth\\n\",test_y[~np.equal(predictions,test_y)])\n",
        "\n",
        "# predictions\n",
        "print(\"Predictions\\n\",predictions[~np.equal(predictions,test_y)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iJtJ-wWvvl5"
      },
      "source": [
        "# Images predicted as non-cat\n",
        "fig, ax = plt.subplots(2,6,figsize=(10,6))\n",
        "wrong_images = (~np.equal(predictions,test_y)).astype(int)\n",
        "index = np.where(wrong_images == 1)[0]\n",
        "\n",
        "for i,value in enumerate(index):\n",
        "  ax[i//6,i%6].imshow(test_x[value].reshape(64,64,3))\n",
        "plt.savefig('wrong_predictions.png', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnywcEUHxvL_"
      },
      "source": [
        "wandb.log({\"wrong_predictions\": [wandb.Image('wrong_predictions.png')]})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhBR6ePBvHy7"
      },
      "source": [
        "# 5 References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb3mCmDDvJjw"
      },
      "source": [
        "1. https://github.com/wandb/awesome-dl-projects\n",
        "2. https://docs.wandb.ai/app/features/panels/parameter-importance\n",
        "3. https://wandb.ai/wandb/DistHyperOpt/reports/Modern-Scalable-Hyperparameter-Tuning-Methods--VmlldzoyMTQxODM"
      ]
    }
  ]
}